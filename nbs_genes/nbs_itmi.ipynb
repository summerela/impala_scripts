{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Newborn Screening Disorders with WGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illumina variants were annotated with the NBS gene table provided by Ben Solomon at ITMI. Variants located in NBS gene regions were annotated with Kaviar frequency, ClinVar clinical significance ratings, DANN predicted pathogenicity scores for SNV's, and coding consequence predictions using SnpEff.\n",
    "\n",
    "Variants were filtered for appropriate mode of inheritance and then labeled as predictive when they contain the presence of mutation(s) with appropriate inheritance (eg, 2 bi-allelic pathogenic mutations for a recessive disorder).  \n",
    "\n",
    "Mutations defined strictly as either:  \n",
    "- Annotated in ClinVar with a clinical significance of 4 or 5, but never 2 or 3  \n",
    "\n",
    "OR  \n",
    "- Novel (in Kaviar with frequency lower than specified below, or not listed in Kaviar) and predicted to be disease-causing with a SnpEff impact score of 'high'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Specified Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# enter kaviar frequency threshold\n",
    "kav_freq = '.01'\n",
    "\n",
    "# enter variant quality score cutoff\n",
    "qual_cutoff = '30'\n",
    "\n",
    "# enter minimum read depth\n",
    "read_depth = '10'\n",
    "\n",
    "# enter dictionary of samples to examine in format 'sample_id':['family_id','member_id']\n",
    "sample_list = 'all'\n",
    "\n",
    "# enter as NB, M, and/or F, or 'all' to include extended family if available\n",
    "trio_member = 'NB','M','F'\n",
    "\n",
    "# enter user database to output tables\n",
    "out_db = 'users_selasady'\n",
    "\n",
    "# enter database.name for variant table\n",
    "variant_table = 'p7_platform.brady_variant'\n",
    "\n",
    "# enter database.name for global variants table\n",
    "gvt = 'p7_ref_grch37.global_variants'\n",
    "\n",
    "# enter database.name for coding consequences table\n",
    "coding_table = 'p7_ref_grch37.coding_consequences'\n",
    "\n",
    "# name for output files\n",
    "out_name = 'nbs_' + time.strftime(\"%y%m%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform of NBS Gene Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NBS Gene Table provided by ITMI was transformed as follows and uploaded to impala:   \n",
    "\n",
    "- A 'level' column was added to represent the color coding found in the file, with the following options: red, yellow, null  \n",
    "- All commas were replaced with colons to prevent errors while importing csv file  \n",
    "- All semicolons were replaced with colons for consistency of data  \n",
    "- Spaces in column names were replaced with underscores  \n",
    "- Special characters were removed from column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding positional information to the NBS gene list with UCSC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genomic position, gene and strand were added to the NBS Gene list by joining it with the ucsc_knowngenes table using gene name. \n",
    "\n",
    "        CREATE TABLE acmg_ucsc AS (\n",
    "            SELECT acmg.*, ucsc.chrom, ucsc.txstart, ucsc.txstop\n",
    "            FROM acmg_genes as acmg, ucsc_genes as ucsc\n",
    "            WHERE acmg.gene = ucsc.gene_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to impala with impyla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import needed modules\n",
    "import sys\n",
    "sys.path.append('/Users/selasady/impala_scripts/parse_impala/')\n",
    "from impala.util import as_pandas\n",
    "import pandas as pd\n",
    "from impala.dbapi import connect\n",
    "import parse_module as pi\n",
    "\n",
    "# disable extraneous pandas warning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# to connect to specific database, use the database argument\n",
    "conn=connect(host='glados19', port=21050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate High Risk Variants in NBS Gene Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variants were filtered to include only variants that passed the following parameters: \n",
    "    - fully called genotype\n",
    "    - read depth >= 10\n",
    "    - quality score >= 30\n",
    "    \n",
    "These filtered variants were then joined with the Global Vriants table and Coding Consequences table to filter for variants with the following parameters: \n",
    "    - Marked as clinicall significant in ClinVar\n",
    "    - Or marked as rare in Kaviar with a high impact coding consequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse User Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following argument will be added to the query: \n",
      "\n",
      " AND (bv.sample_id LIKE '%03' OR bv.sample_id LIKE '%01' OR bv.sample_id LIKE '%02')\n"
     ]
    }
   ],
   "source": [
    "# parse trio arg\n",
    "member_arg = pi.label_member('bv', trio_member)\n",
    "\n",
    "# parse sample id argument\n",
    "subject_list = pi.select_samples('bv', sample_list)\n",
    "\n",
    "# list of user args to join\n",
    "arg_list = [subject_list, member_arg]\n",
    "sample_args = pi.join_args(arg_list)\n",
    "\n",
    "print 'The following argument will be added to the query: \\n'\n",
    "print sample_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query variant table on impala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtered variants will be joined with the global variants table and coding consequences table to filter for variants with the following parameters: \n",
    "    - ClinVar significance rating\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbs_vars = '''\n",
    "WITH vars AS (\n",
    "    SELECT bv.sample_id, bv.chrom, nbs.txstart + 1000 as  start_1000, nbs.txstop + 1000 as stop_1000, bv.pos, bv.ref, bv.alt, bv.id as rs_id, bv.qual, bv.filter,\n",
    "        regexp_replace(bv.gt, '1/2', '0/1') as geno, nbs.gene, nbs.condition, nbs.va_name, nbs.inheritance,\n",
    "        nbs.allelic_condition, nbs.in_pgb, nbs.mrna\n",
    "    FROM {} bv, {} nbs\n",
    "    WHERE bv.qual >= 30\n",
    "    AND bv.dp >= 10\n",
    "    AND bv.gt IS NOT NULL\n",
    "    AND bv.chrom = nbs.chrom\n",
    "    AND bv.pos BETWEEN nbs.txstart + 1000 and nbs.txstop + 1000\n",
    "   )\n",
    "    \n",
    "    SELECT vars.*, gv.kav_freq, gv.clin_sig, gv.clin_dbn, gv.rs_id,\n",
    "        gv.dann_score, cd.effect, cd.impact, cd.feature, cd.feature_id, \n",
    "        cd.biotype, cd.rank, cd.hgvs_c, cd.hgvs_p\n",
    "        FROM vars\n",
    "        JOIN {} gv\n",
    "            ON vars.chrom = gv.chrom\n",
    "            AND vars.pos = gv.pos\n",
    "            AND vars.ref = gv.ref\n",
    "            AND vars.alt = gv.alt\n",
    "        JOIN {} cd\n",
    "            ON vars.chrom = cd.chrom\n",
    "            AND vars.pos = cd.pos\n",
    "            AND vars.ref = cd.ref\n",
    "            AND vars.alt = cd.alt  \n",
    "        WHERE (((gv.kav_freq < .01 or gv.kav_freq IS NULL) AND cd.impact = 'HIGH') OR\n",
    "        ((clin.clin_sig NOT REGEXP '3|2[^5]|2$' AND  clin.clin_sig REGEXP '4|[^25]5|^5'))\n",
    "         )\n",
    "'''\n",
    "\n",
    "# run kaviar annotation query\n",
    "nbs_df = run_query(nbs_vars, 'nbs_variants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for proper mode of inheritance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe was separated into mother, father and newborn predictive het variants to search for compound hertozygosity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mom_hets, dad_hets, nb_het1, nb_het2, nb_het3 = pimp.find_AR_cands(nbs_annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Dominant and Homozygous Recessive Disorders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The newborn and parent variants were subset to report:  \n",
    "- All variants in regions of dominant disorders  \n",
    "- All homozygous recessive variants in regions of autosomal recessive disorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_dominant = pimp.find_dominant_nb(nbs_annot)\n",
    "\n",
    "nb_hom_recessive = pimp.find_hom_rec(nbs_annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for compunt heterozygosity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newborn heterozygous variants were subset to look for compound heterozygosity. This analysis was only performed on newborns where both parents were also sequenced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to find matching parent variants\n",
    "def find_parent_vars(nb_df, parent_df):\n",
    "    # merge dataframes on by variant position\n",
    "    merged_df = pd.merge(nb_df, parent_df, on=['chrom', 'pos', 'ref', 'alt'], how='inner')\n",
    "    # rename parent sample_id column to avoid dropping when removing '_y' cols\n",
    "    merged_df.rename(columns = {'member_y':'from_parent'}, inplace=True)\n",
    "    # drop extra y columns from merge with fathers\n",
    "    drop_y(merged_df)\n",
    "    #remove _x from colnames\n",
    "    merged_df.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
    "    return merged_df\n",
    "    \n",
    "# run function for each group of newborns\n",
    "def match_parents(nb_df):\n",
    "    if (len(mom_hets) > 0) and (len(dad_hets) > 0):\n",
    "        nb_and_mom = find_parent_vars(nb_df, mom_hets)\n",
    "        nb_and_dad = find_parent_vars(nb_df, dad_hets)\n",
    "        # merge variants found in either mother or father\n",
    "        het_cands = pd.concat([nb_and_mom,nb_and_dad]).drop_duplicates().reset_index(drop=True)\n",
    "        # group variants by gene name\n",
    "        by_gene = het_cands.groupby(['gene_name', 'family_id'])\n",
    "        return by_gene\n",
    "    else:\n",
    "        print \"No compound het variants\"\n",
    "        \n",
    "# run function for each group of newborns\n",
    "het1_grouped = match_parents(nb_het1)\n",
    "het2_grouped = match_parents(nb_het2)\n",
    "het3_grouped = match_parents(nb_het3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After grouping the variants by gene and family, the variants will be filtered to keep only variants with at least one different variant coming from the mother and one from the father."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to find compound hets\n",
    "def find_comphets(gene_group, comphet_list_name):\n",
    "    for name, group in gene_group:\n",
    "        # if there is a variant in more than one position\n",
    "        if group.pos.nunique() > 1:\n",
    "            # and there are more than one variants from both parents\n",
    "            if len(group[group['from_parent'] == 'M'] > 1) and len(group[group['from_parent'] == 'F'] > 1):\n",
    "                comphet_list_name.append(group)\n",
    "            # or if there is only one variant from each parent\n",
    "            elif len(group[group['from_parent'] == 'M'] == 1) and len(group[group['from_parent'] == 'F'] == 1):\n",
    "                # and those variants are different\n",
    "                if len(group[group['from_parent'] == 'M'].pos - group[group['from_parent'] == 'F']) > 0:\n",
    "                        comphet_list_name.append(group)\n",
    "\n",
    "# create empty list to store comp_hets\n",
    "comp_hets = []\n",
    "\n",
    "het1_df = find_comphets(het1_grouped, comp_hets)     \n",
    "het2_df = find_comphets(het2_grouped, comp_hets)\n",
    "het3_df = find_comphets(het3_grouped, comp_hets)\n",
    "\n",
    "# check if comphets found\n",
    "def comphet_check(df):\n",
    "    if df:\n",
    "        comp_hets.append(df)\n",
    "\n",
    "# check for each nb df\n",
    "comphet_check(het1_df)\n",
    "comphet_check(het2_df)\n",
    "comphet_check(het3_df)\n",
    "\n",
    "# if any comp  hets were found, append to list and convert to df\n",
    "if len(comp_hets) > 0:\n",
    "    comphet_df = pd.concat(comp_hets)\n",
    "    comphet_df.name = 'comp_het'\n",
    "else:\n",
    "    print 'No comp hets found.'\n",
    "    comphet_df = pd.DataFrame()\n",
    "    comphet_df.name = 'comp_het'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_these = []\n",
    "\n",
    "# make sure all dominant variants are inherited as AD\n",
    "if len(nb_dominant[(~nb_dominant['inheritance'].isin(['AD']))]) > 0:\n",
    "     review_these.append(group)\n",
    "\n",
    "# make sure all homozygous recessive are homozygous alt and AR\n",
    "if len(nb_hom_recessive[(~nb_hom_recessive['inheritance'].isin(['AR'])) & (nb_hom_recessive['gt'] != '1/1')]) > 0:\n",
    "    review_these.append(group)\n",
    "\n",
    "# make sure all compound hets are het and AR \n",
    "if len(comphet_df[(~comphet_df['inheritance'].isin(['AR'])) | (comphet_df['gt'] != '0/1')]) > 0:\n",
    "     review_these.append(group)\n",
    "\n",
    "# check that there is more than one variant per gene\n",
    "het_groupy = comphet_df.groupby(['gene'])\n",
    "\n",
    "for name, group in het_groupy:\n",
    "        # check that there is a variant in more than one position\n",
    "        if group.pos.nunique() < 1:\n",
    "            review_these.append(group)\n",
    "        # check that there is at least one variant from the mother\n",
    "        if len(group[group['from_parent'] == 'M']) == 0:\n",
    "            review_these.append(group)\n",
    "        # check that there is at least one variant from the father\n",
    "        if len(group[group['from_parent'] == 'F']) == 0:\n",
    "            review_these.append(group)\n",
    "        # check that there is at least one different variant from each parent\n",
    "        if len(group[(group['from_parent'] == 'M')].pos - group[(group['from_parent'] == 'F')].pos)  == 0:\n",
    "            review_these.append(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(pimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variants found:\n",
      "28 dominant variants found.\n",
      "Condition: \n",
      "Hypothyroidism: congenital: nongoitrous 2    16\n",
      "Pallister-Hall syndrome 2                    12\n",
      "dtype: int64 \n",
      "\n",
      "Affected gene(s): \n",
      "['PAX8' 'GLI2'] \n",
      "\n",
      "580 hom_recessive variants found.\n",
      "Condition: \n",
      "Hyperprolinemia: type I                                         400\n",
      "Severe combined immunodeficiency: autosomal recessive: T-cell negative: B-cell positive: NK cell positive     60\n",
      "Adrenal hyperplasia: congenital: due to 21-hydroxylase deficiency: Hyperandrogenism: nonclassic type: due to 21-hydroxylase deficiency     60\n",
      "Tyrosinemia: type III                                            32\n",
      "Maple syrup urine disease: type II                               18\n",
      "Severe combined immunodeficiency                                 10\n",
      "dtype: int64 \n",
      "\n",
      "Affected gene(s): \n",
      "['IL7R' 'HPD' 'PRODH' 'CYP21A2' 'MTHFD1' 'DBT'] \n",
      "\n",
      "251 comp_het variants found.\n",
      "Condition: \n",
      "Severe combined immunodeficiency: autosomal recessive: T-cell negative: B-cell positive: NK cell positive    90\n",
      "Cystic fibrosis                                                 85\n",
      "Adrenal hyperplasia: congenital: due to 21-hydroxylase deficiency: Hyperandrogenism: nonclassic type: due to 21-hydroxylase deficiency    58\n",
      "LIG4 syndrome: Severe combined immunodeficiency with sensitivity to ionizing radiation    18\n",
      "dtype: int64 \n",
      "\n",
      "Affected gene(s): \n",
      "['CFTR' 'CYP21A2' 'IL7R' 'LIG4'] \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# report variant counts\n",
    "def report_result_counts(results_df):\n",
    "    if len(results_df) > 0:\n",
    "        print str(len(results_df)) + ' {} variants found.'.format(results_df.name)\n",
    "        condition = results_df['condition'].value_counts()\n",
    "        genes = results_df['gene'].unique()\n",
    "        print 'Condition: \\n', condition, '\\n'\n",
    "        print 'Affected gene(s): \\n', genes, '\\n'\n",
    "    else:\n",
    "         print \"No {} variants found. \\n\".format(results_df.name)\n",
    "        \n",
    "print \"Variants found:\"\n",
    "report_result_counts(nb_dominant)\n",
    "report_result_counts(nb_hom_recessive)\n",
    "report_result_counts(comphet_df)\n",
    "print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 28 dominant variants to current working directory\n",
      "Saving 580 hom_recessive variants to current working directory\n",
      "Saving 251 comp_het variants to current working directory\n"
     ]
    }
   ],
   "source": [
    "# add from_parent column to dom and hom_rec so we can keep info for comp_het\n",
    "nb_dominant['from_parent'] = 'NA'\n",
    "nb_hom_recessive['from_parent'] = 'NA'\n",
    "\n",
    "# merge and mark predicted variants\n",
    "def merge_predictors(df, out_list):\n",
    "    if len(df) > 0:\n",
    "        df['var_type'] = df.name\n",
    "        out_list.append(df)\n",
    "        print \"Saving {} {} variants to current working directory\".format(len(df), df.name)\n",
    "    else:\n",
    "        print \"No {} variants to save.\".format(df.name)\n",
    "\n",
    "# list to store patho output\n",
    "predict_list = []            \n",
    "\n",
    "merge_predictors(nb_dominant, predict_list)\n",
    "merge_predictors(nb_hom_recessive, predict_list)\n",
    "merge_predictors(comphet_df, predict_list)\n",
    "\n",
    "# merge results\n",
    "merged_patho = pd.concat(predict_list, axis=0)\n",
    "\n",
    "# put the columns back in order because pandas\n",
    "cols = ['sample_id', 'chrom', 'pos', 'id', 'ref', 'alt', 'gt', 'gene',  'gene_id', 'allele_freq', \n",
    "        'condition','inheritance', 'clin_sig', 'clin_dbn', 'transcript_id', 'strand',   \n",
    "        'impact', 'effect', 'dbnfsp_predicted', 'dann_score', 'cadd_raw', 'qual', 'filter', \n",
    "        'clin_hgvs', 'omim_phenotype', 'va_name', 'allelic_conditions', 'comments', 'level',\n",
    "        'aa_alt', 'sift_score', 'sift_pred', 'polyphen2_hdiv_score', 'polyphen2_hdiv_pred', \n",
    "        'polyphen2_hvar_score', 'polyphen2_hvar_pred', 'fathmm_score', 'fathmm_pred',  \n",
    "        'mutation_taster_pred', 'mutation_assessor_score', 'mutation_assessor_pred', 'provean_score', 'provean_pred', \n",
    "        'interpro_domain', 'exac_af', 'rank', 'hgvs_c', 'hgvs_p', 'from_parent', 'var_type',   \n",
    "        'member','family_id', 'feature_type', 'gene_name','id']\n",
    "\n",
    "merged_out = merged_patho[cols]\n",
    "\n",
    "# remove unnecessary columns\n",
    "merged_out.drop(merged_out.columns[[50, 51, 52, 52,53,54]], axis=1, inplace=True)\n",
    "\n",
    "# save to file\n",
    "merged_out.to_csv('predicted_NBS_{}.tsv'.format(time.strftime(\"%y%m%d\")), sep= '\\t', header=True, encoding='utf-8', \\\n",
    "                                                                                                    index=False)\n",
    "\n",
    "if len(review_these) > 0:\n",
    "    print 'Some variants were flagged for review and saved to nbs_{)_review.tsv'.format(time.strftime(\"%y%m%d\"))\n",
    "    for_review = pd.DataFrame(review_these)\n",
    "    for_review.to_csv('nbs_{)_review.tsv'.format(time.strftime(\"%y%m%d\")), sep='\\t', header=True, encoding='utf-8', \n",
    "                                                 index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- make package\n",
    "- change location of tab2vcf.py function according to location in package\n",
    "- report only nb vars\n",
    "- mark with variant type\n",
    "- why is sample id _22 showing up? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
