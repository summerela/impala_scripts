{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 1,
     "source": [
      "NBS Gene Annotation"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Purpose"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the following newborns:   \n",
      "\n",
      "102-07005-03  \n",
      "102-00997-03  \n",
      "102-00996-03  \n",
      "102-02001-03  \n",
      "102-00961-03  \n",
      "102-07009-03  \n",
      "102-00932-03  \n",
      "102-00979-03  \n",
      "102-01532-03  \n",
      "102-00974-03  \n",
      "\n",
      "Variants were annotated with the NBS gene table provided by Ben Solomon at ITMI. Variants located in NBS gene regions were filtered, keeping only variants with a Kaviar frequency less than 1%. Candidate variants were then annotated with ClinVar, DANN scores for SNV's and coding consequence predictions. Results were reported for Dominant, homozygous recessive and compound heterozygotes. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Transform of NBS Gene Table"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The NBS Gene Table provided by ITMI was transformed as follows and uploaded to impala:   \n",
      "\n",
      "- A 'level' column was added to represent the color coding found in the file, with the following options: red, yellow, null  \n",
      "- All commas were replaced with colons to prevent errors while importing csv file  \n",
      "- All semicolons were replaced with colons for consistency of data  \n",
      "- Spaces in column names were replaced with underscores  \n",
      "- Special characters were removed from column names"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding positional information to the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Chromosome, start and stop positions were added to the NBS Gene list by joining it with the \n",
      "ensembl_genes table using gene name. This resulted in mulitple listings per gene for each exon, \n",
      "allowing for more precise matches. \n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_ensembl AS \n",
      "            SELECT DISTINCT nbs.gene, nbs.entrez_gene_id as entrez_id, ens.gene_id AS ensembl_id, \n",
      "                ens.chromosome as chrom, ens.start, ens.stop, nbs.condition, nbs.omim_phenotype, \n",
      "                nbs.va_name, nbs.inheritance, nbs.allelic_condition, nbs.in_pgb, nbs.level, ens.feature, \n",
      "                ens.transcript_name, ens.transcript_id, ens.exon_number, ens.exon_id, ens.gene_biotype, nbs.comments\n",
      "            FROM users_selasady.nbs_genes nbs\n",
      "            LEFT JOIN\n",
      "                public_hg19.ensembl_genes ens\n",
      "                ON nbs.gene = ens.gene_name\n",
      "\n",
      "The results were saved as users _ selasady.nbs _ ensembl containing 20872 rows. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding rare variants with Kaviar"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For all trio members in the family's listed above, variants were filtered using Kaviar to retain only variants with a Kaviar frequency of less than .01, or variants not listed in Kaviar at all. The rare variants were then joined with the nbs_ensembl table to locate rare variants falling in NBS gene regions.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "     CREATE TABLE nbs_kaviar AS          \n",
      "          WITH bv as (\n",
      "              SELECT bv.sample_id, bv.chr as chrom, bv.pos, bv.id, bv.ref, \n",
      "                  bv.alt, bv.qual, bv.filter, bv.gt, k.alle_freq\n",
      "             FROM p7_platform.brady_variant bv\n",
      "             LEFT JOIN /* +SHUFFLE */ public_hg19.kaviar k\n",
      "                  ON bv.chr = k.chromosome\n",
      "                  AND bv.pos = k.pos\n",
      "                  AND bv.ref = k.ref\n",
      "                  AND bv.alt = k.alt\n",
      "             WHERE (k.alle_freq < .01 OR k.alle_freq IS NULL)\n",
      "            AND (bv.sample_id LIKE '%03' OR bv.sample_id LIKE '%02' OR bv.sample_id LIKE '%01')\n",
      "         )\n",
      "        SELECT bv.*, nbs.gene, nbs.entrez_id, nbs.ensembl_id, nbs.condition, \n",
      "            nbs.omim_phenotype, nbs.va_name, nbs.inheritance, nbs.allelic_condition,nbs.in_pgb, \n",
      "            nbs.level, nbs.feature, nbs.transcript_name, nbs.transcript_id, nbs.exon_number, \n",
      "            nbs.exon_id, nbs.gene_biotype, nbs.comments          \n",
      "        FROM bv, users_selasady.nbs_ensembl nbs\n",
      "       WHERE bv.chrom = nbs.chrom\n",
      "       AND bv.pos BETWEEN nbs.start and nbs.stop\n",
      "\n",
      "This table was saved as users _ selasady.nbs _ kaviar with 6760 rows at kav freq of .01.  \n",
      "This table was saved as users _ selasady.nbs _ kaviar with 9394 rows at kav freq of .03.  "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Annotating with ClinVar and DANN scores "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Rare variants were annotated with the ClinVar table using genomic position. Variants with a ClinVar significance rating of 4 or 5, but never 2 or 3, were marked with a 'Y' in the clin_patho column to denote non-conflicted pathogenically significant ratings.\n",
      "\n",
      "DANN scores whole-genome variants by training a deep neural network (DNN). DNNs can capture non-linear relationships among features, and are better suited than SVMs for problems with a large number of samples and features. DANN scores have been shown to outperform both CADD and FATHMM (http://www.enlis.com/blog/2015/03/17/the-best-variant-prediction-method-that-no-one-is-using/).\n",
      "\n",
      "DANN scores are provided for SNV's and range between 0 and 1. The closer a score is to 1, the more pathogenic the variant. \n",
      "\n",
      "The following query was used to annotate the nbs variants with DANN scores by matching on chromosome and position, then outputting the score for the alt allele. \n",
      "\n",
      "        CREATE TABLE nbs_annotated AS \n",
      "        WITH n as (\n",
      "            SELECT nbs.*, clin.clin_hgvs, clin.clin_sig, clin.clin_dbn, clin.clin_acc,\n",
      "                CASE WHEN (clin.clin_sig NOT REGEXP '3|2[^5]|2 (replace this text with a dollar sign)'  \n",
      "                    AND  clin.clin_sig REGEXP '4|[^25]5|^5') THEN 'Y'\n",
      "                    ELSE 'N'\n",
      "                END AS clin_patho\n",
      "            FROM users_selasady.nbs_kaviar nbs\n",
      "            LEFT JOIN public_hg19.clinvar clin\n",
      "                ON nbs.chrom = clin.chrom\n",
      "                AND nbs.pos = clin.pos\n",
      "                AND nbs.ref = clin.ref\n",
      "                AND nbs.alt = clin.alt\n",
      "         )\n",
      "        SELECT n.*, \n",
      "            CASE WHEN n.alt = 'A' THEN CAST(d.score_a as STRING)\n",
      "                WHEN n.alt = 'T' THEN CAST(d.score_t as STRING)\n",
      "                WHEN n.alt = 'G' THEN CAST(d.score_g as STRING)\n",
      "                WHEN n.alt = 'C' THEN CAST(d.score_c as STRING)\n",
      "                ELSE 'indel'\n",
      "             END as dann_score, \n",
      "             CASE\n",
      "                 WHEN SUBSTRING(n.sample_id, -2) = '01'THEN 'M'\n",
      "                 WHEN SUBSTRING(n.sample_id, -2) = '02' THEN 'F'\n",
      "                 WHEN SUBSTRING(n.sample_id, -2) = '03'THEN 'NB'\n",
      "             END as member,\n",
      "             SUBSTRING(n.sample_id, 1, (length(n.sample_id)-3)) as family_id,\n",
      "             CONCAT(n.chrom, ':', CAST(n.pos AS STRING), ':', n.ref, ':', n.alt, ':', SUBSTRING(n.sample_id, 1, (length(n.sample_id)-3))) as var_id\n",
      "        FROM n\n",
      "        LEFT JOIN public_hg19.DANN d\n",
      "            ON n.chrom = d.chrom\n",
      "            AND n.pos = d.pos\n",
      "\n",
      "This table was saves as users _ selasady.nbs _ annotated with 6,760 rows. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reading the impala results into python"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "#################\n",
      "# load modules  #\n",
      "#################\n",
      "import pandas as pd\n",
      "from impala.dbapi import connect\n",
      "from impala.util import as_pandas\n",
      "\n",
      "# create database connection\n",
      "conn = connect(host='glados19', port=21050)\n",
      "cur = conn.cursor()\n",
      "\n",
      "# query to left join nbs_annotated variants with DANN scores\n",
      "query = \"\"\"\n",
      "    SELECT * FROM users_selasady.nbs_annotated\n",
      "    \"\"\"\n",
      "# run query on impala\n",
      "cur.execute(query)\n",
      "\n",
      "# store results as pandas data frame\n",
      "nbs_df = as_pandas(cur)"
     ],
     "language": "python",
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding Functional Annotation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn set was output to a modified version of Plink's tab2vcf script to create a VCF file for use with SnpEff. The newborn variants in the VCF file were annotated with coding consequences using SnpEff version 4.1h (build 2015-08-03) with GRCh37.75. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import subprocess as subp\n",
      "import os\n",
      "\n",
      "# enter path to snpEff.jar on your computer\n",
      "# windows\n",
      "#snpeff_path = 'D:/Documents/tools/snpEff/snpEff.jar'\n",
      "# mac\n",
      "snpeff_path = '/Users/summerrae/tools/snpEff/snpEff.jar'\n",
      "\n",
      "# enter basename for output files\n",
      "out_name = 'nbs_genes'\n",
      "\n",
      "# function to add functional annotation\n",
      "def df_to_snpeff(input_df):\n",
      "    if os.path.exists(snpeff_path):\n",
      "        # setup file names\n",
      "        tsv_outname = '{}.tsv'.format(os.path.join(os.getcwd(), out_name))\n",
      "        vcf_outname = '{}.vcf'.format(os.path.join(os.getcwd(), out_name))\n",
      "        # subset columns to output to vcf file\n",
      "        df = input_df[['chrom', 'pos', 'ref', 'alt']]\n",
      "        # write to file for conversion to vcf\n",
      "        df.to_csv(tsv_outname, header=True, encoding='utf-8', sep=\"\\t\", index=False)\n",
      "        # run tab2vcf and upon success, run snpeff\n",
      "        vcf_process = subp.Popen(['python', 'tab2vcf.py', tsv_outname])\n",
      "        vcf_process.wait()\n",
      "        # command to run snpeff\n",
      "        snpeeff_cmd = 'java -Xmx4g -jar {} -v GRCh37.75 {} > nbs_snpeff.vcf'.format(snpeff_path, vcf_outname)\n",
      "        # run snpeff on vcf file\n",
      "        snpeff_process = subp.Popen(snpeeff_cmd, shell=True)\n",
      "        snpeff_process.wait()\n",
      "    else:\n",
      "        print \"Make sure you entered the correct path to snpEff.jar\"\n",
      "\n",
      "# run function on query results\n",
      "try:\n",
      "    df_to_snpeff(nbs_df)\n",
      "except Exception, e: \n",
      "    print str(e)"
     ],
     "language": "python",
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The functional annotations were read back into Python, parsed and matched with the each respective variant data frame. \n",
      "\n",
      "Annotated variants were then labled as pathogenic if they predicted a newborn to have an NBS conddition based on the following parameters:   \n",
      "\n",
      "- Presence of mutation(s) with appropriate inheritance (eg, 2 bi-allelic pathogenic mutations for a recessive disorder).  \n",
      "- Mutations are defined strictly as either:   \n",
      "        - Annotated in ClinVar with a clinical significance of 4 or 5, but never 2 or 3 or labeled pathogenic in HGMD (to be added later) OR  \n",
      "        - Novel but predicted to be disease-causing (ie, a stop-gain, stop-loss, splice-site, whole-exon or larger deletion, or frameshift)  OR  \n",
      "        - Have DANN scores higher than 0.89\n",
      "\n",
      "This output will be used downstream to output a list of high priority variants for examination. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import numpy as np\n",
      "\n",
      "# add snpeff annotations back to dataframe\n",
      "def parse_snpeff(input_df):\n",
      "    # merge snpeff annotated vcf file with dataframe , skipping header\n",
      "    annot_vcf = pd.read_csv('nbs_snpeff.vcf', sep='\\t', skiprows=8)\n",
      "    # split info columns by \"|\" \n",
      "    info_df = pd.DataFrame(list(annot_vcf['INFO'].str.split('|')))\n",
      "    # keep only first (most detrimenatl) consequence listed\n",
      "    info_df = info_df[list(info_df.columns[1:11])]\n",
      "    # merge truncated info field with annot_vcf\n",
      "    annot_vcf = annot_vcf[np.r_[0:2, 3, 4]]\n",
      "    annot_df = pd.concat([annot_vcf, info_df], axis=1)\n",
      "    # remove duplicated rows\n",
      "    annot_df.drop_duplicates(inplace=True)\n",
      "    # rename columns\n",
      "    annot_df.columns =['chrom', 'pos', 'ref', 'alt', 'effect', 'impact', 'gene_name', 'gene_id', 'feature_type', \\\n",
      "        'feature_id', 'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']\n",
      "    # merge annotations with variant table\n",
      "    df_functional = pd.merge(input_df, annot_df, on=['chrom', 'pos', 'ref', 'alt'], how='left')\n",
      "    # drop columns with duplicated info after merge\n",
      "    df_functional.drop(['gene_name', 'gene_id', 'feature_id', 'feature_type', 'rank'], axis=1, inplace=True)\n",
      "    return df_functional\n",
      "    \n",
      "# merge nbs_genes with functional annotations\n",
      "nbs_annot = parse_snpeff(nbs_df)\n",
      "\n",
      "# label variants considered pathogenic \n",
      "nbs_annot['pathogenic'] = (nbs_annot['impact'] == 'HIGH') | (nbs_annot['clin_patho'] == 'Y' )| (nbs_annot['dann_score'] > 0.99)\n",
      "#nbs_annot['pathogenic'] = (nbs_annot['impact'] == 'HIGH') | (nbs_annot['clin_patho'] == 'Y' )"
     ],
     "language": "python",
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataframe was separated into mother, father and newborn for downstream analysis. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of newborn variants: 3279\nNumber of mother variants: 3220\nNumber of father variants: 2895\n"
       ]
      }
     ],
     "input": [
      "# subset data frame by trio member\n",
      "newborns = nbs_annot[nbs_annot['member'] == 'NB']\n",
      "mothers = nbs_annot[nbs_annot['member'] == 'M']\n",
      "fathers = nbs_annot[nbs_annot['member'] == 'F']\n",
      "\n",
      "print \"Number of newborn variants: \" + str(len(newborns)) \n",
      "print \"Number of mother variants: \" + str(len(mothers)) \n",
      "print \"Number of father variants: \" + str(len(fathers))"
     ],
     "language": "python",
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn subset was split to report:   \n",
      "- All variants in regions of dominant disorders  \n",
      "- All homozygous recessive variants in regions of autosomal recessive disorders  \n",
      "- All heterozygous variants in autosomal recessive regions for downstream analysis of compound heterozygosity  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# disable erroneous pandas warning\n",
      "pd.options.mode.chained_assignment = None\n",
      "\n",
      "# subset newborns by variant MOI and/or zygosity\n",
      "nb_dominant = newborns[(newborns['inheritance'] == 'AD')]\n",
      "nb_dominant.name = 'dominant'\n",
      "nb_hom_recessive = newborns[((newborns['inheritance'] == 'AR') & (newborns['gt'] == '1/1'))]\n",
      "nb_hom_recessive.name = 'hom_recessive'\n",
      "nb_het = newborns[((newborns['inheritance'] == 'AR') & (newborns['gt'] == '0/1'))]"
     ],
     "language": "python",
     "prompt_number": 59
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reporting compound heterozygous recessive variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Heterozygous variants in autosomal recessive regions were examined for compound heterozygosity, as follows:   \n",
      "- Newborns must inherit at least one variant from each parent, at different positions on the same gene  \n",
      "- Parents must be heterozygous for the matching variant  \n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# keep only heterozygous variants, as homozygous parents are not of interest\n",
      "mom_het = mothers.loc[mothers['gt'] == '0/1']\n",
      "dad_het = fathers.loc[fathers['gt'] == '0/1']\n",
      "\n",
      "# function to drop extra columns ending in _y from df merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "            \n",
      "# function to find matching parent variants\n",
      "def find_parent_vars(nb_df, parent_df):\n",
      "    # merge dataframes on variant id\n",
      "    merged_df = pd.merge(nb_df, parent_df, on=['var_id'], how='inner')\n",
      "    # rename parent sample_id column to avoid dropping when removing '_y' cols\n",
      "    merged_df.rename(columns = {'member_y':'from_parent'}, inplace=True)\n",
      "    # drop extra y columns from merge with fathers\n",
      "    drop_y(merged_df)\n",
      "    #remove _x from colnames\n",
      "    merged_df.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "    return merged_df\n",
      "    \n",
      "# run function for each parent set\n",
      "if (len(mom_het) > 0) and (len(dad_het) > 0):\n",
      "    nb_and_mom = find_parent_vars(nb_het, mom_het)\n",
      "    nb_and_dad = find_parent_vars(nb_het, dad_het)\n",
      "else:\n",
      "    print \"No compound het variants\""
     ],
     "language": "python",
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After creating data frames for variants that have a pathogenic variant from either the mother or father, these variants are grouped by gene to search for regions with variants at more than one position. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "if (len(nb_and_mom) > 0) and (len(nb_and_dad) > 0):\n",
      "    # merge variants found in either mother or father\n",
      "    het_cands = pd.concat([nb_and_mom,nb_and_dad]).drop_duplicates().reset_index(drop=True)\n",
      "    # group variants by gene name\n",
      "    by_gene = het_cands.groupby(['gene', 'family_id'])\n",
      "else:\n",
      "    print \"No compound het variants found.\""
     ],
     "language": "python",
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After grouping the variants by gene, the variants will be filtered to keep only variants with at least one different variant coming from the mother and one from the father.  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# function to find compound hets\n",
      "def find_comphets(gene_group, comphet_list_name):\n",
      "    for name, group in gene_group:\n",
      "        # if there is a variant in more than one position\n",
      "        if group.pos.nunique() > 1:\n",
      "            # and there are more than one variants from both parents\n",
      "            if len(group[group['from_parent'] == 'M'] > 1) and len(group[group['from_parent'] == 'F'] > 1):\n",
      "                comphet_list_name.append(group)\n",
      "            # or if there is a variant from both parents\n",
      "            elif len(group[group['from_parent'] == 'M'] == 1) and len(group[group['from_parent'] == 'F'] == 1):\n",
      "                # and those variants are different\n",
      "                if len(group[group['from_parent'] == 'M'].pos - group[group['from_parent'] == 'F']) > 0:\n",
      "                        comphet_list_name.append(group)\n",
      "\n",
      "# create empty list to store comp_hets\n",
      "comp_hets = []\n",
      "\n",
      "if len(by_gene) > 0:\n",
      "    # run function on by_gene\n",
      "    find_comphets(by_gene, comp_hets)\n",
      "    # combine results into dataframe\n",
      "    comphet_df = pd.concat(comp_hets)\n",
      "    comphet_df.name = 'comp_het'\n",
      "else:\n",
      "    print 'No compound het variants found.'\n",
      "    comphet_df = pd.DataFrame()\n",
      "    comphet_df.name = 'comp_het'"
     ],
     "language": "python",
     "prompt_number": 62
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding newborns predicted to have NBS conditions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dominant, homozgous recessive and compound heterozygous recessive candidate variants were filtered to retain newborns predicted to have NBS conditions:     \n",
      "\n",
      "- Presence of mutation(s) with appropriate inheritance using filtering procedures outlined above   \n",
      "- Mutations defined strictly as either:   \n",
      "    - Clearly annotated in ClinVar, HGMD or both, as pathogenic or disease-causing for the NBS condition   \n",
      "     OR  \n",
      "    - Novel but predicted to be disease-causing (ie, a rating of 'HIGH' from SnpEff impact score)  \n",
      "- Additionally, compound heterozygous variants will be filtered to include only mutations where both variants inherited from the parent are pathogenic  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# return only variants that are pathogenic\n",
      "nb_dom_patho= pd.DataFrame(nb_dominant.loc[nb_dominant['pathogenic'] == True])\n",
      "nb_dom_patho.name = 'dominant'\n",
      "nb_hom_rec_patho = pd.DataFrame(nb_hom_recessive.loc[nb_hom_recessive['pathogenic'] == True])\n",
      "nb_hom_rec_patho.name = 'hom_rec'\n",
      "\n",
      "###############################################################\n",
      "## find comp_het variants where both variants are pathogenic ##\n",
      "###############################################################\n",
      "if len(comphet_df) > 0:\n",
      "    # group comp_hets by gene and family id\n",
      "    patho_by_gene = comphet_df.groupby(['gene', 'family_id'])\n",
      "    # create list to store results\n",
      "    patho_comphet = []\n",
      "    # search within each gene and family:\n",
      "    for name, group in patho_by_gene:\n",
      "        # if there are pathogenic genes at more than one position\n",
      "        if (group[(group['pathogenic'] == True)].pos.nunique() > 1):\n",
      "            # append to patho_comphet\n",
      "            patho_comphet.append(group)\n",
      "            # transform results into dataframe and name it\n",
      "            patho_comphet_df = pd.concat(patho_comphet)\n",
      "            patho_comphet_df.name = 'comp_het'\n",
      "        else:\n",
      "             patho_comphet_df = pd.DataFrame()\n",
      "             patho_comphet_df.name = 'comp_het'\n",
      "else:\n",
      "    patho_comphet_df = pd.DataFrame()\n",
      "    patho_comphet_df.name = 'comp_het'"
     ],
     "language": "python",
     "prompt_number": 63
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Results"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "print nb_dom_patho['dann_score']"
     ],
     "language": "python",
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variants found:\n124 dominant variants found.\n293 hom_recessive variants found.\n529 comp_het variants found.\n\n\nOf those variants, the following were predicted to cause NBS disorders:\n115 dominant variants found.\n216 hom_rec variants found.\n507 comp_het variants found.\n\ndominant:  \n\nImpact: \nMODIFIER    48\nMODERATE    35\nLOW         32\ndtype: int64 \n\nEffect: \n3_prime_UTR_variant                               43\nmissense_variant                                  35\nsynonymous_variant                                31\ndownstream_gene_variant                            2\n5_prime_UTR_variant                                2\n5_prime_UTR_premature_start_codon_gain_variant     1\nupstream_gene_variant                              1\ndtype: int64 \n\nCondition: \nHypothyroidism: congenital: nongoitrous 2                       42\nChoreoathetosis: hypothyroidism: and neonatal respiratory distress    36\nPallister-Hall syndrome 2                                       33\nHypothyroidism: congenital nongoitrous: 5                        4\ndtype: int64 \n\nAffected gene(s): \n['PAX8' 'GLI2' 'NKX2-1' 'NKX2-5'] \n\n\nhom_rec:  \n\nImpact: \nMODIFIER    95\nLOW         66\nMODERATE    55\ndtype: int64 \n\nEffect: \nmissense_variant           55\n3_prime_UTR_variant        44\nTF_binding_site_variant    36\nsynonymous_variant         19\ndownstream_gene_variant    15\n5_prime_UTR_variant        15\nintron_variant             13\nsequence_feature            9\nupstream_gene_variant       6\nnon_coding_exon_variant     2\nsplice_region_variant       2\ndtype: int64 \n\nCondition: \nAcyl-CoA dehydrogenase: very long chain: deficiency of          36\n  Mucopolysaccharidosis: type Ih (Hurler syndrome)              33\nAcyl-CoA dehydrogenase: medium chain: deficiency of             15\nSevere combined immunodeficiency                                14\nMethylmalonic acidemia: cblG type                               12\nPhenylketonuria: Hyperphenylalaninemia: non-PKU mild            10\nHyperprolinemia: type I                                         10\nMitochondrial DNA depletion syndrome 9 (encephalomyopathic type with methylmalonic aciduria)     9\nCombined malonic and methylmalonic aciduria                      8\nHypothyroidism: congenital: nongoitrous: 1                       6\nMaple syrup urine disease: type II                               5\nCystinosis (multiple types)                                      5\nAlpha-methylacetoacetic aciduria                                 5\nTranscobalamin II deficiency                                     4\nMultiple acyl-CoA dehydrogenase deficiency: Glutaric aciduria IIA     4\nMucopolysaccharidosis: type VII (Sly syndrome)                   4\nGalactosemia                                                     4\nBamforth-Lazarus syndrome                                        4\nThyroid dyshormonogenesis 3                                      4\nDiabetes mellitus: neonatal: with congenital hypothyroidism      3\nKrabbe disease                                                   3\nImmunodeficiency due to purine nucleoside phosphorylase deficiency     3\nEthylmalonic encephalopathy                                      2\nMethylmalonic acidemia: cblB type                                2\n3-beta-hydroxysteroid dehydrogenase: type II: deficiency         2\nNiemann-Pick disease: type C1: Niemann-Pick disease: type D      2\nHomocystinuria                                                   2\nT cell-negative: B cell-negative: natural killer cell-positive severe combined immunodeficiency: Omenn syndrome: Alpha/beta T-cell lymphopenia with gamma/delta T-cell expansion: severe cytomegalovirus infection: and autoimmunity: Combined cellular and humoral immune defects with granulomas     1\nGlycine encephalopathy                                           1\nGalactose epimerase deficiency                                   1\nMucopolysaccharidosis: type VI (Maroteaux-Lamy syndrome)         1\nSevere combined immunodeficiency due to adenosine deaminase deficiency     1\ndtype: int64 \n\nAffected gene(s): \n['PRODH' 'ACSF3' 'DBT' 'MTR' 'PNP' 'TCN2' 'FOXE1' 'MMAB' 'GALC' 'ADA'\n 'ACADM' 'TG' 'HSD3B2' 'ACAT1' 'MTHFR' 'ETHE1' 'ACADVL' 'MTHFD1' 'GUSB'\n 'GALE' 'PAH' 'TSHR' 'GLIS3' 'RAG1' 'GLDC' 'CTNS' 'GALT' 'ETFA' 'ARSB'\n 'SUCLG1' 'IDUA' 'NPC1'] \n\n\ncomp_het:  \n\nImpact: \nMODERATE    191\nMODIFIER    178\nLOW         138\ndtype: int64 \n\nEffect: \nmissense_variant                            191\n3_prime_UTR_variant                          94\nsynonymous_variant                           72\nsequence_feature                             54\n5_prime_UTR_variant                          50\ndownstream_gene_variant                      16\nsplice_region_variant&synonymous_variant     10\nupstream_gene_variant                        10\nintron_variant                                7\nsplice_region_variant                         2\nnon_coding_exon_variant                       1\ndtype: int64 \n\nCondition: \n  Mucopolysaccharidosis: type Ih (Hurler syndrome)              46\nMultiple acyl-CoA dehydrogenase deficiency: Glutaric aciduria IIB    38\nCombined malonic and methylmalonic aciduria                     34\nHyperprolinemia: type I                                         34\nGlycine encephalopathy                                          29\nIsobutyryl-CoA dehydrogenase deficiency                         23\nTyrosinemia: type I                                             21\nAlpha-1-antitrypsin deficiency                                  19\nMethylmalonic acidemia: cblG type                               19\nOmenn syndrome: Severe combined immunodeficiency with sensitivity to ionizing radiation    18\nAcyl-CoA dehydrogenase: short-chain: deficiency of              17\nProlidase deficiency                                            17\nAdrenal hyperplasia: congenital: due to 21-hydroxylase deficiency: Hyperandrogenism: nonclassic type: due to 21-hydroxylase deficiency    16\nHistidinemia                                                    15\nCystic fibrosis                                                 14\nMaple syrup urine disease: mild variant                         13\nHolocarboxylase synthetase deficiency                           11\nSevere combined immunodeficiency                                11\nHomocystinuria due to cystathionine beta-synthase deficiency    10\nCarbamoylphosphate synthetase I deficiency                      10\nTranscobalamin II deficiency                                     9\nMaple syrup urine disease: type II                               9\nAcyl-CoA dehydrogenase family: member 9: deficiency of           9\nPhenylketonuria: Hyperphenylalaninemia: non-PKU mild             8\nMucopolysaccharidosis: type VII (Sly syndrome)                   7\nNiemann-Pick disease: type C1: Niemann-Pick disease: type D      7\nCystinosis (multiple types)                                      7\nHomocystinuria-megaloblastic anemia: cobalamin E type            6\nBamforth-Lazarus syndrome                                        5\nDiabetes mellitus: neonatal: with congenital hypothyroidism      5\nThyroid dyshormonogenesis 4                                      5\nGalactose epimerase deficiency                                   5\nPropionic acidemia                                               4\n2-methylbutyryl-CoA dehydrogenase deficiency                     2\nAlpha-methylacetoacetic aciduria                                 2\nLipoid adrenal hyperplasi                                        2\ndtype: int64 \n\nAffected gene(s): \n['ACAD8' 'ACAD9' 'ACADS' 'ACADSB' 'ACAT1' 'ACSF3' 'AMT' 'CBS' 'CFTR' 'CPS1'\n 'CTNS' 'CYP21A2' 'DBT' 'DCLRE1C' 'ETFB' 'FAH' 'FOXE1' 'GALE' 'GLIS3'\n 'GUSB' 'HAL' 'HLCS' 'IDUA' 'IYD' 'MTHFD1' 'MTR' 'MTRR' 'NPC1' 'PAH' 'PCCB'\n 'PEPD' 'PPM1K' 'PRODH' 'SERPINA1' 'STAR' 'TCN2'] \n\n"
       ]
      }
     ],
     "input": [
      "# report variant counts\n",
      "def report_result_counts(results_df):\n",
      "    if len(results_df) > 0:\n",
      "        print str(len(results_df)) + ' {} variants found.'.format(results_df.name)\n",
      "    else:\n",
      "         print \"No {} variants found.\".format(results_df.name)\n",
      "        \n",
      "print \"Variants found:\"\n",
      "report_result_counts(nb_dominant)\n",
      "report_result_counts(nb_hom_recessive)\n",
      "report_result_counts(comphet_df)\n",
      "print \"\\n\"\n",
      "\n",
      "print \"Of those variants, the following were predicted to cause NBS disorders:\"        \n",
      "report_result_counts(nb_dom_patho)\n",
      "report_result_counts(nb_hom_rec_patho)\n",
      "report_result_counts(patho_comphet_df)\n",
      "\n",
      "def summarize(df):\n",
      "    if len(df) > 0:\n",
      "        print '\\n' + df.name + ': ', '\\n'\n",
      "        impact = df['impact'].value_counts()\n",
      "        effect = df['effect'].value_counts()\n",
      "        condition = df['condition'].value_counts()\n",
      "        genes = df['gene'].unique()\n",
      "        print 'Impact: \\n', impact, '\\n'\n",
      "        print 'Effect: \\n', effect, '\\n'\n",
      "        print 'Condition: \\n', condition, '\\n'\n",
      "        print 'Affected gene(s): \\n', genes, '\\n'\n",
      "\n",
      "summarize(nb_dom_patho)\n",
      "summarize(nb_hom_rec_patho)\n",
      "summarize(patho_comphet_df)"
     ],
     "language": "python",
     "prompt_number": 64
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Saving Output"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving 529 comp_het variants to current working directory\nSaving 124 dominant variants to current working directory"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\nSaving 293 hom_recessive variants to current working directory\nNo dominant variants to save."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\nNo hom_rec variants to save.\nNo comp_het variants to save.\n"
       ]
      }
     ],
     "input": [
      "# save output to current working directory\n",
      "def save_results(df):\n",
      "    if len(df) > 0:\n",
      "        print \"Saving {} {} variants to current working directory\".format(len(df), df.name)\n",
      "        df.to_csv('{}.csv'.format(df.name), header=True, encoding='utf-8', index=False)\n",
      "        \n",
      "# save unfiltered variants to file\n",
      "save_results(comphet_df)\n",
      "save_results(nb_dominant)\n",
      "save_results(nb_hom_recessive)\n",
      "\n",
      "# merge and mark predicted variants\n",
      "def merge_predictors(df, out_list):\n",
      "    if len(df) > 0:\n",
      "        df['var_type'] = df.name\n",
      "        out_list.append(df)\n",
      "        merged_patho_df = pd.concat(out_list)\n",
      "        merged_patho_df.to_csv('predicted_NBS.csv', header=True, encoding='utf-8', index=False)\n",
      "    else:\n",
      "        print \"No {} variants to save.\".format(df.name)\n",
      "\n",
      "# list to store patho output\n",
      "predict_list = []            \n",
      "\n",
      "patho_list = [nb_dom_patho, nb_hom_rec_patho, patho_comphet_df]\n",
      "\n",
      "for df in patho_list:\n",
      "    merge_predictors(df, predict_list)"
     ],
     "language": "python",
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "115\n"
       ]
      }
     ],
     "input": [
      "print len(nb_dom_patho)"
     ],
     "language": "python",
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0
}