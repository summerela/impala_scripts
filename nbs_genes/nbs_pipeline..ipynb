{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 1,
     "source": [
      "Locating Variants in NBS Gene Regions"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "html": [
        "<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>"
       ],
       "metadata": {}
      },
      {
       "output_type": "pyout",
       "html": [
        "<button onclick=\"jQuery('.input_area').toggle(); jQuery('.prompt').toggle();\">Toggle code</button>"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "import IPython.core.display as di\n",
      "\n",
      "# This line will hide code by default when the notebook is exported as HTML\n",
      "di.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)\n",
      "\n",
      "# This line will add a button to toggle visibility of code blocks, for use with the HTML export version\n",
      "di.display_html('''<button onclick=\"jQuery('.input_area').toggle(); jQuery('.prompt').toggle();\">Toggle code</button>''', raw=True)"
     ],
     "language": "python",
     "prompt_number": 156
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variants were annotated with the NBS gene table provided by Ben Solomon at ITMI. Variants located in NBS gene regions were annotated with Kaviar frequency, ClinVar clinical significance ratings, DANN predicted pathogenicity scores for SNV's, and coding consequence predictions using SnpEff.\n",
      "\n",
      "Variants were filtered for appropriate mode of inheritance and then labeled as predictive when they contain the presence of mutation(s) with appropriate inheritance (eg, 2 bi-allelic pathogenic mutations for a recessive disorder).  \n",
      "\n",
      "Mutations defined strictly as either:  \n",
      "- Annotated in ClinVar with a clinical significance of 4 or 5, but never 2 or 3 or labeled pathogenic in HGMD (to be added later)  \n",
      "\n",
      "OR  \n",
      "- Novel (in Kaviar with frequency lower than specified below, or not listed in Kaviar) but predicted to be disease-causing with a SnpEff impact score of 'high', or a pathogenic rating in one of the dbNFSP predictive measurements"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "User Specified Parameters"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import time\n",
      "# enter kaviar frequency threshold\n",
      "kav_freq = '.03'\n",
      "\n",
      "# enter dictionary of samples to examine in format 'sample_id':['family_id','member_id']\n",
      "sample_list = 'all'\n",
      "\n",
      "# enter as NB, M, and/or F, or 'all' to include extended family if available\n",
      "trio_member = 'NB','M','F'\n",
      "\n",
      "# enter minimum dann score for predicted NBS\n",
      "dann_score = '0.96'\n",
      "\n",
      "# enter user database to output tables\n",
      "out_db = 'users_selasady'\n",
      "# enter database.name for variant table\n",
      "variant_table = 'p7_platform.brady_variant'\n",
      "# enter database.name of kaviar table\n",
      "kaviar_table = 'p7_ref_grch37.kaviar'\n",
      "# enter database.name of clinvar table\n",
      "clinvar_table = 'p7_ref_grch37.clinvar'\n",
      "# enter database.name of dann table\n",
      "dbnfsp_table = 'p7_ref_grch37.dbnsfp_variant'\n",
      "\n",
      "# enter path to snpEff.jar on your computer\n",
      "#snpeff_path = '/Users/summerrae/tools/snpEff/snpEff.jar'\n",
      "snpeff_path = 'D:/Documents/tools/snpEff/snpEff.jar'\n",
      "# enter desired basename for output files\n",
      "out_name = 'nbs_' + time.strftime(\"%y%m%d\")"
     ],
     "language": "python",
     "prompt_number": 157
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Transform of NBS Gene Table"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The NBS Gene Table provided by ITMI was transformed as follows and uploaded to impala:   \n",
      "\n",
      "- A 'level' column was added to represent the color coding found in the file, with the following options: red, yellow, null  \n",
      "- All commas were replaced with colons to prevent errors while importing csv file  \n",
      "- All semicolons were replaced with colons for consistency of data  \n",
      "- Spaces in column names were replaced with underscores  \n",
      "- Special characters were removed from column names"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding positional information to the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Genomic position, gene and transcript information and strand were added to the NBS Gene list by joining it with the ensembl_genes table by gene name. \n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_ensembl AS (\n",
      "             SELECT DISTINCT nbs.*, ens.chrom, ens.start, ens.stop, ens.gene_id, \n",
      "             ens.transcript_id, ens.strand\n",
      "             FROM users_selasady.nbs_genes nbs, p7_ref_grch37.ensembl_genes ens\n",
      "             WHERE nbs.gene = ens.gene_name\n",
      "           )\n",
      "\n",
      "The results were saved as users _ selasady.nbs _ ensembl containing 14839 rows due to multiple transcripts per gene name. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding rare variants with Kaviar"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For all specified trio members, variants were annotated with Kaviar, labeling variants under the Kaviar frequency threshold, or not listed in Kaviar, as rare. Variants were then joined with the nbs_ensembl table to retain only variants falling in NBS gene regions"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# load modules to connect to impala\n",
      "from impala.dbapi import connect\n",
      "from impala.util import as_pandas\n",
      "\n",
      "# format trio argument\n",
      "member_list = []\n",
      "for member in trio_member:\n",
      "    if member == 'NB':\n",
      "        member_list.append(\"bv.sample_id LIKE '%03'\")\n",
      "    if member == 'M':\n",
      "        member_list.append(\"bv.sample_id LIKE '%01'\")\n",
      "    if member == 'F':\n",
      "        member_list.append(\"bv.sample_id LIKE '%02'\")\n",
      "    if member_list == 'all':\n",
      "        member_list =''\n",
      "        \n",
      "# if the member argument is not empty create statement\n",
      "if len(member_list) > 0:\n",
      "    member_arg = 'AND (' + ' OR '.join(member_list) + ')'\n",
      "# otherwise statment is empty\n",
      "else: member_arg = ''\n",
      "\n",
      "# format sample id argument\n",
      "sample_arg = []\n",
      "if sample_list != 'all':\n",
      "    sample_arg.append(\"AND bv.sample_id IN \" + str(sample_list))\n",
      "    subject_list = \", \".join(str(i) for i in sample_arg)\n",
      "else: \n",
      "    subject_list = ''\n",
      "\n",
      "# list of user args to join \n",
      "arg_list = [subject_list, member_arg]\n",
      "\n",
      "# if there's an argument, format\n",
      "if len(arg_list) > 0:\n",
      "    subject_statement = ' '.join(arg_list)\n",
      "# otherwise return empty string\n",
      "else:\n",
      "    subject_statement = ''"
     ],
     "language": "python",
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# function to open connection, run query, close connection \n",
      "def run_query(query_name, remove_name):\n",
      "    # create connection object\n",
      "    conn=connect(host='glados19', port=21050, timeout=120)\n",
      "    # drop table if it exists\n",
      "    cur = conn.cursor()\n",
      "    print 'Removing table if it already exists...'\n",
      "    cur.execute('DROP TABLE IF EXISTS {}.{}_{}'.format(out_db,out_name, remove_name))\n",
      "    # run query \n",
      "    print 'Running the following query on impala: \\n' + query_name\n",
      "    cur.execute(query_name)\n",
      "    cur.execute('COMPUTE STATS {}.{}_{}'.format(out_db,out_name, remove_name))\n",
      "    print 'Query finished. Closing connection.'\n",
      "    cur.close()\n",
      "    conn.close()"
     ],
     "language": "python",
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Removing table if it already exists...\nRunning the following query on impala: \n \nCREATE TABLE users_selasady.nbs_150922_annot AS \n    WITH bv as (\n       SELECT bv.sample_id, bv.chrom, bv.pos, bv.ref, bv.alt, bv.id, bv.qual, bv.filter,\n                regexp_replace(bv.gt, '1/2', '0/1') as geno,nbs.gene, nbs.transcript_id,\n                nbs.gene_id, nbs.strand, nbs.condition, nbs.omim_phenotype, nbs.va_name, nbs.inheritance,\n                nbs.allelic_conditions, nbs.comments, nbs.level, nbs.in_pbg\n                FROM users_selasady.nbs_ensembl nbs, p7_platform.brady_variant bv\n                WHERE nbs.chrom = bv.chrom\n                AND (bv.pos BETWEEN nbs.start and nbs.stop)\n                )\n        SELECT DISTINCT bv.*, k.allele_freq,  \n                  CASE WHEN (k.allele_freq < .03 OR k.allele_freq IS NULL )then 'Y'\n                  ELSE 'N'\n                  END as kaviar_rare\n             FROM bv\n             LEFT JOIN /* +SHUFFLE */ p7_ref_grch37.kaviar k\n                  ON bv.chrom = k.chrom\n                  AND bv.pos = k.pos\n                  AND bv.ref = k.ref\n                  AND bv.alt = k.alt\n            WHERE (bv.chrom <> 'X' AND bv.chrom <> 'Y')\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\nQuery finished. Closing connection."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "input": [
      "nbs_query = ''' \n",
      "CREATE TABLE {}.{}_annot AS \n",
      "    WITH bv as (\n",
      "       SELECT bv.sample_id, bv.chrom, bv.pos, bv.ref, bv.alt, bv.id, bv.qual, bv.filter,\n",
      "                regexp_replace(bv.gt, '1/2', '0/1') as geno,nbs.gene, nbs.transcript_id,\n",
      "                nbs.gene_id, nbs.strand, nbs.condition, nbs.omim_phenotype, nbs.va_name, nbs.inheritance,\n",
      "                nbs.allelic_conditions, nbs.comments, nbs.level, nbs.in_pbg\n",
      "                FROM {}.nbs_ensembl nbs, {} bv\n",
      "                WHERE nbs.chrom = bv.chrom\n",
      "                AND (bv.pos BETWEEN nbs.start and nbs.stop)\n",
      "                )\n",
      "        SELECT DISTINCT bv.*, k.allele_freq,  \n",
      "                  CASE WHEN (k.allele_freq < {} OR k.allele_freq IS NULL )then 'Y'\n",
      "                  ELSE 'N'\n",
      "                  END as kaviar_rare\n",
      "             FROM bv\n",
      "             LEFT JOIN /* +SHUFFLE */ {} k\n",
      "                  ON bv.chrom = k.chrom\n",
      "                  AND bv.pos = k.pos\n",
      "                  AND bv.ref = k.ref\n",
      "                  AND bv.alt = k.alt\n",
      "            WHERE (bv.chrom <> 'X' AND bv.chrom <> 'Y')\n",
      "'''.format(out_db,out_name, out_db, variant_table, kav_freq, kaviar_table)\n",
      "\n",
      "# run kaviar annotation query\n",
      "run_query(nbs_query, 'annot')"
     ],
     "language": "python",
     "prompt_number": 160
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Please note that the 1/2 genotype was converted to 0/1 for downstream compatibility with snpeff, and only used for determining compound heterozygosity."
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Annotating with ClinVar pathogenicity and pathogenicity ratings from dbNFSP"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variants in NBS gene regions were then annotated with the ClinVar table by genomic position. Variants with a ClinVar significance rating of 4 or 5, but never 2 or 3, were marked with a 'Y' in the clin_patho column to denote non-conflicted pathogenically significant ratings.\n",
      "\n",
      "DANN scores are provided for SNV's and range between 0 and 1. The closer a score is to 1, the more pathogenic the variant. The DANN table was matched to variants on genomic position and alternate allele. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Removing table if it already exists...\nRunning the following query on impala: \n\n        CREATE TABLE IF NOT EXISTS users_selasady.nbs_150921_annotated AS \n        WITH nbs as (\n             SELECT DISTINCT nbs.*, clin.clin_hgvs, clin.clin_sig, clin.clin_dbn,\n                 CASE WHEN (clin.clin_sig NOT REGEXP '3|2[^5]|2$'  \n                     AND  clin.clin_sig REGEXP '4|[^25]5|^5') THEN 'Y'\n                     ELSE 'N'\n                 END AS clin_patho\n             FROM users_selasady.nbs_150921_annot nbs\n             LEFT JOIN p7_ref_grch37.clinvar clin\n                 ON nbs.chrom = clin.chrom\n                 AND nbs.pos = clin.pos\n                 AND nbs.alt = clin.alt\n          )\n\n        SELECT DISTINCT nbs.*, db.aa_alt, db.sift_score, db.sift_pred, db.polyphen2_hdiv_score,\n            db.polyphen2_hdiv_pred, db.polyphen2_hvar_score, db.polyphen2_hvar_pred, \n            db.fathmm_score, db.fathmm_pred, db.cadd_raw, db.dann_score, db.mutation_taster_pred,\n            db.mutation_assessor_score, mutation_assessor_pred, db.provean_score, db.provean_pred,\n            db.clinvar_clnsig, db.interpro_domain, db.exac_af,\n            CASE\n                WHEN SUBSTRING(nbs.sample_id, -2) = '01'THEN 'M'\n                WHEN SUBSTRING(nbs.sample_id, -2) = '02' THEN 'F'\n                WHEN SUBSTRING(nbs.sample_id, -2) = '03'THEN 'NB'\n                END as member,\n             CASE\n                WHEN (db.sift_pred LIKE '%D%' or db.polyphen2_hdiv_pred LIKE '%D%' or db.mutation_taster_pred LIKE '%D%'\n                     or db.mutation_assessor_pred LIKE '%H%' or db.fathmm_pred LIKE '%D%' or db.provean_pred LIKE '%D%'\n                     or db.dann_score >= 0.96) THEN 'Y'\n                ELSE 'N'\n                END as dbnfsp_predicted,\n            SUBSTRING(nbs.sample_id, 1, (length(nbs.sample_id)-3)) as family_id,\n            CONCAT(nbs.chrom, ':', CAST(nbs.pos AS STRING), ':', nbs.ref, ':', nbs.alt) as var_id \n        FROM nbs, p7_ref_grch37.dbnsfp_variant db\n            WHERE nbs.chrom = db.chrom\n            AND nbs.pos = db.pos\n            AND nbs.alt = db.alt\n            "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\nQuery finished. Closing connection."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "input": [
      "dbnsfp_query = '''\n",
      "        CREATE TABLE IF NOT EXISTS {}.{}_annotated AS \n",
      "        WITH nbs as (\n",
      "             SELECT DISTINCT nbs.*, clin.clin_hgvs, clin.clin_sig, clin.clin_dbn,\n",
      "                 CASE WHEN (clin.clin_sig NOT REGEXP '3|2[^5]|2$'  \n",
      "                     AND  clin.clin_sig REGEXP '4|[^25]5|^5') THEN 'Y'\n",
      "                     ELSE 'N'\n",
      "                 END AS clin_patho\n",
      "             FROM {}.{}_annot nbs\n",
      "             LEFT JOIN {} clin\n",
      "                 ON nbs.chrom = clin.chrom\n",
      "                 AND nbs.pos = clin.pos\n",
      "                 AND nbs.alt = clin.alt\n",
      "          )\n",
      "\n",
      "        SELECT DISTINCT nbs.*, db.aa_alt, db.sift_score, db.sift_pred, db.polyphen2_hdiv_score,\n",
      "            db.polyphen2_hdiv_pred, db.polyphen2_hvar_score, db.polyphen2_hvar_pred, \n",
      "            db.fathmm_score, db.fathmm_pred, db.cadd_raw, db.dann_score, db.mutation_taster_pred,\n",
      "            db.mutation_assessor_score, mutation_assessor_pred, db.provean_score, db.provean_pred,\n",
      "            db.clinvar_clnsig, db.interpro_domain, db.exac_af,\n",
      "            CASE\n",
      "                WHEN SUBSTRING(nbs.sample_id, -2) = '01'THEN 'M'\n",
      "                WHEN SUBSTRING(nbs.sample_id, -2) = '02' THEN 'F'\n",
      "                WHEN SUBSTRING(nbs.sample_id, -2) = '03'THEN 'NB'\n",
      "                END as member,\n",
      "             CASE\n",
      "                WHEN (db.sift_pred LIKE '%D%' or db.polyphen2_hdiv_pred LIKE '%D%' or db.mutation_taster_pred LIKE '%D%'\n",
      "                     or db.mutation_assessor_pred LIKE '%H%' or db.fathmm_pred LIKE '%D%' or db.provean_pred LIKE '%D%'\n",
      "                     or db.dann_score >= {}) THEN 'Y'\n",
      "                ELSE 'N'\n",
      "                END as dbnfsp_predicted,\n",
      "            SUBSTRING(nbs.sample_id, 1, (length(nbs.sample_id)-3)) as family_id,\n",
      "            CONCAT(nbs.chrom, ':', CAST(nbs.pos AS STRING), ':', nbs.ref, ':', nbs.alt) as var_id \n",
      "        FROM nbs, {} db\n",
      "            WHERE nbs.chrom = db.chrom\n",
      "            AND nbs.pos = db.pos\n",
      "            AND nbs.alt = db.alt\n",
      "            '''.format(out_db, out_name, out_db, out_name, clinvar_table, dann_score, dbnfsp_table)\n",
      "\n",
      "# run dbNFSP query on impala\n",
      "run_query(dbnsfp_query, 'annotated')"
     ],
     "language": "python",
     "prompt_number": 77
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 3,
     "source": [
      "Reading the impala results into python"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "#################\n",
      "# load modules  #\n",
      "#################\n",
      "from impala.util import as_pandas\n",
      "\n",
      "# query to left join nbs_annotated variants with DANN scores\n",
      "nbs_query = \"\"\"\n",
      "    SELECT * FROM users_selasady.nbs_150921_annotated\n",
      "    \"\"\".format(out_db, out_name)\n",
      "# run query on impala\n",
      "conn=connect(host='glados19', port=21050, timeout=120)\n",
      "cur = conn.cursor()\n",
      "cur.execute(nbs_query)\n",
      "\n",
      "# store results as pandas data frame\n",
      "nbs_df = as_pandas(cur)\n",
      "cur.close()\n",
      "conn.close()\n",
      "\n",
      "#{}.{}_annotated"
     ],
     "language": "python",
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "16029 variants located in NBS regions.\n"
       ]
      }
     ],
     "input": [
      "if len(nbs_df) > 0:\n",
      "    print str(len(nbs_df)) + ' variants located in NBS regions.'\n",
      "else: \n",
      "    print \"No variants located in NBS regions.\""
     ],
     "language": "python",
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding Functional Annotation"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import subprocess as subp\n",
      "import os\n",
      "\n",
      "# rename 'geno' to 'gt' for vcf output\n",
      "nbs_df = nbs_df.rename(columns = {'geno':'gt'})\n",
      "\n",
      "# function to add functional annotation\n",
      "def df_to_snpeff(input_df):\n",
      "    if os.path.exists(snpeff_path):\n",
      "        # setup file names\n",
      "        tsv_outname = '{}.tsv'.format(os.path.join(os.getcwd(), out_name))\n",
      "        vcf_outname = '{}.vcf'.format(os.path.join(os.getcwd(), out_name))\n",
      "        # these columns are output to vcf file\n",
      "        df = input_df[['chrom', 'pos', 'ref', 'alt', 'qual', 'filter', 'gt']]\n",
      "        # write to file for conversion to vcf\n",
      "        df.to_csv(tsv_outname, header=True, encoding='utf-8', sep=\"\\t\", index=False)\n",
      "        # run tab2vcf and upon success, run snpeff\n",
      "        vcf_process = subp.Popen(['python', './nbs_genes/tab2vcf.py', tsv_outname])\n",
      "        vcf_process.wait()\n",
      "        # command to run snpeff \n",
      "        snpeff_cmd = 'java -Xmx4g -jar {}  -t -v -noStats GRCh37.74 {} > {}_snpeff.vcf'.format(\n",
      "            snpeff_path, vcf_outname, out_name)\n",
      "        # run snpeff on vcf file\n",
      "        snpeff_process = subp.Popen(snpeff_cmd, shell=True)\n",
      "        snpeff_process.wait()\n",
      "    else:\n",
      "        print \"Make sure you entered the correct path to snpEff.jar\"\n",
      "\n",
      "# run function on query results\n",
      "try:\n",
      "    df_to_snpeff(nbs_df)\n",
      "except Exception, e: \n",
      "    print str(e)"
     ],
     "language": "python",
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The functional annotations were read back into Python, parsed and matched with the each respective variant data frame. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "38157 variants annotated for coding consequences.\n"
       ]
      }
     ],
     "input": [
      "#import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# pull out rows that have no transcript id for positional matching\n",
      "no_tx = nbs_df[nbs_df['transcript_id'].isnull()]\n",
      "with_tx = nbs_df[nbs_df['transcript_id'].notnull()]\n",
      "\n",
      "# function to drop extra columns ending in _y from df merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "            \n",
      "def parse_snpeff(input_df, input_vcf):\n",
      "    # read in snpeff vcf file\n",
      "    annot_vcf = pd.read_csv(input_vcf, sep='\\t', skiprows=8)\n",
      "    # split info field into separate rows for each transcript\n",
      "    info_df = pd.Series([j for i in annot_vcf['INFO'].str.split(',') for j in i])\n",
      "    # split each rown into separate columns by the pipe\n",
      "    info_df = pd.DataFrame(list(info_df.str.split('|')))\n",
      "    # drop emtpy/unnecessary columns\n",
      "    info_df = info_df[list(info_df.columns[0:11])]\n",
      "    info_df.columns = ['alt', 'effect', 'impact', 'gene_name', 'gene_id', 'feature_type', 'transcript_id', \n",
      "                     'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']\n",
      "    # remove the annotation header 'ANN=' from the alt field\n",
      "    info_df['alt'] = info_df['alt'].str.replace('ANN=', '')\n",
      "    # keep only transcript level feature types\n",
      "    info_df = info_df[(info_df['feature_type'] == 'transcript')]\n",
      "    # merge annotations with variant table\n",
      "    df_functional = pd.merge(input_df, info_df, on=['transcript_id', 'alt'], how='left')  \n",
      "    drop_y(df_functional)\n",
      "    # rename columns ending in _x from merge\n",
      "    df_functional.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "    df_functional.drop_duplicates(inplace=True)\n",
      "    return df_functional\n",
      "\n",
      "def snpeff_notx(input_df, input_vcf):\n",
      "    # read in snpeff vcf file\n",
      "    annot_vcf = pd.read_csv(input_vcf, sep='\\t', skiprows=8)\n",
      "    # split info field into separate rows for each transcript\n",
      "    info_df = pd.Series([j for i in annot_vcf['INFO'].str.split(',') for j in i])\n",
      "    # split each rown into separate columns by the pipe\n",
      "    info_df = pd.DataFrame(list(info_df.str.split('|')))\n",
      "    # drop emtpy/unnecessary columns\n",
      "    info_df = info_df[list(info_df.columns[0:11])]\n",
      "    info_df.columns = ['alt', 'effect', 'impact', 'gene_name', 'gene_id', 'feature_type', 'transcript_id', \n",
      "                     'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']\n",
      "    # remove the annotation header 'ANN=' from the alt field\n",
      "    info_df['alt'] = info_df['alt'].str.replace('ANN=', '')\n",
      "    # keep only transcript level feature types\n",
      "    info_df = info_df[(info_df['feature_type'] == 'transcript')]\n",
      "    #merge annotations with variant table\n",
      "    df_functional = pd.merge(input_df, info_df, on=['chrom', 'pos', 'ref', 'alt'], how='left')  \n",
      "    drop_y(df_functional)\n",
      "    # rename columns ending in _x from merge\n",
      "    df_functional.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "    df_functional.drop_duplicates(inplace=True)\n",
      "    return df_functional\n",
      "\n",
      "# merge nbs_genes with functional annotations\n",
      "tx_annot = parse_snpeff(with_tx, '{}_snpeff.vcf'.format(out_name))\n",
      "notx_annot = parse_snpeff(no_tx, '{}_snpeff.vcf'.format(out_name))\n",
      "\n",
      "# merge data frames back together\n",
      "nbs_annot = pd.concat([tx_annot, notx_annot]).drop_duplicates().reset_index(drop=True)\n",
      "\n",
      "print str(len(nbs_annot)) + \" variants annotated for coding consequences.\""
     ],
     "language": "python",
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Filtering for potentially pathogenic mutations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "dbNFSP variant table was used to add the following additional measures of possible pathogenicity.\n",
      "\n",
      "If a variant was labeled as pathogenic in ClinVar, or was considered rare with a Kaviar frequency less than .03 and contained any of the following parameters, it was marked as pathogenic.\n",
      "\n",
      "- SnpEff effect = High  \n",
      "- sift_pred = D  \n",
      "- polyphen2_ hdiv _pred = D  \n",
      "- polyphen2_ hvar _pred= D  \n",
      "- mutation_ taster _pred= D  \n",
      "- mutation_ assessor _pred = H  \n",
      "- fathmm_ pred = D  \n",
      "- provean_ pred = D  \n",
      "- cadd_ raw = provided for reference only  \n",
      "- dann_ score = above user-specified cutoff  \n",
      "- exac_ af = provided for reference only  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5722 variants labeled as predictive.\n"
       ]
      }
     ],
     "input": [
      "# label variants considered pathogenic \n",
      "nbs_annot['predictive'] = ((nbs_annot['clin_patho'] == 'Y') | \n",
      "                           ((nbs_annot['kaviar_rare'] == 'Y') & \n",
      "                           ((nbs_annot['impact'] == 'HIGH') \n",
      "                           | (nbs_annot['dbnfsp_predicted'] == 'Y'))))\n",
      " \n",
      "print str(len(nbs_annot[(nbs_annot['predictive'] == True)])) + \" variants labeled as predictive.\""
     ],
     "language": "python",
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding newborns predicted to have NBS conditions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataframe was separated into mother, father and newborn predictive het variants to search for compound hertozygosity."
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# disable extraneous pandas warning\n",
      "pd.options.mode.chained_assignment = None\n",
      "\n",
      "# add a family id column for comp_het analysis\n",
      "nbs_annot['family_id'] = nbs_annot['sample_id'].apply(lambda x: x.split('-')[1])\n",
      "\n",
      "#subset for het AR parent variants\n",
      "mom_hets = nbs_annot[((nbs_annot['member'] == 'M') & (nbs_annot['gt'] == '0/1') \n",
      "                      & (nbs_annot['predictive'] == True) & (nbs_annot['inheritance'] == 'AR'))]\n",
      "dad_hets = nbs_annot[((nbs_annot['member'] == 'F') & (nbs_annot['gt'] == '0/1') \n",
      "                      & (nbs_annot['predictive'] == True) & (nbs_annot['inheritance'] == 'AR'))]\n",
      "\n",
      "#subset newborn het AR variants\n",
      "nb_het1 = nbs_annot[((nbs_annot['member'] == 'NB') & (nbs_annot['gt'] == '0/1') \n",
      "                     & (nbs_annot['predictive'] == True) & (nbs_annot['inheritance'] == 'AR'))]\n",
      "nb_het2 = nbs_annot[((nbs_annot['member'] == 'NB2') & (nbs_annot['gt'] == '0/1') \n",
      "                     & (nbs_annot['predictive'] == True)& (nbs_annot['inheritance'] == 'AR'))]\n",
      "nb_het3 = nbs_annot[((nbs_annot['member'] == 'NB3') & (nbs_annot['gt'] == '0/1') \n",
      "                     & (nbs_annot['predictive'] == True)& (nbs_annot['inheritance'] == 'AR'))]"
     ],
     "language": "python",
     "prompt_number": 90
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 3,
     "source": [
      "Finding Dominant and Homozygous Recessive Disorders"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn and parent variants were subset to report:  \n",
      "- All variants in regions of dominant disorders  \n",
      "- All homozygous recessive variants in regions of autosomal recessive disorders"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# subset newborn variants by variant MOI and/or zygosity\n",
      "nb_dominant = nbs_annot[((nbs_annot['member'] == 'NB') & (nbs_annot['inheritance'].isin(['AD'])) & (nbs_annot[\n",
      "                                                                                                      'predictive'] == True))]\n",
      "nb_dominant.name = 'dominant'\n",
      "\n",
      "nb_hom_recessive = nbs_annot[((nbs_annot['member'] == 'NB') & (nbs_annot['inheritance'].isin(['AR'])) & (nbs_annot[\n",
      "                                                                                                           'gt'] == '1/1') & \n",
      "                              (nbs_annot['predictive'] == True))]\n",
      "nb_hom_recessive.name = 'hom_recessive'"
     ],
     "language": "python",
     "prompt_number": 113
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 3,
     "source": [
      "Looking for compunt heterozygosity"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Newborn heterozygous variants were subset to look for compound heterozygosity. This analysis was only performed on newborns where both parents were also sequenced."
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# function to find matching parent variants\n",
      "def find_parent_vars(nb_df, parent_df):\n",
      "    # merge dataframes on by variant position\n",
      "    merged_df = pd.merge(nb_df, parent_df, on=['chrom', 'pos', 'ref', 'alt'], how='inner')\n",
      "    # rename parent sample_id column to avoid dropping when removing '_y' cols\n",
      "    merged_df.rename(columns = {'member_y':'from_parent'}, inplace=True)\n",
      "    # drop extra y columns from merge with fathers\n",
      "    drop_y(merged_df)\n",
      "    #remove _x from colnames\n",
      "    merged_df.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "    return merged_df\n",
      "    \n",
      "# run function for each group of newborns\n",
      "def match_parents(nb_df):\n",
      "    if (len(mom_hets) > 0) and (len(dad_hets) > 0):\n",
      "        nb_and_mom = find_parent_vars(nb_df, mom_hets)\n",
      "        nb_and_dad = find_parent_vars(nb_df, dad_hets)\n",
      "        # merge variants found in either mother or father\n",
      "        het_cands = pd.concat([nb_and_mom,nb_and_dad]).drop_duplicates().reset_index(drop=True)\n",
      "        # group variants by gene name\n",
      "        by_gene = het_cands.groupby(['gene_name', 'family_id'])\n",
      "        return by_gene\n",
      "    else:\n",
      "        print \"No compound het variants\"\n",
      "        \n",
      "# run function for each group of newborns\n",
      "het1_grouped = match_parents(nb_het1)\n",
      "het2_grouped = match_parents(nb_het2)\n",
      "het3_grouped = match_parents(nb_het3)"
     ],
     "language": "python",
     "prompt_number": 114
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After grouping the variants by gene and family, the variants will be filtered to keep only variants with at least one different variant coming from the mother and one from the father."
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# function to find compound hets\n",
      "def find_comphets(gene_group, comphet_list_name):\n",
      "    for name, group in gene_group:\n",
      "        # if there is a variant in more than one position\n",
      "        if group.pos.nunique() > 1:\n",
      "            # and there are more than one variants from both parents\n",
      "            if len(group[group['from_parent'] == 'M'] > 1) and len(group[group['from_parent'] == 'F'] > 1):\n",
      "                comphet_list_name.append(group)\n",
      "            # or if there is only one variant from each parent\n",
      "            elif len(group[group['from_parent'] == 'M'] == 1) and len(group[group['from_parent'] == 'F'] == 1):\n",
      "                # and those variants are different\n",
      "                if len(group[group['from_parent'] == 'M'].pos - group[group['from_parent'] == 'F']) > 0:\n",
      "                        comphet_list_name.append(group)\n",
      "\n",
      "# create empty list to store comp_hets\n",
      "comp_hets = []\n",
      "\n",
      "het1_df = find_comphets(het1_grouped, comp_hets)     \n",
      "het2_df = find_comphets(het2_grouped, comp_hets)\n",
      "het3_df = find_comphets(het3_grouped, comp_hets)\n",
      "\n",
      "# check if comphets found\n",
      "def comphet_check(df):\n",
      "    if df:\n",
      "        comp_hets.append(df)\n",
      "\n",
      "# check for each nb df\n",
      "comphet_check(het1_df)\n",
      "comphet_check(het2_df)\n",
      "comphet_check(het3_df)\n",
      "\n",
      "# if any comp  hets were found, append to list and convert to df\n",
      "if len(comp_hets) > 0:\n",
      "    comphet_df = pd.concat(comp_hets)\n",
      "    comphet_df.name = 'comp_het'\n",
      "else:\n",
      "    print 'No comp hets found.'\n",
      "    comphet_df = pd.DataFrame()\n",
      "    comphet_df.name = 'comp_het'"
     ],
     "language": "python",
     "prompt_number": 115
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "QA"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "review_these = []\n",
      "\n",
      "# make sure all dominant variants are inherited as AD\n",
      "if len(nb_dominant[(~nb_dominant['inheritance'].isin(['AD']))]) > 0:\n",
      "     review_these.append(group)\n",
      "\n",
      "# make sure all homozygous recessive are homozygous alt and AR\n",
      "if len(nb_hom_recessive[(~nb_hom_recessive['inheritance'].isin(['AR'])) & (nb_hom_recessive['gt'] != '1/1')]) > 0:\n",
      "    review_these.append(group)\n",
      "\n",
      "# make sure all compound hets are het and AR \n",
      "if len(comphet_df[(~comphet_df['inheritance'].isin(['AR'])) | (comphet_df['gt'] != '0/1')]) > 0:\n",
      "     review_these.append(group)\n",
      "\n",
      "# check that there is more than one variant per gene\n",
      "het_groupy = comphet_df.groupby(['gene'])\n",
      "\n",
      "for name, group in het_groupy:\n",
      "        # check that there is a variant in more than one position\n",
      "        if group.pos.nunique() < 1:\n",
      "            review_these.append(group)\n",
      "        # check that there is at least one variant from the mother\n",
      "        if len(group[group['from_parent'] == 'M']) == 0:\n",
      "            review_these.append(group)\n",
      "        # check that there is at least one variant from the father\n",
      "        if len(group[group['from_parent'] == 'F']) == 0:\n",
      "            review_these.append(group)\n",
      "        # check that there is at least one different variant from each parent\n",
      "        if len(group[(group['from_parent'] == 'M')].pos - group[(group['from_parent'] == 'F')].pos)  == 0:\n",
      "            review_these.append(group)"
     ],
     "language": "python",
     "prompt_number": 154
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Results"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variants found:\n28 dominant variants found.\nCondition: \nHypothyroidism: congenital: nongoitrous 2    16\nPallister-Hall syndrome 2                    12\ndtype: int64 \n\nAffected gene(s): \n['PAX8' 'GLI2'] \n\n580 hom_recessive variants found.\nCondition: \nHyperprolinemia: type I                                         400\nSevere combined immunodeficiency: autosomal recessive: T-cell negative: B-cell positive: NK cell positive     60\nAdrenal hyperplasia: congenital: due to 21-hydroxylase deficiency: Hyperandrogenism: nonclassic type: due to 21-hydroxylase deficiency     60\nTyrosinemia: type III                                            32\nMaple syrup urine disease: type II                               18\nSevere combined immunodeficiency                                 10\ndtype: int64 \n\nAffected gene(s): \n['IL7R' 'HPD' 'PRODH' 'CYP21A2' 'MTHFD1' 'DBT'] \n\n251 comp_het variants found.\nCondition: \nSevere combined immunodeficiency: autosomal recessive: T-cell negative: B-cell positive: NK cell positive    90\nCystic fibrosis                                                 85\nAdrenal hyperplasia: congenital: due to 21-hydroxylase deficiency: Hyperandrogenism: nonclassic type: due to 21-hydroxylase deficiency    58\nLIG4 syndrome: Severe combined immunodeficiency with sensitivity to ionizing radiation    18\ndtype: int64 \n\nAffected gene(s): \n['CFTR' 'CYP21A2' 'IL7R' 'LIG4'] \n\n\n\n"
       ]
      }
     ],
     "input": [
      "# report variant counts\n",
      "def report_result_counts(results_df):\n",
      "    if len(results_df) > 0:\n",
      "        print str(len(results_df)) + ' {} variants found.'.format(results_df.name)\n",
      "        condition = results_df['condition'].value_counts()\n",
      "        genes = results_df['gene'].unique()\n",
      "        print 'Condition: \\n', condition, '\\n'\n",
      "        print 'Affected gene(s): \\n', genes, '\\n'\n",
      "    else:\n",
      "         print \"No {} variants found. \\n\".format(results_df.name)\n",
      "        \n",
      "print \"Variants found:\"\n",
      "report_result_counts(nb_dominant)\n",
      "report_result_counts(nb_hom_recessive)\n",
      "report_result_counts(comphet_df)\n",
      "print \"\\n\""
     ],
     "language": "python",
     "prompt_number": 117
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Saving Output"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving 28 dominant variants to current working directory\nSaving 580 hom_recessive variants to current working directory\nSaving 251 comp_het variants to current working directory\n"
       ]
      }
     ],
     "input": [
      "# add from_parent column to dom and hom_rec so we can keep info for comp_het\n",
      "nb_dominant['from_parent'] = 'NA'\n",
      "nb_hom_recessive['from_parent'] = 'NA'\n",
      "\n",
      "# merge and mark predicted variants\n",
      "def merge_predictors(df, out_list):\n",
      "    if len(df) > 0:\n",
      "        df['var_type'] = df.name\n",
      "        out_list.append(df)\n",
      "        print \"Saving {} {} variants to current working directory\".format(len(df), df.name)\n",
      "    else:\n",
      "        print \"No {} variants to save.\".format(df.name)\n",
      "\n",
      "# list to store patho output\n",
      "predict_list = []            \n",
      "\n",
      "merge_predictors(nb_dominant, predict_list)\n",
      "merge_predictors(nb_hom_recessive, predict_list)\n",
      "merge_predictors(comphet_df, predict_list)\n",
      "\n",
      "# merge results\n",
      "merged_patho = pd.concat(predict_list, axis=0)\n",
      "\n",
      "# put the columns back in order because pandas\n",
      "cols = ['sample_id', 'chrom', 'pos', 'id', 'ref', 'alt', 'gt', 'gene',  'gene_id', 'allele_freq', \n",
      "        'condition','inheritance', 'clin_sig', 'clin_dbn', 'transcript_id', 'strand',   \n",
      "        'impact', 'effect', 'dbnfsp_predicted', 'dann_score', 'cadd_raw', 'qual', 'filter', \n",
      "        'clin_hgvs', 'omim_phenotype', 'va_name', 'allelic_conditions', 'comments', 'level',\n",
      "        'aa_alt', 'sift_score', 'sift_pred', 'polyphen2_hdiv_score', 'polyphen2_hdiv_pred', \n",
      "        'polyphen2_hvar_score', 'polyphen2_hvar_pred', 'fathmm_score', 'fathmm_pred',  \n",
      "        'mutation_taster_pred', 'mutation_assessor_score', 'mutation_assessor_pred', 'provean_score', 'provean_pred', \n",
      "        'interpro_domain', 'exac_af', 'rank', 'hgvs_c', 'hgvs_p', 'from_parent', 'var_type',   \n",
      "        'member','family_id', 'feature_type', 'gene_name','id']\n",
      "\n",
      "merged_out = merged_patho[cols]\n",
      "\n",
      "# remove unnecessary columns\n",
      "merged_out.drop(merged_out.columns[[50, 51, 52, 52,53,54]], axis=1, inplace=True)\n",
      "\n",
      "# save to file\n",
      "merged_out.to_csv('predicted_NBS_{}.tsv'.format(time.strftime(\"%y%m%d\")), sep= '\\t', header=True, encoding='utf-8', \\\n",
      "                                                                                                    index=False)\n",
      "\n",
      "if len(review_these) > 0:\n",
      "    print 'Some variants were flagged for review and saved to nbs_{)_review.tsv'.format(time.strftime(\"%y%m%d\"))\n",
      "    for_review = pd.DataFrame(review_these)\n",
      "    for_review.to_csv('nbs_{)_review.tsv'.format(time.strftime(\"%y%m%d\")), sep='\\t', header=True, encoding='utf-8', \n",
      "                                                 index=False)"
     ],
     "language": "python",
     "prompt_number": 155
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "To Do"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- reorder columns  \n",
      "- make package\n",
      "- change location of tab2vcf.py function according to location in package\n",
      "- report only nb vars\n",
      "- mark with variant type\n",
      "- why is sample id _22 showing up? "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0
}