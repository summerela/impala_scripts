{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 1,
     "source": [
      "NBS Gene Annotation"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Purpose"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variants were annotated with the NBS gene table provided by Ben Solomon at ITMI. Variants located in NBS gene regions were annotated with Kaviar frequency, ClinVar clinical significance ratings, DANN predicted pathogenicity scores for SNV's, and coding consequence predictions using SnpEff. \n",
      "\n",
      "Variants were filtered for appropriate mode of inheritance and then labeled as predictive when meeting the following conditions:   \n",
      "- Presence of mutation(s) with appropriate inheritance (eg, 2 bi-allelic pathogenic mutations for a recessive disorder).  \n",
      "\n",
      "Mutations defined strictly as either:   \n",
      "    - Annotated in ClinVar with a clinical significance of 4 or 5, but never 2 or 3 or labeled pathogenic in HGMD (to be added later)  \n",
      "    OR    \n",
      "    - Novel (in Kaviar with frequency less than .03 or not in Kaviar) but either predicted to be disease-causing with a SnpEff impact score of 'high' or a DANN score higher than specified cutoff below"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "User Specified Parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The analysis was performed using the parameters specified below: "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "#############\n",
      "## kaviar ##\n",
      "############\n",
      "# enter kaviar frequency threshold\n",
      "kav_freq = '.03'\n",
      "\n",
      "###############\n",
      "## family id ##\n",
      "###############\n",
      "# enter dictionary of samples to examine in format 'sample_id':['family_id','member_id']\n",
      "sample_list = {'08-01_PG0001705-BLD':'M', '08-04_PG0001704-BLD':'F', '08-05_PG0001706-BLD':'NB',\n",
      "               '08-06_PG0001707-BLD':'NB', '08-07_PG0001708-BLD':'NB', \n",
      "               '05-02_PG0003573-BLD':'M', '05-03_PG0003565-BLD':'F', '05-01_PG0003524-BLD':'NB',\n",
      "               '07-02_PG0001692-BLD':'M', '07-03_PG0001693-BLD':'F', '07-01_PG0002918-DNA':'NB',\n",
      "               '07-05_PG0002917-DNA':'NB',\n",
      "               '06-02_PG0001697-BLD':'M', '06-03_PG0001698-BLD':'F', '06-01_PG0001696-BLD':'NB',\n",
      "               '04-01_PG0001691-BLD':'NB'\n",
      "               }\n",
      "\n",
      "################\n",
      "## dann_score ##\n",
      "################\n",
      "# enter minimum dann score for predicted NBS\n",
      "dann_score = '0.96'\n",
      "\n",
      "########################\n",
      "## database locations ##\n",
      "########################\n",
      "# enter user database to output tables\n",
      "out_db = 'users_selasady'\n",
      "# enter database.name for variant table\n",
      "variant_table = 'clarity2.wgs_illumina_variant'\n",
      "# enter database.name of kaviar table\n",
      "kaviar_table = 'p7_ref_grch37.kaviar_isb'\n",
      "# enter database.name of clinvar table\n",
      "clinvar_table = 'p7_ref_grch37.clinvar'\n",
      "# enter database.name of dann table\n",
      "dbnfsp_table = 'p7_ref_grch37.dbnsfp_variant'\n",
      "\n",
      "#################\n",
      "## system info ##\n",
      "#################\n",
      "# enter path to snpEff.jar on your computer\n",
      "snpeff_path = '/Users/summerrae/tools/snpEff/snpEff.jar'\n",
      "#snpeff_path = 'D:/Documents/tools/snpEff/snpEff.jar'\n",
      "# enter desired basename for output files\n",
      "out_name = 'clarity_nbs'"
     ],
     "language": "python",
     "prompt_number": 507
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Transform of NBS Gene Table"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The NBS Gene Table provided by ITMI was transformed as follows and uploaded to impala:   \n",
      "\n",
      "- A 'level' column was added to represent the color coding found in the file, with the following options: red, yellow, null  \n",
      "- All commas were replaced with colons to prevent errors while importing csv file  \n",
      "- All semicolons were replaced with colons for consistency of data  \n",
      "- Spaces in column names were replaced with underscores  \n",
      "- Special characters were removed from column names"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding positional information to the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Chromosome, start and stop positions were added to the NBS Gene list by joining it with the \n",
      "ucsc_genes table using gene name. This resulted in mulitple listings per gene for each exon, \n",
      "allowing for more precise matches. \n",
      "\n",
      "        CREATE TABLE nbs_ucsc AS (\n",
      "             SELECT DISTINCT nbs.*, ucsc.chrom, ucsc.txstart, ucsc.txend, ucsc.mrna\n",
      "             FROM nbs_genes as nbs, p7_ref_grch37.ucsc_genes as ucsc\n",
      "             WHERE nbs.gene = ucsc.gene_name\n",
      "           )\n",
      "\n",
      "The results were saved as users _ selasady.nbs _ ucsc containing 611 rows. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding rare variants with Kaviar"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For all specified trio members, variants were annotated with Kaviar, labeling variants under the Kaviar frequency threshold, or not listed in Kaviar, as rare. Variants were then joined with the nbs_ucsc table to retain only variants falling in NBS gene regions.  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# format arg for sample ids to include\n",
      "sample_arg = []\n",
      "\n",
      "if sample_list != 'all':\n",
      "    sample_arg.append(\"AND bv.sample_id IN ('{}')\".format( \"', '\".join(sample_list.keys()))) \n",
      "    subject_statement = \", \".join(str(i) for i in sample_arg)\n",
      "else: \n",
      "    subject_statement = ''"
     ],
     "language": "python",
     "prompt_number": 425
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# load modules to connect to impala\n",
      "from impala.dbapi import connect\n",
      "from impala.util import as_pandas"
     ],
     "language": "python",
     "prompt_number": 428
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# open connection, run query, close connection \n",
      "def run_query(query_name, remove_name):\n",
      "    # create connection object\n",
      "    conn=connect(host='glados19', port=21050, timeout=120)\n",
      "    # drop table if it exists\n",
      "    cur = conn.cursor()\n",
      "    print 'Removing table if it already exists...'\n",
      "    cur.execute('DROP TABLE IF EXISTS {}.{}_{}'.format(out_db,out_name, remove_name))\n",
      "    # run query \n",
      "    print 'Running the following query on impala: \\n' + query_name\n",
      "    cur.execute(query_name)\n",
      "    cur.execute('COMPUTE STATS {}.{}_{}'.format(out_db,out_name, remove_name))\n",
      "    print 'Query finished. Closing connection.'\n",
      "    cur.close()\n",
      "    conn.close()"
     ],
     "language": "python",
     "prompt_number": 431
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Removing table if it already exists...\nRunning the following query on impala: \n\n\n    CREATE TABLE users_selasady.clarity_nbs_kaviar AS         \n          WITH bv as (\n             SELECT bv.sample_id, bv.chrom, bv.pos, bv.id, k.rs_id as kav_rsid, bv.ref, \n                  bv.alt, bv.qual, bv.filter, regexp_replace(gt, '1/2', '0/1') as geno, k.allele_freq,  \n                  CASE WHEN (k.allele_freq < .03 OR k.allele_freq IS NULL )then 'Y'\n                  ELSE 'N'\n                  END as kaviar_rare\n             FROM clarity2.wgs_illumina_variant bv\n             LEFT JOIN /* +SHUFFLE */ p7_ref_grch37.kaviar_isb k\n                  ON bv.chrom = k.chrom\n                  AND bv.pos = k.pos\n                  AND bv.ref = k.ref\n                  AND bv.alt = k.alt\n            WHERE (bv.chrom <> 'X' AND bv.chrom <> 'Y')\n            AND bv.sample_id IN ('05-02_PG0003573-BLD', '07-02_PG0001692-BLD', '05-03_PG0003565-BLD', '06-02_PG0001697-BLD', '07-03_PG0001693-BLD', '07-05_PG0002917-DNA', '08-06_PG0001707-BLD', '04-01_PG0001691-BLD', '08-05_PG0001706-BLD', '06-01_PG0001696-BLD', '05-01_PG0003524-BLD', '08-07_PG0001708-BLD', '06-03_PG0001698-BLD', '07-01_PG0002918-DNA', '08-04_PG0001704-BLD', '08-01_PG0001705-BLD')\n         )\n        SELECT DISTINCT bv.*, nbs.gene, nbs.entrez_gene_id, nbs.condition, nbs.mrna,\n            nbs.omim_phenotype, nbs.va_name, nbs.inheritance, nbs.allelic_condition,nbs.in_pgb, \n            nbs.level, nbs.comments          \n       FROM bv, users_selasady.nbs_ucsc nbs\n       WHERE bv.chrom = nbs.chrom\n       AND bv.pos BETWEEN nbs.txstart and nbs.txend\n       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\nQuery finished. Closing connection."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "input": [
      "# create kaviar query\n",
      "kaviar_query = '''\n",
      "\n",
      "    CREATE TABLE {}.{}_kaviar AS         \n",
      "          WITH bv as (\n",
      "             SELECT bv.sample_id, bv.chrom, bv.pos, bv.id, k.rs_id as kav_rsid, bv.ref, \n",
      "                  bv.alt, bv.qual, bv.filter, regexp_replace(gt, '1/2', '0/1') as geno, k.allele_freq,  \n",
      "                  CASE WHEN (k.allele_freq < {} OR k.allele_freq IS NULL )then 'Y'\n",
      "                  ELSE 'N'\n",
      "                  END as kaviar_rare\n",
      "             FROM {} bv\n",
      "             LEFT JOIN /* +SHUFFLE */ {} k\n",
      "                  ON bv.chrom = k.chrom\n",
      "                  AND bv.pos = k.pos\n",
      "                  AND bv.ref = k.ref\n",
      "                  AND bv.alt = k.alt\n",
      "            WHERE (bv.chrom <> 'X' AND bv.chrom <> 'Y')\n",
      "            {}\n",
      "         )\n",
      "        SELECT DISTINCT bv.*, nbs.gene, nbs.entrez_gene_id, nbs.condition, nbs.mrna,\n",
      "            nbs.omim_phenotype, nbs.va_name, nbs.inheritance, nbs.allelic_condition,nbs.in_pgb, \n",
      "            nbs.level, nbs.comments          \n",
      "       FROM bv, {}.nbs_ucsc nbs\n",
      "       WHERE bv.chrom = nbs.chrom\n",
      "       AND bv.pos BETWEEN nbs.txstart and nbs.txend\n",
      "       '''.format(out_db, out_name, kav_freq, variant_table, kaviar_table, subject_statement, out_db)\n",
      "\n",
      "# run kaviar annotation query\n",
      "run_query(kaviar_query, 'kaviar')"
     ],
     "language": "python",
     "prompt_number": 511
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Please note that the 1/2 genotype was converted to 0/1 for downstream compatibility with snpeff, and only used for determining compound heterozygosity. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Annotating with ClinVar and pathogenicity from dbNFSP"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variants in NBS gene regions were then annotated with the ClinVar table by genomic position. Variants with a ClinVar significance rating of 4 or 5, but never 2 or 3, were marked with a 'Y' in the clin_patho column to denote non-conflicted pathogenically significant ratings.\n",
      "\n",
      "DANN scores are provided for SNV's and range between 0 and 1. The closer a score is to 1, the more pathogenic the variant. The DANN table was matched to variants on genomic position and alternate allele. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# parse args to create member_id column\n",
      "sample_case = []\n",
      "for key, val in sample_list.iteritems():\n",
      "    sample_case.append('WHEN nbs.sample_id = \"{}\" THEN \"{}\"'.format(key, val))\n",
      "    \n",
      "sample_case_list = '\\n'.join(sample_case)"
     ],
     "language": "python",
     "prompt_number": 518
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Removing table if it already exists...\nRunning the following query on impala: \n\n        CREATE TABLE users_selasady.clarity_nbs_annotated AS \n        WITH nbs as (\n             SELECT DISTINCT nbs.*, clin.clin_hgvs, clin.clin_sig, clin.clin_dbn,\n                 CASE WHEN (clin.clin_sig NOT REGEXP '3|2[^5]|2$'  \n                     AND  clin.clin_sig REGEXP '4|[^25]5|^5') THEN 'Y'\n                     ELSE 'N'\n                 END AS clin_patho\n             FROM users_selasady.clarity_nbs_kaviar nbs\n             LEFT JOIN p7_ref_grch37.clinvar clin\n                 ON nbs.chrom = clin.chrom\n                 AND nbs.pos = clin.pos\n                 AND nbs.alt = clin.alt\n          )\n\n        SELECT DISTINCT nbs.*, db.aa_alt, db.sift_score, db.sift_pred, db.polyphen2_hdiv_score,\n            db.polyphen2_hdiv_pred, db.polyphen2_hvar_score, db.polyphen2_hvar_pred, \n            db.fathmm_score, db.fathmm_pred, db.cadd_raw, db.dann_score, db.mutation_taster_pred,\n            db.mutation_assessor_score, mutation_assessor_pred, db.provean_score, db.provean_pred,\n            db.clinvar_clnsig, db.interpro_domain, db.exac_af,\n            CASE\n               WHEN nbs.sample_id = \"05-02_PG0003573-BLD\" THEN \"M\"\nWHEN nbs.sample_id = \"07-02_PG0001692-BLD\" THEN \"M\"\nWHEN nbs.sample_id = \"05-03_PG0003565-BLD\" THEN \"F\"\nWHEN nbs.sample_id = \"06-02_PG0001697-BLD\" THEN \"M\"\nWHEN nbs.sample_id = \"07-03_PG0001693-BLD\" THEN \"F\"\nWHEN nbs.sample_id = \"07-05_PG0002917-DNA\" THEN \"NB\"\nWHEN nbs.sample_id = \"08-06_PG0001707-BLD\" THEN \"NB\"\nWHEN nbs.sample_id = \"04-01_PG0001691-BLD\" THEN \"NB\"\nWHEN nbs.sample_id = \"08-05_PG0001706-BLD\" THEN \"NB\"\nWHEN nbs.sample_id = \"06-01_PG0001696-BLD\" THEN \"NB\"\nWHEN nbs.sample_id = \"05-01_PG0003524-BLD\" THEN \"NB\"\nWHEN nbs.sample_id = \"08-07_PG0001708-BLD\" THEN \"NB\"\nWHEN nbs.sample_id = \"06-03_PG0001698-BLD\" THEN \"F\"\nWHEN nbs.sample_id = \"07-01_PG0002918-DNA\" THEN \"NB\"\nWHEN nbs.sample_id = \"08-04_PG0001704-BLD\" THEN \"F\"\nWHEN nbs.sample_id = \"08-01_PG0001705-BLD\" THEN \"M\"\n                END as member,\n            CASE\n                WHEN (db.sift_pred LIKE '%D%' or db.polyphen2_hdiv_pred LIKE '%D%' or db.mutation_taster_pred LIKE '%D%'\n                     or db.mutation_assessor_pred LIKE '%H%' or db.fathmm_pred LIKE '%D%' \n                     or db.provean_pred LIKE '%D%' or db.dann_score >= 0.96) THEN 'Y'\n                ELSE 'N'\n                END as dbnfsp_predicted,\n            CONCAT(nbs.chrom, ':', CAST(nbs.pos AS STRING), ':', nbs.ref, ':', nbs.alt) as var_id \n        FROM nbs, p7_ref_grch37.dbnsfp_variant db\n            WHERE nbs.chrom = db.chrom\n            AND nbs.pos = db.pos\n            AND nbs.alt = db.alt\n            "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\nQuery finished. Closing connection."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "input": [
      "dbnsfp_query = '''\n",
      "        CREATE TABLE {}.{}_annotated AS \n",
      "        WITH nbs as (\n",
      "             SELECT DISTINCT nbs.*, clin.clin_hgvs, clin.clin_sig, clin.clin_dbn,\n",
      "                 CASE WHEN (clin.clin_sig NOT REGEXP '3|2[^5]|2$'  \n",
      "                     AND  clin.clin_sig REGEXP '4|[^25]5|^5') THEN 'Y'\n",
      "                     ELSE 'N'\n",
      "                 END AS clin_patho\n",
      "             FROM {}.{}_kaviar nbs\n",
      "             LEFT JOIN {} clin\n",
      "                 ON nbs.chrom = clin.chrom\n",
      "                 AND nbs.pos = clin.pos\n",
      "                 AND nbs.alt = clin.alt\n",
      "          )\n",
      "\n",
      "        SELECT DISTINCT nbs.*, db.aa_alt, db.sift_score, db.sift_pred, db.polyphen2_hdiv_score,\n",
      "            db.polyphen2_hdiv_pred, db.polyphen2_hvar_score, db.polyphen2_hvar_pred, \n",
      "            db.fathmm_score, db.fathmm_pred, db.cadd_raw, db.dann_score, db.mutation_taster_pred,\n",
      "            db.mutation_assessor_score, mutation_assessor_pred, db.provean_score, db.provean_pred,\n",
      "            db.clinvar_clnsig, db.interpro_domain, db.exac_af,\n",
      "            CASE\n",
      "               {}\n",
      "                END as member,\n",
      "            CASE\n",
      "                WHEN (db.sift_pred LIKE '%D%' or db.polyphen2_hdiv_pred LIKE '%D%' or db.mutation_taster_pred LIKE '%D%'\n",
      "                     or db.mutation_assessor_pred LIKE '%H%' or db.fathmm_pred LIKE '%D%' \n",
      "                     or db.provean_pred LIKE '%D%' or db.dann_score >= {}) THEN 'Y'\n",
      "                ELSE 'N'\n",
      "                END as dbnfsp_predicted,\n",
      "            CONCAT(nbs.chrom, ':', CAST(nbs.pos AS STRING), ':', nbs.ref, ':', nbs.alt) as var_id \n",
      "        FROM nbs, {} db\n",
      "            WHERE nbs.chrom = db.chrom\n",
      "            AND nbs.pos = db.pos\n",
      "            AND nbs.alt = db.alt\n",
      "            '''.format(out_db, out_name, out_db, out_name, clinvar_table, sample_case_list, dann_score, dbnfsp_table)\n",
      "\n",
      "# run dbNFSP query on impala\n",
      "run_query(dbnsfp_query, 'annotated')"
     ],
     "language": "python",
     "prompt_number": 519
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reading the impala results into python"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "#################\n",
      "# load modules  #\n",
      "#################\n",
      "from impala.util import as_pandas\n",
      "\n",
      "# query to left join nbs_annotated variants with DANN scores\n",
      "nbs_query = \"\"\"\n",
      "    SELECT * FROM {}.{}_annotated\n",
      "    \"\"\".format(out_db, out_name)\n",
      "# run query on impala\n",
      "conn=connect(host='glados19', port=21050, timeout=120)\n",
      "cur = conn.cursor()\n",
      "cur.execute(nbs_query)\n",
      "\n",
      "# store results as pandas data frame\n",
      "nbs_df = as_pandas(cur)\n",
      "cur.close()\n",
      "conn.close()"
     ],
     "language": "python",
     "prompt_number": 520
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6517 variants located in NBS regions.\n"
       ]
      }
     ],
     "input": [
      "if len(nbs_df) > 0:\n",
      "    print str(len(nbs_df)) + ' variants located in NBS regions.'\n",
      "else: \n",
      "    print \"No variants located in NBS regions.\""
     ],
     "language": "python",
     "prompt_number": 524
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding Functional Annotation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn set was output to a modified version of Plink's tab2vcf script to create a VCF file for use with SnpEff. The newborn variants in the VCF file were annotated with coding consequences using SnpEFf. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import subprocess as subp\n",
      "import os\n",
      "\n",
      "# rename 'geno' to 'gt' for vcf output\n",
      "nbs_df = nbs_df.rename(columns = {'geno':'gt'})\n",
      "\n",
      "# function to add functional annotation\n",
      "def df_to_snpeff(input_df):\n",
      "    if os.path.exists(snpeff_path):\n",
      "        # setup file names\n",
      "        tsv_outname = '{}.tsv'.format(os.path.join(os.getcwd(), out_name))\n",
      "        vcf_outname = '{}.vcf'.format(os.path.join(os.getcwd(), out_name))\n",
      "        # these columns are output to vcf file\n",
      "        df = input_df[['chrom', 'pos', 'ref', 'alt', 'qual', 'filter', 'gt']]\n",
      "        # write to file for conversion to vcf\n",
      "        df.to_csv(tsv_outname, header=True, encoding='utf-8', sep=\"\\t\", index=False)\n",
      "        # run tab2vcf and upon success, run snpeff\n",
      "        vcf_process = subp.Popen(['python', './nbs_genes/tab2vcf.py', tsv_outname])\n",
      "        vcf_process.wait()\n",
      "        # command to run snpeff \n",
      "        snpeff_cmd = 'java -Xmx4g -jar {} -v GRCh37.75 {} > nbs_snpeff.vcf'.format(snpeff_path, vcf_outname)\n",
      "        # run snpeff on vcf file\n",
      "        snpeff_process = subp.Popen(snpeff_cmd, shell=True)\n",
      "        snpeff_process.wait()\n",
      "    else:\n",
      "        print \"Make sure you entered the correct path to snpEff.jar\"\n",
      "\n",
      "# run function on query results\n",
      "try:\n",
      "    df_to_snpeff(nbs_df)\n",
      "except Exception, e: \n",
      "    print str(e)"
     ],
     "language": "python",
     "prompt_number": 525
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The functional annotations were read back into Python, parsed and matched with the each respective variant data frame. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6517 potential variants functionally annotated.\n"
       ]
      }
     ],
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# function to drop extra columns ending in _y from df merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "\n",
      "# add snpeff annotations back to dataframe\n",
      "def parse_snpeff(input_df):\n",
      "    # merge snpeff annotated vcf file with dataframe , skipping header\n",
      "    annot_vcf = pd.read_csv('nbs_snpeff.vcf', sep='\\t', skiprows=8)\n",
      "    # split info columns by \"|\" \n",
      "    info_df = pd.DataFrame(list(annot_vcf['INFO'].str.split('|')))\n",
      "    # keep only first (most detrimental) consequence listed\n",
      "    info_df = info_df[list(info_df.columns[1:11])]\n",
      "    # merge truncated info field with annot_vcf\n",
      "    annot_vcf = annot_vcf[np.r_[0:7, 9]]\n",
      "    annot_df = pd.concat([annot_vcf, info_df], axis=1)\n",
      "    # rename columns\n",
      "    annot_df.columns =['chrom', 'pos', 'id', 'ref', 'alt', 'qual', 'filter', 'gt', 'effect', 'impact', 'gene_name', \n",
      "    'gene_id', 'feature_type', 'feature_id', 'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']\n",
      "    # drop unnecessary columns before merging\n",
      "    annot_df.drop(['qual', 'filter', 'gene_name', 'gene_id', 'feature_id', 'feature_type', 'rank'], axis=1, inplace=True)\n",
      "    # merge annotations with variant table\n",
      "    df_functional = pd.merge(input_df, annot_df, left_on=['var_id'], right_on=['id'])\n",
      "    drop_y(df_functional)\n",
      "    # rename columns ending in _x from merge\n",
      "    df_functional.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "    df_functional.drop_duplicates(inplace=True)\n",
      "    return df_functional\n",
      "    \n",
      "# merge nbs_genes with functional annotations\n",
      "nbs_annot = parse_snpeff(nbs_df)\n",
      "\n",
      "print str(len(nbs_annot)) + \" potential variants functionally annotated.\""
     ],
     "language": "python",
     "prompt_number": 542
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Labeling potentially pathogenic mutations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "dbNFSP variant table was used to add the following additional measures of possible pathogenicity. \n",
      "\n",
      "If a variant was labeled as pathogenic in ClinVar, or was considered rare with a Kaviar frequency less than .03 and contained any of the following parameters, it was marked as pathogenic.  \n",
      "\n",
      "- SnpEff effect = High  \n",
      "- sift_pred = D  \n",
      "- polyphen2_hdiv_pred = D  \n",
      "- polyphen2_hvar_pred= D  \n",
      "- mutation_taster_pred= D  \n",
      "- mutation_assessor_pred = H  \n",
      "- fathmm_pred = D  \n",
      "- provean_pred = D  \n",
      "- cadd_raw = provided for reference only  \n",
      "- dann_score = above user-specified cutoff \n",
      "- exac_af = provided for reference only"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "733 variants labeled as predictive.\n"
       ]
      }
     ],
     "input": [
      "# label variants considered pathogenic \n",
      "nbs_annot['predictive'] = ((nbs_annot['clin_patho'] == 'Y') | ((nbs_annot['kaviar_rare'] == 'Y') & \n",
      "                            ((nbs_annot['impact'] == 'HIGH') | (nbs_annot['dbnfsp_predicted'] == 'Y'))))\n",
      " \n",
      "print str(len(nbs_annot[(nbs_annot['predictive'] == True)])) + \" variants labeled as predictive.\""
     ],
     "language": "python",
     "prompt_number": 551
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# add a family id column for comp_het analysis\n",
      "nbs_annot['family_id'] = nbs_annot['sample_id'].apply(lambda x: x.split('-')[0])"
     ],
     "language": "python",
     "prompt_number": 552
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 1,
     "source": [
      "Finding newborns predicted to have NBS conditions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataframe was separated into mother, father and newborn for downstream analysis. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of newborn variants: 3158\nNumber of mother variants: 1691\nNumber of father variants: 1668\n"
       ]
      }
     ],
     "input": [
      "# subset data frame by trio member\n",
      "newborns = nbs_annot[nbs_annot['member'] == 'NB']\n",
      "mothers = nbs_annot[nbs_annot['member'] == 'M']\n",
      "fathers = nbs_annot[nbs_annot['member'] == 'F']\n",
      "\n",
      "print \"Number of newborn variants: \" + str(len(newborns)) \n",
      "print \"Number of mother variants: \" + str(len(mothers)) \n",
      "print \"Number of father variants: \" + str(len(fathers))"
     ],
     "language": "python",
     "prompt_number": 553
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding Dominant and Homozygous Recessive Disorders"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn and parent variants were subset to report:   \n",
      "- All variants in regions of dominant disorders   \n",
      "- All homozygous recessive variants in regions of autosomal recessive disorders     "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# disable erroneous pandas warning\n",
      "pd.options.mode.chained_assignment = None\n",
      "\n",
      "# subset newborn variants by variant MOI and/or zygosity\n",
      "nb_dominant = newborns[((newborns['inheritance'] == 'AD') & (newborns['predictive'] == True))]\n",
      "nb_dominant.name = 'dominant'\n",
      "\n",
      "nb_hom_recessive = newborns[((newborns['inheritance'] == 'AR') & \n",
      "                             (newborns['gt'] == '1/1') & (newborns['predictive'] == True))]\n",
      "nb_hom_recessive.name = 'hom_recessive'\n",
      "\n",
      "# subset parent variants by MOI and/or zygosity\n",
      "parents = nbs_annot[(nbs_annot['member'] == 'M' )| (nbs_annot['member'] == 'F')]\n",
      "parents_dom = parents[((parents['inheritance'] == 'AD') & (parents['predictive'] == True))]\n",
      "parents_dom.name = 'parents_dom'\n",
      "parents_rec = parents[((parents['inheritance'] == 'AR') & \n",
      "                       (parents['gt'] == '1/1') & (parents['predictive'] == True))]\n",
      "parents_rec.name = 'parents_rec'"
     ],
     "language": "python",
     "prompt_number": 557
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reporting compound heterozygous recessive variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Newborn heterozygous variants were subset to look for compound heterozygosity. This analysis was only performed on newborns where both parents were also sequenced. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# create a subset of exact trios\n",
      "trios = nbs_annot.groupby('family_id').filter(lambda g: g.sample_id.nunique() == 3 and\n",
      "                                              'M' in g.values and 'F' in g.values and 'NB' in g.values)\n",
      "# convert back to a dataframe\n",
      "trio_df = pd.concat([trios]).drop_duplicates().reset_index(drop=True)\n",
      "\n",
      "# create a subset for parents with multiple nb \n",
      "multi_nbs = nbs_annot.groupby('family_id').filter(lambda g: g[(g['member'] == 'NB')].sample_id.nunique() > 1)"
     ],
     "language": "python",
     "prompt_number": 572
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Newborn het predictive variants were subset for variants inherited from het parents, and then grouped by gene and family: "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# keep only heterozygous parent variants, as homozygous parents are not of interest\n",
      "mom_het = mothers.loc[mothers['gt'] == '0/1']\n",
      "dad_het = fathers.loc[fathers['gt'] == '0/1']\n",
      "\n",
      "# subset trio and multi_nb variants for only het, predictive variants\n",
      "nb_het = newborns[((newborns['inheritance'] == 'AR') & (newborns['gt'] == '0/1') & (newborns['predictive'] == True))]\n",
      "\n",
      "           \n",
      "# function to find matching parent variants\n",
      "def find_parent_vars(nb_df, parent_df):\n",
      "    # merge dataframes on variant id\n",
      "    merged_df = pd.merge(nb_df, parent_df, on=['var_id'], how='inner')\n",
      "    # rename parent sample_id column to avoid dropping when removing '_y' cols\n",
      "    merged_df.rename(columns = {'member_y':'from_parent'}, inplace=True)\n",
      "    # drop extra y columns from merge with fathers\n",
      "    drop_y(merged_df)\n",
      "    #remove _x from colnames\n",
      "    merged_df.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "    return merged_df\n",
      "    \n",
      "# run function on trios\n",
      "if (len(mom_het) > 0) and (len(dad_het) > 0):\n",
      "    nb_and_mom = find_parent_vars(trio_df, mom_het)\n",
      "    nb_and_dad = find_parent_vars(trio_df, dad_het)\n",
      "    # merge variants found in either mother or father\n",
      "    het_cands = pd.concat([nb_and_mom,nb_and_dad]).drop_duplicates().reset_index(drop=True)\n",
      "    # group variants by gene name\n",
      "    trio_by_gene = het_cands.groupby(['gene', 'family_id'])\n",
      "else:\n",
      "    print \"No compound het variants\"\n",
      "    \n",
      "# run function for families with multiple nb's\n",
      "\n",
      "# create a list of families with multi nb's\n",
      "multi_list = []\n",
      "for id in multi_nbs['sample_id'][(multi_nbs['member'] == 'NB')].unique():\n",
      "    multi_list.append(id)\n",
      "\n",
      "# match mutli nb's with parent variants \n",
      "multi_cands = [] \n",
      "for nb_id in multi_list:\n",
      "    nb_and_mom = find_parent_vars(newborns[(newborns['sample_id'] == nb_id)], mom_het)\n",
      "    nb_and_dad = find_parent_vars(newborns[(newborns['sample_id'] == nb_id)], dad_het)\n",
      "    # merge variants found in either mother or father\n",
      "    het_cands = pd.concat([nb_and_mom,nb_and_dad]).drop_duplicates().reset_index(drop=True)\n",
      "    new_df = multi_cands.append(het_cands)\n",
      "    # group variants by gene name\n",
      "multi_df = pd.concat(multi_cands)\n",
      "multi_by_gene = het_cands.groupby(['gene', 'family_id'])"
     ],
     "language": "python",
     "prompt_number": 559
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After grouping the variants by gene and family, the variants will be filtered to keep only variants with at least one different variant coming from the mother and one from the father.  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# function to find compound hets\n",
      "def find_comphets(gene_group, comphet_list_name):\n",
      "    for name, group in gene_group:\n",
      "        # if there is a variant in more than one position\n",
      "        if group.pos.nunique() > 1:\n",
      "            # and there are more than one variants from both parents\n",
      "            if len(group[group['from_parent'] == 'M'] > 1) and len(group[group['from_parent'] == 'F'] > 1):\n",
      "                comphet_list_name.append(group)\n",
      "            # or if there is only one variant from each parent\n",
      "            elif len(group[group['from_parent'] == 'M'] == 1) and len(group[group['from_parent'] == 'F'] == 1):\n",
      "                # and those variants are different\n",
      "                if len(group[group['from_parent'] == 'M'].pos - group[group['from_parent'] == 'F']) > 0:\n",
      "                        comphet_list_name.append(group)\n",
      "\n",
      "# create empty list to store comp_hets\n",
      "comp_hets = []\n",
      "\n",
      "if len(trio_by_gene) > 0:\n",
      "    # run function on by_gene\n",
      "    find_comphets(trio_by_gene, comp_hets)\n",
      "    # combine results into dataframe\n",
      "    comphet_df = pd.concat(comp_hets)\n",
      "    comphet_df.name = 'comp_het'\n",
      "else:\n",
      "    print 'No compound het variants found.'\n",
      "    comphet_df = pd.DataFrame()\n",
      "    comphet_df.name = 'comp_het'\n",
      "    \n",
      "# add families with multi newborns to comp_het df\n",
      "if len(multi_by_gene) > 0:\n",
      "    # run function on by_gene\n",
      "    find_comphets(multi_by_gene, comp_hets)\n",
      "    # combine results into dataframe\n",
      "    comphet_df = pd.concat(comp_hets)\n",
      "    comphet_df.name = 'comp_het'\n",
      "else:\n",
      "    print 'No compound het variants found.'\n",
      "    comphet_df = pd.DataFrame()\n",
      "    comphet_df.name = 'comp_het'"
     ],
     "language": "python",
     "prompt_number": 560
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Results"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variants found:\n11 dominant variants found.\nCondition: \nPallister-Hall syndrome 2                    8\nHypothyroidism: congenital nongoitrous: 5    3\ndtype: int64 \n\nAffected gene(s): \n['NKX2-5' 'GLI2'] \n\n93 hom_recessive variants found.\nCondition: \nHyperprolinemia: type I                                         24\nSevere combined immunodeficiency: autosomal recessive: T-cell negative: B-cell positive: NK cell positive    18\nMaple syrup urine disease: type II                              16\nTyrosinemia: type III                                           14\nGaucher disease                                                 12\nAdrenal hyperplasia: congenital: due to 21-hydroxylase deficiency: Hyperandrogenism: nonclassic type: due to 21-hydroxylase deficiency     6\nSevere combined immunodeficiency                                 3\ndtype: int64 \n\nAffected gene(s): \n['HPD' 'DBT' 'MTHFD1' 'IL7R' 'PRODH' 'GBA' 'CYP21A2'] \n\n3587 comp_het variants found.\nCondition: \nThyroid dyshormonogenesis 2A                                    555\nWilson disease                                                  366\nAlpha-1-antitrypsin deficiency                                  336\nThyroid dyshormonogenesis 3                                     236\nDiabetes mellitus: neonatal: with congenital hypothyroidism     210\nPallister-Hall syndrome 2                                       176\n  Mucopolysaccharidosis: type Ih (Hurler syndrome)              150\nCombined malonic and methylmalonic aciduria                     140\nCystinosis (multiple types)                                     120\nHomocystinuria-megaloblastic anemia: cobalamin E type           120\nHyperprolinemia: type I                                         114\nNiemann-Pick disease: type C1: Niemann-Pick disease: type D      99\nHomocystinuria                                                   93\nOmenn syndrome: Severe combined immunodeficiency with sensitivity to ionizing radiation     87\nGlycogen storage disease II (Pompe disease)                      75\nT cell-negative: B cell-negative: natural killer cell-positive severe combined immunodeficiency: Omenn syndrome: Alpha/beta T-cell lymphopenia with gamma/delta T-cell expansion: severe cytomegalovirus infection: and autoimmunity: Combined cellular and humoral immune defects with granulomas     72\nThyroid dyshormonogenesis 4                                      70\nCarbamoylphosphate synthetase I deficiency                       64\nSevere combined immunodeficiency                                 58\nThyroid dyshormonogenesis 6                                      58\nCystic fibrosis                                                  58\nKrabbe disease                                                   56\nMethylmalonic acidemia: cblB type                                42\nNiemann-Pick disease: type A: Niemann-Pick disease: type B       42\nAdrenal hyperplasia: congenital: due to 21-hydroxylase deficiency: Hyperandrogenism: nonclassic type: due to 21-hydroxylase deficiency     40\nSevere combined immunodeficiency: autosomal recessive: T-cell negative: B-cell positive: NK cell positive     36\nMitochondrial DNA depletion syndrome 5 (Succinate-CoA ligase deficiency)     24\nMethylmalonic acidemia due to methylmalonyl-CoA mutase deficiency     22\nGM1-gangliosidosis: types I: II: and III: Mucopolysaccharidosis: type IVB (Morquio syndrome B)     17\nMaple syrup urine disease: type Ia                               14\n3-hydroxyacyl-CoA dehydrogenase deficiency                       12\nN/A                                                              12\nIsovaleric acidemia                                               6\nAlpha-thalassemia (Hemoglobin Bart syndrome): Alpha-thalassemia (Hemoglobin H  disease)      4\nCarnitine palmitoyltransferase II deficiency                      3\ndtype: int64 \n\nAffected gene(s): \n['ACADL' 'ACSF3' 'ATP7B' 'BCKDHA' 'CFTR' 'CPS1' 'CTNS' 'CYP21A2' 'DCLRE1C'\n 'DUOX2' 'GAA' 'GALC' 'GLB1' 'GLI2' 'GLIS3' 'HADH' 'HBA1' 'IDUA' 'IL7R'\n 'IYD' 'MMAB' 'MTHFD1' 'MTHFR' 'MTRR' 'MUT' 'NPC1' 'PRODH' 'RAG1'\n 'SERPINA1' 'SMPD1' 'SUCLA2' 'TG' 'TPO' 'CPT2' 'IVD'] \n\n\n\n"
       ]
      }
     ],
     "input": [
      "# report variant counts\n",
      "def report_result_counts(results_df):\n",
      "    if len(results_df) > 0:\n",
      "        print str(len(results_df)) + ' {} variants found.'.format(results_df.name)\n",
      "        condition = results_df['condition'].value_counts()\n",
      "        genes = results_df['gene'].unique()\n",
      "        print 'Condition: \\n', condition, '\\n'\n",
      "        print 'Affected gene(s): \\n', genes, '\\n'\n",
      "    else:\n",
      "         print \"No {} variants found. \\n\".format(results_df.name)\n",
      "        \n",
      "print \"Variants found:\"\n",
      "report_result_counts(nb_dominant)\n",
      "report_result_counts(nb_hom_recessive)\n",
      "report_result_counts(comphet_df)\n",
      "print \"\\n\""
     ],
     "language": "python",
     "prompt_number": 562
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Saving Output"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving 11 dominant variants to current working directory\nSaving 93 hom_recessive variants to current working directory\nSaving 3587 comp_het variants to current working directory\n"
       ]
      }
     ],
     "input": [
      "# add from_parent column to dom and hom_rec so we can keep info for comp_het\n",
      "nb_dominant['from_parent'] = 'NA'\n",
      "nb_hom_recessive['from_parent'] = 'NA'\n",
      "\n",
      "# merge and mark predicted variants\n",
      "def merge_predictors(df, out_list):\n",
      "    if len(df) > 0:\n",
      "        df['var_type'] = df.name\n",
      "        out_list.append(df)\n",
      "        print \"Saving {} {} variants to current working directory\".format(len(df), df.name)\n",
      "    else:\n",
      "        print \"No {} variants to save.\".format(df.name)\n",
      "\n",
      "# list to store patho output\n",
      "predict_list = []            \n",
      "\n",
      "merge_predictors(nb_dominant, predict_list)\n",
      "merge_predictors(nb_hom_recessive, predict_list)\n",
      "merge_predictors(comphet_df, predict_list)\n",
      "\n",
      "# merge results\n",
      "merged_patho = pd.concat(predict_list, axis=0)\n",
      "\n",
      "# remove unnecessary columns\n",
      "merge_df = merged_patho[np.r_[0:41, 43, 44, 46, 49:53, 55, 56]]\n",
      "\n",
      "# save to file\n",
      "merge_df.to_csv('clarity_predicted_NBS.csv', header=True, encoding='utf-8', index=False)"
     ],
     "language": "python",
     "prompt_number": 563
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Resources"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- dbNSFP: 3.0a  \n",
      "- SnpEff: 4.1h (build 2015-08-03) with GRCh37.75  \n",
      "- ClinVar: 2/5/15 build  \n",
      "- Kaviar: 150812 ISB\n",
      "- genomes: clarity2.wgs_illumina_variant"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0
}