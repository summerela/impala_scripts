{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 1,
     "source": [
      "Finding ClinVar Pathogenic Variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Return variants that are marked as pathogenic in ClinVar with a rating of 4 or 5, but never 2 or 3 and then annotate with ensembl and dbNFSP. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "        CREATE TABLE clarity_clinvar AS \n",
      "        WITH clins AS (\n",
      "            SELECT DISTINCT cl.sample_id, cl.chrom, cl.pos, cl.id, cl.ref, cl.alt, cl.gt, cl.qual, cl.filter, clin.rs_id, clin.clin_hgvs, clin.clin_sig, clin.clin_dbn\n",
      "            FROM clarity2.wgs_illumina_variant cl, p7_ref_grch37.clinvar clin\n",
      "            WHERE cl.chrom = clin.chrom\n",
      "            AND cl.pos = clin.pos\n",
      "           AND cl.ref = clin.ref\n",
      "           AND cl.alt = clin.alt\n",
      "           AND (clin.clin_sig NOT REGEXP '3|2[^5]|2INSERTQUESTIONMARKHERE' AND  clin.clin_sig REGEXP '4|[^25]5|^5') \n",
      "           )\n",
      "           SELECT clins.*, ens.gene_name, ens.gene_id, ens.transcript_id,db.aa_alt, db.sift_score, db.sift_pred, db.polyphen2_hdiv_score,\n",
      "                db.polyphen2_hdiv_pred, db.polyphen2_hvar_score, db.polyphen2_hvar_pred, \n",
      "                db.fathmm_score, db.fathmm_pred, db.cadd_raw, db.dann_score, db.mutation_taster_pred,\n",
      "                db.mutation_assessor_score, mutation_assessor_pred, db.provean_score, db.provean_pred,\n",
      "                db.interpro_domain, db.exac_af,\n",
      "                CASE\n",
      "                    WHEN (db.sift_pred LIKE '%D%' or db.polyphen2_hdiv_pred LIKE '%D%' or db.mutation_taster_pred LIKE '%D%'\n",
      "                     or db.mutation_assessor_pred LIKE '%H%' or db.fathmm_pred LIKE '%D%' or db.provean_pred LIKE '%D%'\n",
      "                     or db.dann_score >= .96) THEN 'Y'\n",
      "                ELSE 'N'\n",
      "                END as dbnfsp_predicted\n",
      "            FROM clins\n",
      "            LEFT JOIN p7_ref_grch37.ensembl_genes ens\n",
      "            ON clins.chrom = ens.chrom\n",
      "            AND clins.pos BETWEEN ens.start and ens.stop\n",
      "            JOIN p7_ref_grch37.dbnsfp_variant db \n",
      "            ON clins.chrom = db.chrom\n",
      "           AND clins.pos = db.pos\n",
      "           AND clins.ref = db.ref\n",
      "           AND clins.alt = db.alt"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Predict coding consequences using SnpEff"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# load modules to connect to impala\n",
      "from impala.dbapi import connect\n",
      "from impala.util import as_pandas\n",
      "\n",
      "# query to left join nbs_annotated variants with DANN scores\n",
      "nbs_query = \"\"\"\n",
      "    SELECT * FROM users_selasady.clarity_clinvar\n",
      "    \"\"\"\n",
      "# run query on impala\n",
      "conn=connect(host='glados19', port=21050, timeout=120)\n",
      "cur = conn.cursor()\n",
      "cur.execute(nbs_query)\n",
      "\n",
      "# store results as pandas data frame\n",
      "clinvar_df = as_pandas(cur)\n",
      "cur.close()\n",
      "conn.close()"
     ],
     "language": "python",
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 3,
     "source": [
      "Output variants as vcf format and run through SnpEff"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import subprocess as subp\n",
      "import os\n",
      "\n",
      "snpeff_path = '/Users/selasady/tools/snpEff/snpEff.jar'\n",
      "\n",
      "# function to add functional annotation\n",
      "def df_to_snpeff(input_df):\n",
      "    if os.path.exists(snpeff_path):\n",
      "        # these columns are output to vcf file\n",
      "        df = input_df[['chrom', 'pos', 'ref', 'alt', 'qual', 'filter', 'gt']]\n",
      "        # write to file for conversion to vcf\n",
      "        df.to_csv('clarity_clinsig.tsv', header=True, encoding='utf-8', sep=\"\\t\", index=False)\n",
      "        # run tab2vcf and upon success, run snpeff\n",
      "        vcf_process = subp.Popen(['python', './nbs_genes/tab2vcf.py', 'clarity_clinsig.tsv'])\n",
      "        vcf_process.wait()\n",
      "        # command to run snpeff \n",
      "        snpeff_cmd = 'java -Xmx4g -jar {} -v GRCh37.75 clarity_clinsig.vcf > clarity_clinvar_snpeff.vcf'.format(snpeff_path)\n",
      "        # run snpeff on vcf file\n",
      "        snpeff_process = subp.Popen(snpeff_cmd, shell=True)\n",
      "        snpeff_process.wait()\n",
      "    else:\n",
      "        print \"Make sure you entered the correct path to snpEff.jar\"\n",
      "\n",
      "# run function on query results\n",
      "try:\n",
      "    df_to_snpeff(clinvar_df)\n",
      "except Exception, e: \n",
      "    print str(e)"
     ],
     "language": "python",
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The functional annotations were read back into Python, parsed and matched with the each respective variant data frame. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# function to drop extra columns ending in _y from df merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "\n",
      "# read in snpeff vcf file\n",
      "annot_vcf = pd.read_csv('clarity_clinvar_snpeff.vcf', sep='\\t', skiprows=8)\n",
      "# split info field into separate rows for each transcript\n",
      "info_df = pd.Series([j for i in annot_vcf['INFO'].str.split(',') for j in i])\n",
      "# split each rown into separate columns by the pipe\n",
      "info_df = pd.DataFrame(list(info_df.str.split('|')))\n",
      "# drop emtpy/unnecessary columns\n",
      "info_df = info_df[list(info_df.columns[0:11])]\n",
      "info_df.columns = ['alt', 'effect', 'impact', 'gene_name', 'gene_id', 'feature_type', 'transcript_id', 'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']\n",
      "#merge annotations with variant table\n",
      "df_functional = pd.merge(clinvar_df, info_df, on=['transcript_id'])\n",
      "drop_y(df_functional)\n",
      "# rename columns ending in _x from merge\n",
      "df_functional.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "df_functional.drop_duplicates(inplace=True)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# # add snpeff annotations back to dataframe\n",
      "# def parse_snpeff(input_df):\n",
      "#     # merge snpeff annotated vcf file with dataframe , skipping header\n",
      "#     annot_vcf = pd.read_csv('clarity_clinvar_snpeff.vcf', sep='\\t', skiprows=8)\n",
      "#     # split info columns by \"|\" \n",
      "#     info_df = pd.DataFrame(list(annot_vcf['INFO'].str.split('|')))\n",
      "#     # keep only first (most detrimental) consequence listed\n",
      "#     info_df = info_df[list(info_df.columns[1:11])]\n",
      "#     # merge truncated info field back to annot_vcf\n",
      "#     annot_vcf = annot_vcf[np.r_[0,1,2, 3:7, 9]]\n",
      "#     annot_df = pd.concat([annot_vcf, info_df], axis=1)\n",
      "#     # rename columns\n",
      "#     annot_df.columns =['chrom', 'pos', 'id', 'ref', 'alt', 'gt', 'qual', 'filter', 'effect', 'impact', 'gene_name', \n",
      "#     'gene_id', 'feature_type', 'feature_id', 'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']\n",
      "#     # drop unnecessary columns before merging\n",
      "#     annot_df.drop(['qual', 'filter', 'gene_name', 'gene_id', 'feature_id', 'feature_type', 'rank'], axis=1, inplace=True)\n",
      "#     # merge annotations with variant table\n",
      "#     df_functional = pd.merge(input_df, annot_df, left_on=['var_id'], right_on=['id'])\n",
      "#     drop_y(df_functional)\n",
      "#     # rename columns ending in _x from merge\n",
      "#     df_functional.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "#     df_functional.drop_duplicates(inplace=True)\n",
      "#     return df_functional\n",
      "#     \n",
      "# # merge nbs_genes with functional annotations\n",
      "# nbs_annot = parse_snpeff(clinvar_df)\n",
      "# \n",
      "# print str(len(nbs_annot)) + \" potential variants functionally annotated.\""
     ],
     "language": "python",
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0
}