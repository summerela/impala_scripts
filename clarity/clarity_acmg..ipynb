{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 1,
     "source": [
      "Locating ClinVar Pathogenic Variants in ACMG Genes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Clarity variants labeled as non-conflicted pathogenic in ClinVar (clinical significance of 4 or 5, but never 2 or 3), were examined for location in ACMG gene regions. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding positional information to the ACMG gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Chromosome, start and stop positions were added to the ACMG Gene list by joining it with the ensembl_genes table to provide positional information, gene id and transcript id. \n",
      "\n",
      "        CREATE TABLE acmg_ensembl AS\n",
      "        SELECT DISTINCT acmg.*, ens.chrom, ens.start, ens.stop, ens.gene_id, ens.transcript_id\n",
      "            FROM users_selasady.acmg_genes acmg, p7_ref_grch37.ensembl_genes ens\n",
      "            WHERE acmg.gene = ens.gene_name\n",
      "\n",
      "7705 rows were inserted into users_selasady.acmg _ ensembl"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reading in ClinVar Pathogenic Variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Clarity variants labeled as non-conflicted pathogenic in the ClinVar database (version 2/5/15), and annotated with allele frequency from Kaviar (ISB version 150812) were matched by position to the acmg_ensembl table to located clinically significant variants in ACMG gene regions. \n",
      "\n",
      "Variants were annotated with dbNSFP (v3.0b2a) to provide prediction scores such as FATHMM, Interpro, CADD and DANN. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "        CREATE TABLE clarity_acmg AS\n",
      "        WITH kav as (\n",
      "            SELECT DISTINCT cl.*\n",
      "            FROM clarity_clinsig cl\n",
      "         )\n",
      "      SELECT DISTINCT cl.*, acmg.age_onset, acmg.inheritance, acmg.mim_disorder, \n",
      "            acmg.mim_gene, acmg.phenotype, acmg.pmid_entry, acmg.variants_to_report\n",
      "            FROM kav cl, acmg_ensembl acmg\n",
      "            WHERE cl.chrom = acmg.chrom\n",
      "            AND (cl.pos BETWEEN acmg.start and acmg.stop)\n",
      "\n",
      "Resulting in 155 rows. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Checking for Mode of Inheritance"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 3,
     "source": [
      "Reading in Results of Impala Query"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# load modules to connect to impala\n",
      "from impala.dbapi import connect\n",
      "from impala.util import as_pandas\n",
      "\n",
      "# query to left join nbs_annotated variants with DANN scores\n",
      "nbs_query = \"\"\"\n",
      "    SELECT DISTINCT * FROM users_selasady.clarity_acmg\n",
      "    \"\"\"\n",
      "# run query on impala\n",
      "conn=connect(host='glados19', port=21050, timeout=120)\n",
      "cur = conn.cursor()\n",
      "cur.execute(nbs_query)\n",
      "\n",
      "# store results as pandas data frame\n",
      "acmg_df = as_pandas(cur)\n",
      "cur.close()\n",
      "conn.close()"
     ],
     "language": "python",
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "155 ACMG variants imported from impala.\n"
       ]
      }
     ],
     "input": [
      "print str(len(acmg_df)) + ' ACMG variants imported from impala.'"
     ],
     "language": "python",
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding Predictive Coding Consequences and Functional Anntoation"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 3,
     "source": [
      "Output Variants to VCF and anntate with SnpEff"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "SnpEff (version 4.1h build 2015-08-03 with GRCh37.75) was used to annotate the ClinVar variants with predicted coding consequences. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import subprocess as subp\n",
      "import os\n",
      "\n",
      "#snpeff_path = '/Users/summerrae/tools/snpEff/snpEff.jar'\n",
      "snpeff_path = 'D:/Documents/tools/snpEff/snpEff.jar'\n",
      "\n",
      "# function to add functional annotation\n",
      "def df_to_snpeff(input_df):\n",
      "    if os.path.exists(snpeff_path):\n",
      "        # these columns are output to vcf file\n",
      "        df = input_df[['chrom', 'pos', 'ref', 'alt', 'qual', 'filter', 'gt']]\n",
      "        # write to file for conversion to vcf\n",
      "        df.to_csv('clarity_acmg.tsv', header=True, encoding='utf-8', sep=\"\\t\", index=False)\n",
      "        # run tab2vcf and upon success, run snpeff\n",
      "        vcf_process = subp.Popen(['python', './nbs_genes/tab2vcf.py', 'clarity_acmg.tsv'])\n",
      "        vcf_process.wait()\n",
      "        # command to run snpeff \n",
      "        snpeff_cmd = 'java -Xmx4g -jar {} -t -v -noStats GRCh37.75 clarity_acmg.vcf > ' \\\n",
      "                     'clarity_acmg_snpeff.vcf'.format(snpeff_path)\n",
      "        # run snpeff on vcf file\n",
      "        snpeff_process = subp.Popen(snpeff_cmd, shell=True)\n",
      "        snpeff_process.wait()\n",
      "    else:\n",
      "        print \"Make sure you entered the correct path to snpEff.jar\"\n",
      "\n",
      "# run function on query results\n",
      "try:\n",
      "    df_to_snpeff(acmg_df)\n",
      "except Exception, e: \n",
      "    print str(e)"
     ],
     "language": "python",
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The functional annotations were read back into Python, parsed and matched back up with the variants by transcript id. If a transcript id was not available, variants were matched by chrom,pos,ref and alt allele."
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "157 variants annotated for coding consequences.\n"
       ]
      }
     ],
     "input": [
      "#import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# pull out rows that have no transcript id for positional matching\n",
      "no_tx = acmg_df[acmg_df['transcript_id'].isnull()]\n",
      "with_tx = acmg_df[acmg_df['transcript_id'].notnull()]\n",
      "\n",
      "# function to drop extra columns ending in _y from df merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "            \n",
      "def parse_snpeff(input_df, input_vcf):\n",
      "    # read in snpeff vcf file\n",
      "    annot_vcf = pd.read_csv(input_vcf, sep='\\t', skiprows=8)\n",
      "    # split info field into separate rows for each transcript\n",
      "    info_df = pd.Series([j for i in annot_vcf['INFO'].str.split(',') for j in i])\n",
      "    # split each rown into separate columns by the pipe\n",
      "    info_df = pd.DataFrame(list(info_df.str.split('|')))\n",
      "    # drop emtpy/unnecessary columns\n",
      "    info_df = info_df[list(info_df.columns[0:11])]\n",
      "    info_df.columns = ['alt', 'effect', 'impact', 'gene_name', 'gene_id', 'feature_type', 'transcript_id', \n",
      "                     'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']\n",
      "    # remove the annotation header 'ANN=' from the alt field\n",
      "    info_df['alt'] = info_df['alt'].str.replace('ANN=', '')\n",
      "    # keep only transcript level feature types\n",
      "    info_df = info_df[(info_df['feature_type'] == 'transcript')]\n",
      "    # merge annotations with variant table\n",
      "    df_functional = pd.merge(input_df, info_df, on=['transcript_id', 'alt'], how='left')  \n",
      "    drop_y(df_functional)\n",
      "    # rename columns ending in _x from merge\n",
      "    df_functional.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "    df_functional.drop_duplicates(inplace=True)\n",
      "    return df_functional\n",
      "\n",
      "def snpeff_notx(input_df, input_vcf):\n",
      "    # read in snpeff vcf file\n",
      "    annot_vcf = pd.read_csv(input_vcf, sep='\\t', skiprows=8)\n",
      "    # split info field into separate rows for each transcript\n",
      "    info_df = pd.Series([j for i in annot_vcf['INFO'].str.split(',') for j in i])\n",
      "    # split each rown into separate columns by the pipe\n",
      "    info_df = pd.DataFrame(list(info_df.str.split('|')))\n",
      "    # drop emtpy/unnecessary columns\n",
      "    info_df = info_df[list(info_df.columns[0:11])]\n",
      "    info_df.columns = ['alt', 'effect', 'impact', 'gene_name', 'gene_id', 'feature_type', 'transcript_id', \n",
      "                     'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']\n",
      "    # remove the annotation header 'ANN=' from the alt field\n",
      "    info_df['alt'] = info_df['alt'].str.replace('ANN=', '')\n",
      "    # keep only transcript level feature types\n",
      "    info_df = info_df[(info_df['feature_type'] == 'transcript')]\n",
      "    #merge annotations with variant table\n",
      "    df_functional = pd.merge(input_df, info_df, on=['chrom', 'pos', 'ref', 'alt'], how='left')  \n",
      "    drop_y(df_functional)\n",
      "    # rename columns ending in _x from merge\n",
      "    df_functional.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "    df_functional.drop_duplicates(inplace=True)\n",
      "    return df_functional\n",
      "\n",
      "# merge nbs_genes with functional annotations\n",
      "tx_annot = parse_snpeff(with_tx, 'clarity_acmg_snpeff.vcf')\n",
      "notx_annot = parse_snpeff(no_tx, 'clarity_acmg_snpeff.vcf')\n",
      "\n",
      "# merge data frames back together\n",
      "acmg_annot = pd.concat([tx_annot, notx_annot]).drop_duplicates().reset_index(drop=True)\n",
      "\n",
      "print str(len(acmg_annot)) + \" variants annotated for coding consequences.\""
     ],
     "language": "python",
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Locate Compound Heterozygotes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Newborn het variants were subset for variants inherited from het parents, and then grouped by gene and family: "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# disable erroneous pandas warning\n",
      "pd.options.mode.chained_assignment = None\n",
      "\n",
      "# add a family id column for comp_het analysis\n",
      "acmg_annot['family_id'] = acmg_annot['sample_id'].apply(lambda x: x.split('-')[0])\n",
      "\n",
      "#subset for het parent variants\n",
      "mom_hets = acmg_annot[((acmg_annot['member'] == 'M') & (acmg_annot['geno'] == 'het'))]\n",
      "dad_hets = acmg_annot[((acmg_annot['member'] == 'F') & (acmg_annot['geno'] == 'het'))]\n",
      "\n",
      "#subset newborn het variants\n",
      "nb_het1 = acmg_annot[((acmg_annot['member'] == 'NB1') & (acmg_annot['geno'] == 'het'))]\n",
      "nb_het2 = acmg_annot[((acmg_annot['member'] == 'NB2') & (acmg_annot['geno'] == 'het'))]\n",
      "nb_het3 = acmg_annot[((acmg_annot['member'] == 'NB3') & (acmg_annot['geno'] == 'het'))]"
     ],
     "language": "python",
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# function to find matching parent variants\n",
      "def find_parent_vars(nb_df, parent_df):\n",
      "    # merge dataframes on by variant position\n",
      "    merged_df = pd.merge(nb_df, parent_df, on=['chrom', 'pos', 'ref', 'alt'], how='inner')\n",
      "    # rename parent sample_id column to avoid dropping when removing '_y' cols\n",
      "    merged_df.rename(columns = {'member_y':'from_parent'}, inplace=True)\n",
      "    # drop extra y columns from merge with fathers\n",
      "    drop_y(merged_df)\n",
      "    #remove _x from colnames\n",
      "    merged_df.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "    return merged_df\n",
      "    \n",
      "# run function for each group of newborns\n",
      "def match_parents(nb_df):\n",
      "    if (len(mom_hets) > 0) and (len(dad_hets) > 0):\n",
      "        nb_and_mom = find_parent_vars(nb_df, mom_hets)\n",
      "        nb_and_dad = find_parent_vars(nb_df, dad_hets)\n",
      "        # merge variants found in either mother or father\n",
      "        het_cands = pd.concat([nb_and_mom,nb_and_dad]).drop_duplicates().reset_index(drop=True)\n",
      "        # group variants by gene name\n",
      "        by_gene = het_cands.groupby(['gene_name', 'family_id'])\n",
      "        return by_gene\n",
      "    else:\n",
      "        print \"No compound het variants\"\n",
      "        \n",
      "# run function for each group of newborns\n",
      "het1_grouped = match_parents(nb_het1)\n",
      "het2_grouped = match_parents(nb_het2)\n",
      "het3_grouped = match_parents(nb_het3)"
     ],
     "language": "python",
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After grouping the variants by gene and family, the variants will be filtered to keep only variants with at least one different variant coming from the mother and one from the father. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "No comp hets found.\n"
       ]
      }
     ],
     "input": [
      "# function to find compound hets\n",
      "def find_comphets(gene_group, comphet_list_name):\n",
      "    for name, group in gene_group:\n",
      "        # if there is a variant in more than one position\n",
      "        if group.pos.nunique() > 1:\n",
      "            # and there are more than one variants from both parents\n",
      "            if len(group[group['from_parent'] == 'M'] > 1) and len(group[group['from_parent'] == 'F'] > 1):\n",
      "                comphet_list_name.append(group)\n",
      "            # or if there is only one variant from each parent\n",
      "            elif len(group[group['from_parent'] == 'M'] == 1) and len(group[group['from_parent'] == 'F'] == 1):\n",
      "                # and those variants are different\n",
      "                if len(group[group['from_parent'] == 'M'].pos - group[group['from_parent'] == 'F']) > 0:\n",
      "                        comphet_list_name.append(group)\n",
      "\n",
      "# create empty list to store comp_hets\n",
      "comp_hets = []\n",
      "\n",
      "het1_df = find_comphets(het1_grouped, comp_hets)     \n",
      "het2_df = find_comphets(het2_grouped, comp_hets)\n",
      "het3_df = find_comphets(het3_grouped, comp_hets)\n",
      "\n",
      "# check if comphets found\n",
      "def comphet_check(df):\n",
      "    if df:\n",
      "        comp_hets.append(df)\n",
      "\n",
      "# check for each nb df\n",
      "comphet_check(het1_df)\n",
      "comphet_check(het2_df)\n",
      "comphet_check(het3_df)\n",
      "\n",
      "# if any comp  hets were found, append to list and convert to df\n",
      "if len(comp_hets) > 0:\n",
      "    comphet_df = pd.concat(comp_hets)\n",
      "    comphet_df.name = 'comp_het'\n",
      "else:\n",
      "    print 'No comp hets found.'\n",
      "    comphet_df = pd.DataFrame()\n",
      "    comphet_df.name = 'comp_het'"
     ],
     "language": "python",
     "prompt_number": 69
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Filtering Results for MOI"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import pandas as pd\n",
      "\n",
      "# disable erroneous pandas warning\n",
      "pd.options.mode.chained_assignment = None\n",
      "\n",
      "# report all dominant variants\n",
      "dominant = acmg_annot[(acmg_annot['inheritance'] == 'AD')]\n",
      "dominant.name = 'dominant'\n",
      "\n",
      "# report AR variants for hom_recessive genotypes\n",
      "recessive = acmg_annot[((acmg_annot['inheritance'] == 'AR') & (acmg_annot['gt'] == '1/1'))]\n",
      "recessive.name = 'recessive'"
     ],
     "language": "python",
     "prompt_number": 60
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Results Summary "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variants found: \n\n157 dominant variants found.\nCondition: \nProgressive_familial_heart_block_type_1A|not_specified|not_provided    110\nBrugada_syndrome_1|Long_QT_syndrome_3\\x2c_acquired\\x2c_susceptibility_to|not_provided|not_specified|Primary_familial_hypertrophic_cardiomyopathy     20\nBreast-ovarian_cancer\\x2c_familial_1|Familial_cancer_of_breast|Hereditary_cancer-predisposing_syndrome     18\nArrhythmogenic_right_ventricular_cardiomyopathy\\x2c_type_10|Cardiomyopathy\\x2c_dilated\\x2c_1bb\\x2c_susceptibility_to|not_specified|Arrhythmogenic_right_ventricular_cardiomyopathy|Primary_familial_hypertrophic_cardiomyopathy|Catecholaminergic_polymorphic_ventricular_tachycardia      6\nCardiomyopathy|not_specified|not_provided                         3\ndtype: int64 \n\nAffected gene(s): \n['SCN5A' 'DSG2' 'BRCA1' 'TMEM43' 'RP11-434D12.1'] \n\nNo recessive variants found. \n\nNo comp_het variants found. \n\n\n\n"
       ]
      }
     ],
     "input": [
      "# report variant counts\n",
      "def report_result_counts(results_df):\n",
      "    if len(results_df) > 0:\n",
      "        print str(len(results_df)) + ' {} variants found.'.format(results_df.name)\n",
      "        condition = results_df['clin_dbn'].value_counts()\n",
      "        genes = results_df['gene_name'].unique()\n",
      "        print 'Condition: \\n', condition, '\\n'\n",
      "        print 'Affected gene(s): \\n', genes, '\\n'\n",
      "    else:\n",
      "         print \"No {} variants found. \\n\".format(results_df.name)\n",
      "        \n",
      "print \"Variants found: \\n\"\n",
      "report_result_counts(dominant)\n",
      "report_result_counts(recessive)\n",
      "report_result_counts(comphet_df)\n",
      "print \"\\n\""
     ],
     "language": "python",
     "prompt_number": 70
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Save Results"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving 157 dominant variants to current working directory\nNo recessive variants to save.\nNo comp_het variants to save.\n"
       ]
      }
     ],
     "input": [
      "# add from_parent column to dom and rec so we can keep info for comp_het\n",
      "dominant['from_parent'] = 'NA'\n",
      "recessive['from_parent'] = 'NA'\n",
      "\n",
      "# merge and mark predicted variants\n",
      "def merge_predictors(df, out_list):\n",
      "    if len(df) > 0:\n",
      "        df['var_type'] = df.name\n",
      "        out_list.append(df)\n",
      "        print \"Saving {} {} variants to current working directory\".format(len(df), df.name)\n",
      "    else:\n",
      "        print \"No {} variants to save.\".format(df.name)\n",
      "\n",
      "# list to store combined output\n",
      "var_list = []            \n",
      "\n",
      "merge_predictors(dominant, var_list)\n",
      "merge_predictors(recessive, var_list)\n",
      "merge_predictors(comphet_df, var_list)\n",
      "\n",
      "# merge results\n",
      "merged_df = pd.concat(var_list, axis=0)\n",
      "\n",
      "# put the columns back in order because pandas\n",
      "cols = ['sample_id', 'chrom', 'pos', 'id', 'ref', 'alt', 'gt', 'qual', 'filter', 'rs_id', 'age_onset', \n",
      "        'inheritance', 'mim_disorder', 'mim_gene', 'phenotype', 'pmid_entry', 'variants_to_report', \n",
      "        'clin_hgvs', 'clin_sig', 'clin_dbn', 'kav_freq', 'geno', 'member', 'gene_id', 'transcript_id', \n",
      "        'strand', 'aa_alt', 'sift_score', 'sift_pred', 'polyphen2_hdiv_score', 'polyphen2_hdiv_pred', \n",
      "        'polyphen2_hvar_score', 'polyphen2_hvar_pred', 'fathmm_score', 'fathmm_pred', 'cadd_raw', 'dann_score', \n",
      "        'mutation_taster_pred', 'mutation_assessor_score', 'mutation_assessor_pred', 'provean_score', 'provean_pred', \n",
      "        'interpro_domain', 'exac_af', 'dbnfsp_predicted', 'effect', 'impact', 'gene_name', 'feature_type', \n",
      "        'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p', 'family_id', 'from_parent', 'var_type']\n",
      "\n",
      "merged_acmg = merged_df[cols]\n",
      "\n",
      "# save to file\n",
      "merged_acmg.to_csv('clarity_acmg.tsv', header=True, encoding='utf-8', index=False, sep='\\t')"
     ],
     "language": "python",
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0
}