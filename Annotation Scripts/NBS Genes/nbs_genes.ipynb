{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 1,
     "source": [
      "NBS Gene Annotation"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Purpose"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the following newborns:   \n",
      "\n",
      "102-07005-03  \n",
      "102-00997-03  \n",
      "102-00996-03  \n",
      "102-02001-03  \n",
      "102-00961-03  \n",
      "102-07009-03  \n",
      "102-00932-03  \n",
      "102-00979-03  \n",
      "102-01532-03  \n",
      "102-00974-03  \n",
      "\n",
      "Variants were annotated with the NBS gene table provided by Ben Solomon at ITMI. Variants located in NBS gene regions were filtered, keeping only variants with a Kaviar frequency less than 1%. Candidate variants were then annotated with ClinVar, DANN scores for SNV's and coding consequence predictions. Results were reported for Dominant, homozygous recessive and compound heterozygotes. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "6,927 variants were located in the NBS gene list. Of those variants: \n",
      "\n",
      "- 118 dominant variants found.  \n",
      "- 248 homozygous recessive variants found.  \n",
      "- 192 comp_het variants found. \n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dominant \n\nImpact: \nMODIFIER    56\nLOW         36\nMODERATE    26\ndtype: int64\n\n\nEffect: \n3_prime_UTR_variant                               52\nsynonymous_variant                                35\nmissense_variant                                  26\ndownstream_gene_variant                            2\n5_prime_UTR_variant                                2\n5_prime_UTR_premature_start_codon_gain_variant     1\ndtype: int64\n\n\nCondiction: \nChoreoathetosis: hypothyroidism: and neonatal respiratory distress    45\nPallister-Hall syndrome 2                                       33\nHypothyroidism: congenital: nongoitrous 2                       32\nHypothyroidism: congenital nongoitrous: 5                        8\ndtype: int64\n\n\nHomozygous Recessive \n\nImpact: \nMODERATE    111\nMODIFIER     71\nLOW          66\ndtype: int64\n\n\nEffect: \ndisruptive_inframe_deletion    60\nmissense_variant               51\n3_prime_UTR_variant            43\nTF_binding_site_variant        38\nsynonymous_variant             17\ndownstream_gene_variant        13\nsequence_feature                9\nintron_variant                  9\nupstream_gene_variant           4\nnon_coding_exon_variant         2\nsplice_region_variant           2\ndtype: int64\n\n\nCondiction: \nNiemann-Pick disease: type A: Niemann-Pick disease: type B      60\nAcyl-CoA dehydrogenase: very long chain: deficiency of          36\n  Mucopolysaccharidosis: type Ih (Hurler syndrome)              33\nAcyl-CoA dehydrogenase: medium chain: deficiency of             15\nSevere combined immunodeficiency                                14\nMethylmalonic acidemia: cblG type                               12\nHyperprolinemia: type I                                         10\nMitochondrial DNA depletion syndrome 9 (encephalomyopathic type with methylmalonic aciduria)     9\nMultiple acyl-CoA dehydrogenase deficiency: Glutaric aciduria IIC     8\nMaple syrup urine disease: type II                               7\nCombined malonic and methylmalonic aciduria                      6\nAlpha-methylacetoacetic aciduria                                 5\nMucopolysaccharidosis: type VII (Sly syndrome)                   4\nGalactosemia                                                     4\nHypothyroidism: congenital: nongoitrous: 1                       3\nDiabetes mellitus: neonatal: with congenital hypothyroidism      3\nBamforth-Lazarus syndrome                                        2\n3-beta-hydroxysteroid dehydrogenase: type II: deficiency         2\n3-methylglutaconic aciduria: type III                            2\nGalactose epimerase deficiency                                   2\nTrifunctional protein deficiency                                 2\nCystinosis (multiple types)                                      2\nHomocystinuria                                                   2\nT cell-negative: B cell-negative: natural killer cell-positive severe combined immunodeficiency: Omenn syndrome: Alpha/beta T-cell lymphopenia with gamma/delta T-cell expansion: severe cytomegalovirus infection: and autoimmunity: Combined cellular and humoral immune defects with granulomas     1\nMethylmalonic acidemia: cblB type                                1\nTranscobalamin II deficiency                                     1\nMethylmalonic acidemia due to methylmalonyl-CoA mutase deficiency     1\nMucopolysaccharidosis: type VI (Maroteaux-Lamy syndrome)         1\ndtype: int64\n\n\nCompound Heterozygous \n\nImpact: \nMODIFIER    79\nLOW         61\nMODERATE    52\ndtype: int64\n\n\nEffect: \nmissense_variant           52\n3_prime_UTR_variant        44\nsynonymous_variant         36\nsequence_feature           25\n5_prime_UTR_variant        15\ndownstream_gene_variant    12\nintron_variant              5\nnon_coding_exon_variant     2\nupstream_gene_variant       1\ndtype: int64\n\n\nCondiction: \n  Mucopolysaccharidosis: type Ih (Hurler syndrome)              23\nMultiple acyl-CoA dehydrogenase deficiency: Glutaric aciduria IIB    19\nMaple syrup urine disease: mild variant                         16\nTyrosinemia: type I                                             16\nCombined malonic and methylmalonic aciduria                     15\nCystic fibrosis                                                 10\nMaple syrup urine disease: type II                               9\nAcyl-CoA dehydrogenase family: member 9: deficiency of           9\nProlidase deficiency                                             9\nHolocarboxylase synthetase deficiency                            8\nMucopolysaccharidosis: type VII (Sly syndrome)                   7\nDiabetes mellitus: neonatal: with congenital hypothyroidism      6\nOmenn syndrome: Severe combined immunodeficiency with sensitivity to ionizing radiation     6\nGalactose epimerase deficiency                                   6\n3-methylglutaconic aciduria: type III                            5\nHyperprolinemia: type I                                          5\nTranscobalamin II deficiency                                     5\nThyroid dyshormonogenesis 4                                      4\nPhenylketonuria: Hyperphenylalaninemia: non-PKU mild             3\nBamforth-Lazarus syndrome                                        3\nAlpha-methylacetoacetic aciduria                                 2\nCarbamoylphosphate synthetase I deficiency                       2\nLipoid adrenal hyperplasi                                        2\nNiemann-Pick disease: type C1: Niemann-Pick disease: type D      2\ndtype: int64\n\n\n"
       ]
      }
     ],
     "input": [
      "def summarize(df):\n",
      "    impact = df['impact'].value_counts()\n",
      "    print \"Impact: \\n\", impact\n",
      "    print \"\\n\"\n",
      "    effect = df['effect'].value_counts()\n",
      "    print \"Effect: \\n\", effect\n",
      "    print \"\\n\"\n",
      "    condition = df['condition'].value_counts()\n",
      "    print \"Condiction: \\n\", condition\n",
      "    print \"\\n\"\n",
      "    \n",
      "print \"Dominant \\n\"    \n",
      "summarize(nb_dominant)\n",
      "\n",
      "print \"Homozygous Recessive \\n\"    \n",
      "summarize(nb_hom_recessive)\n",
      "    \n",
      "print \"Compound Heterozygous \\n\"    \n",
      "summarize(comphet_df)"
     ],
     "language": "python",
     "prompt_number": 58
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Transform of NBS Gene Table"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The NBS Gene Table provided by ITMI was transformed as follows and uploaded to impala:   \n",
      "\n",
      "- A 'level' column was added to represent the color coding found in the file, with the following options: red, yellow, null  \n",
      "- All commas were replaced with colons to prevent errors while importing csv file  \n",
      "- All semicolons were replaced with colons for consistency of data  \n",
      "- Spaces in column names were replaced with underscores  \n",
      "- Special characters were removed from column names"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding rare variants with Kaviar"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To reduce the number of variants input into downstream queries and analysis, all trio variants were annotated with kaviar frequencies, Keep only variants with a kaviar frequency less than .01, or variants not listed in the kaviar table.  \n",
      "\n",
      "         WITH bv AS (\n",
      "             SELECT bv.sample_id, bv.chr, bv.pos, bv.id, bv.ref, bv.alt, bv.qual, bv.filter, bv.gt\n",
      "             FROM p7_platform.brady_variant bv\n",
      "             WHERE (bv.sample_id LIKE '%03' OR bv.sample_id LIKE '%02' OR bv.sample_id LIKE '%01')\n",
      "          )\n",
      "  \n",
      "          SELECT bv.*, k.alle_freq\n",
      "          FROM bv\n",
      "          LEFT JOIN /* +SHUFFLE */ public_hg19.kaviar k\n",
      "               ON bv.chr = k.chromosome\n",
      "               AND bv.pos = k.pos\n",
      "               AND bv.ref = k.ref\n",
      "               AND bv.alt = k.alt\n",
      "         WHERE (k.alle_freq < .01 OR k.alle_freq IS NULL)\n",
      "\n",
      "Query Statements:   \n",
      "- Queries were limited to trio members, excluding more distant relatives  \n",
      "- Keep only variants with a kaviar frequency less than .01, or variants not listed in the kaviar table. \n",
      "\n",
      "Results were saved to an hdfs table named bv_kaviar. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding positional information to the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Chromosome, start and stop positions were added to the NBS Gene list by joining it with the \n",
      "ensembl_genes table using gene name. This resulted in mulitple listings per gene for each exon, \n",
      "allowing for more precise matches. \n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_positional AS SELECT nbs.gene, \n",
      "        nbs.entrez_gene_id as entrez_id, ens.gene_id AS ensembl_id, ens.chromosome as chrom, \n",
      "        ens.start, ens.stop, nbs.condition, nbs.omim_phenotype, nbs.va_name, nbs.inheritance, \n",
      "        nbs.allelic_condition, nbs.in_pgb, nbs.level, ens.feature, ens.transcript_name, \n",
      "        ens.transcript_id, ens.exon_number, ens.exon_id, ens.gene_biotype, nbs.comments\n",
      "        FROM users_selasady.nbs_genes nbs\n",
      "        LEFT JOIN\n",
      "                 public_hg19.ensembl_genes ens\n",
      "                ON nbs.gene = ens.gene_name\n",
      "\n",
      "The results were saved as users _ selasady.nbs _ ensembl containing 20872 rows. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Locate rare variants in the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next the Kaviar-filtered variants were joined with nbs _ ensembl using chromosome, start and stop positions, returning rare variants in the nbs_gene list, and annotated those with ClinVar. \n",
      "\n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_annotated AS \n",
      "            WITH nbs AS (\n",
      "            SELECT bv.sample_id, bv.chr as chrom, bv.pos, bv.id as rs_id, bv.ref, bv.alt, bv.qual, bv.filter,bv.gt, \n",
      "            bv.alle_freq AS kav_freq,nbs.gene, nbs.entrez_id, nbs.ensembl_id, nbs.condition, nbs.omim_phenotype, \n",
      "            nbs.va_name, nbs.inheritance, nbs.allelic_condition,nbs.in_pgb, nbs.level, nbs.feature, \n",
      "            nbs.transcript_name, nbs.transcript_id, nbs.exon_number, nbs.exon_id, nbs.gene_biotype, nbs.comments\n",
      "            FROM public_hg19.bv_kaviar bv, users_selasady.nbs_ensembl nbs\n",
      "            WHERE bv.chr = nbs.chrom\n",
      "            AND bv.pos BETWEEN nbs.start and nbs.stop\n",
      "            )\n",
      "  \n",
      "           SELECT nbs.*, clin.clin_hgvs, clin.clin_sig, clin.clin_dbn, clin.clin_acc \n",
      "           FROM nbs\n",
      "           LEFT JOIN public_hg19.clinvar clin\n",
      "               ON nbs.rs_id = clin.id\n",
      "\n",
      "6927 rows were returned, the table was saved as users _ selasady.nbs_annotated. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding DANN scores  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "DANN scores whole-genome variants by training a deep neural network (DNN). DNNs can capture non-linear relationships among features, and are better suited than SVMs for problems with a large number of samples and features. DANN scores have been shown to outperform both CADD and FATHMM (http://www.enlis.com/blog/2015/03/17/the-best-variant-prediction-method-that-no-one-is-using/).\n",
      "\n",
      "DANN scores are provided for SNV's and range between 0 and 1. The closer a score is to 1, the more pathogenic the variant. \n",
      "\n",
      "The following query was used to annotate the nbs variants with DANN scores by matching on chromosome and position, then outputting the score for the alt allele. \n",
      "\n",
      "\tSELECT n.*, CASE \n",
      "             WHEN n.alt = 'A' then d.score_a\n",
      "             WHEN n.alt = 'T' then d.score_t\n",
      "             WHEN n.alt = 'G' then d.score_g\n",
      "             WHEN n.alt = 'C' then d.score_c\n",
      "        END as dann_score \n",
      "        FROM users_selasady.nbs_annotated n\n",
      "        LEFT JOIN public_hg19.DANN d\n",
      "            ON n.chrom = d.chrom"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reading the impala results into python"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "#################\n",
      "# load modules  #\n",
      "#################\n",
      "import pandas as pd\n",
      "from impala.dbapi import connect\n",
      "from impala.util import as_pandas\n",
      "\n",
      "#create database connection\n",
      "conn = connect(host='glados19', port=21050)\n",
      "cur = conn.cursor()\n",
      "\n",
      "# query to left join nbs_annotated variants with DANN scores\n",
      "query = \"\"\"\n",
      "    SELECT * FROM users_selasady.nbs_dann\n",
      "    \"\"\"\n",
      "# run query on impala\n",
      "cur.execute(query)\n",
      "\n",
      "#store results as pandas data frame\n",
      "nbs_df = as_pandas(cur)"
     ],
     "language": "python",
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataframe was separated into mother, father and newborn for downstream analysis. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "newborns = nbs_df[nbs_df['sample_id'].str.endswith('03')]\n",
      "mothers = nbs_df[nbs_df['sample_id'].str.endswith('01')]\n",
      "fathers = nbs_df[nbs_df['sample_id'].str.endswith('02')]"
     ],
     "language": "python",
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding Functional Annotation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn set was output to a modified version of Plink's tab2vcf script to create a VCF file for use with SnpEff. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "newborns.tsv\n0 1 2 3\n"
       ]
      }
     ],
     "input": [
      "import os\n",
      "import sys\n",
      "\n",
      "# output columns to vcf file using a modified version of anntools tab2vcf.py\n",
      "nb_to_vcf = newborns[['chrom','pos', 'ref', 'alt']]\n",
      "\n",
      "\n",
      "# write to file for conversion to vcf\n",
      "nb_to_vcf.to_csv('{}/newborns.tsv'.format(os.getcwd()), header=True, encoding='utf-8', sep=\"\\t\", index=False)\n",
      "\n",
      "# run tab2vcf.py script\n",
      "try:\n",
      "    %run ./tab2vcf.py newborns.tsv\n",
      "except Exception,e: print str(e)"
     ],
     "language": "python",
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn variants in the VCF file were annotated with coding consequences using SnpEff version 4.1h (build 2015-08-03) with _GRCh37.75. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# run SnpEff on newborns.vcf for windows\n",
      "#!java -Xmx4g -jar `cygpath -m /cygdrive/D/Documents/tools/snpEff/snpEff.jar` -v GRCh37.75 ./newborns.tsv.vcf > \n",
      "# newborns_annot.vcf"
     ],
     "language": "python",
     "prompt_number": 108
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The annotations were read back into Python, parsed and matched with the newborn variant data frame."
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import numpy as np\n",
      "# read in vcf as tsv file, skipping header\n",
      "annot_vcf = pd.read_csv('newborns_annot.vcf', sep='\\t', skiprows=8)\n",
      "\n",
      "# split info columns by \"|\" and keep most detrimental consequence (first)\n",
      "info_df = pd.DataFrame(list(annot_vcf['INFO'].str.split('|')))\n",
      "# keep only first consequence listed\n",
      "info_df = info_df[list(info_df.columns[1:11])]\n",
      "\n",
      "# merge annotations with annot_vcf\n",
      "annot_vcf = annot_vcf[np.r_[0:2,3, 4]]\n",
      "annot_df = pd.concat([annot_vcf, info_df], axis=1)\n",
      "# remove duplicated rows\n",
      "annot_df.drop_duplicates(inplace=True)\n",
      "# rename columns\n",
      "annot_df.columns = ['chrom', 'pos', 'ref', 'alt', 'effect', 'impact','gene_name', 'gene_id', 'feature_type', \n",
      "                    'feature_id', 'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']\n",
      "\n",
      "# merge annotations with newborn variant table\n",
      "newborn_annot = pd.merge(newborns, annot_df, on=['chrom', 'pos', 'ref', 'alt'], how='left')\n",
      "\n",
      "# drop columns with duplicated info after merge\n",
      "newborn_annot.drop(['gene_name', 'gene_id', 'feature_type', 'feature_id', 'tx_biotype'], axis=1, inplace=True)"
     ],
     "language": "python",
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reporting dominant and homozygous recessive variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn subset was split into dominant, homozygous recessive and heterozygous variants for downstream analysis. \n",
      "\n",
      "A family id column was added for downstream matching. A variant id composed of chrom:pos:ref:alt was added for matching nb comp_het variants with parent variants.  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "118 dominant variants found.\n248 homozygous recessive variants found.\n"
       ]
      }
     ],
     "input": [
      "# disable erroneous pandas warning\n",
      "pd.options.mode.chained_assignment = None\n",
      "\n",
      "# subset newborns by variant zygosity\n",
      "nb_dominant = newborn_annot[(newborn_annot['inheritance'] == 'AD')]\n",
      "nb_hom_recessive = newborn_annot[((newborn_annot['inheritance'] == 'AR') & (newborn_annot['gt'] == '1/1'))]\n",
      "nb_het = newborn_annot[((newborn_annot['inheritance'] == 'AR') & (newborn_annot['gt'] == '0/1'))]\n",
      "\n",
      "# add family id to simplify variant matching\n",
      "nb_het['family_id'] = nb_het['sample_id'].apply(lambda x: x[:-3])\n",
      "mothers['family_id'] = mothers['sample_id'].apply(lambda x: x[:-3])\n",
      "fathers['family_id'] = fathers['sample_id'].apply(lambda x: x[:-3])\n",
      "\n",
      "# add variant id's to simplify variant matching\n",
      "nb_het['var_id'] = nb_het.apply(lambda x:'{}:{}:{}:{}:{}'.format(x['chrom'],x['pos'], x['ref'], x['alt'],\n",
      "                                                                 x['family_id']),axis=1)\n",
      "mothers['var_id'] = mothers.apply(lambda x:'{}:{}:{}:{}:{}'.format(x['chrom'],x['pos'], x['ref'], x['alt'], \n",
      "                                                                   x['family_id']),axis=1)\n",
      "fathers['var_id'] = fathers.apply(lambda x:'{}:{}:{}:{}:{}'.format(x['chrom'],x['pos'], x['ref'], x['alt'], \n",
      "                                                                   x['family_id']),axis=1)\n",
      "\n",
      "print str(len(nb_dominant)) + \" dominant variants found.\"\n",
      "print str(len(nb_hom_recessive)) + \" homozygous recessive variants found.\""
     ],
     "language": "python",
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reporting heterozygous recessive variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Heterozygous recessive newborn variants were examined for compound heterozygosity, keeping only variants where the parents are also heterozygous for that variant. \n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# merge het newborns with matching variants from father \n",
      "nb_and_dad = pd.merge(nb_het, fathers, on=['var_id'], how='inner')\n",
      "\n",
      "# rename father's sample_id column\n",
      "nb_and_dad.rename(columns = {'sample_id_y':'sample_id_f'}, inplace=True)\n",
      "\n",
      "# drop extra columns ending in _y from merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "\n",
      "# drop extra y columns from merge with fathers\n",
      "drop_y(nb_and_dad)\n",
      "#remove _x from colnames\n",
      "nb_and_dad.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "\n",
      "# subset to keep only heterozygous variants\n",
      "nb_and_dad = nb_and_dad[(nb_and_dad['gt'] == '0/1')]\n",
      "\n",
      "# merge het newborns with matching variants from mother \n",
      "nb_and_mom = pd.merge(nb_het, mothers, on=['var_id'], how='inner')\n",
      "# rename mother's sample_id column\n",
      "nb_and_mom.rename(columns = {'sample_id_y':'sample_id_m'}, inplace=True)\n",
      "\n",
      "# drop extra columns ending in _y from merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "\n",
      "# drop extra y columns from merge with fathers\n",
      "drop_y(nb_and_mom)\n",
      "#remove _x from colnames\n",
      "nb_and_mom.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "\n",
      "# subset to keep only heterozygous variants\n",
      "nb_and_mom = nb_and_mom[(nb_and_mom['gt'] == '0/1')]"
     ],
     "language": "python",
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After creating data frames for variants that have a match from either the mother or father, the newborn het dataframe is subset for only variants in either set, and then grouped by gene name to search within genes for compound heterozygosity. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1324 candidate variants found for compound heterozygosity.\n"
       ]
      }
     ],
     "input": [
      "# subset nb_hets for only variants found in either mother or father\n",
      "het_cands = (nb_het[(nb_het['var_id'].isin(nb_and_dad['var_id']) | nb_het['var_id'].isin(nb_and_mom['var_id']))])\n",
      "\n",
      "#subset het variants to include only recessive \n",
      "het_cands = het_cands[(het_cands['inheritance'] == 'AR')]\n",
      "\n",
      "print str(len(het_cands)) + \" candidate variants found for compound heterozygosity.\"\n",
      "\n",
      "# group variants by gene name\n",
      "by_gene = het_cands.groupby(['gene', 'family_id'])"
     ],
     "language": "python",
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Search for genes that contain newborn variants at more than one position; if those genes have variants from both parents at different positions, mark as compound het. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "192 comp_het variants found\n"
       ]
      }
     ],
     "input": [
      "# create empty list to hold comp_hets\n",
      "comp_hets = []\n",
      "\n",
      "for name, group in by_gene:\n",
      "    #if there is a variant in more than one position\n",
      "    if group.pos.nunique() > 1:\n",
      "        # and there are more than one variants from both parents\n",
      "        if (len(group[(group['var_id'].isin(nb_and_dad['var_id']))] > 1) and \\\n",
      "                len(group[(group['var_id'].isin(nb_and_mom['var_id']))] > 1)):\n",
      "            comp_hets.append(group)\n",
      "        # or if there is a variant from both parents\n",
      "        elif (len(group[(group['var_id'].isin(nb_and_dad['var_id']))] > 0) and \\\n",
      "                len(group[(group['var_id'].isin(nb_and_mom['var_id']))] > 0)):\n",
      "            # and those variants are different\n",
      "            if len(group[(group['var_id'].isin(fathers['var_id']))].pos - group[(group['var_id'].isin(mothers['var_id']))].pos) > 0:\n",
      "                    comp_hets.append(group)\n",
      "\n",
      "# combine results into dataframe                    \n",
      "comphet_df = pd.concat(comp_hets)\n",
      "\n",
      "print str(len(comphet_df)) + \" comp_het variants found.\""
     ],
     "language": "python",
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Saving Output"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving 192 het variants to nb_het.csv in current working directory\nSaving 118 dominant variants to nb_dominant.csv in current working directory\nSaving 248 homozygous recessive variants to nb_hom_recessive.csv in current working directory\n"
       ]
      }
     ],
     "input": [
      "# save output to current working directory\n",
      "\n",
      "print \"Saving \" + str(len(comphet_df)) + \" het variants to nb_het.csv in current working directory\"\n",
      "comphet_df.to_csv('nb_het.csv', header=True, encoding='utf-8', index=False)\n",
      "\n",
      "print \"Saving \" + str(len(nb_dominant)) + \" dominant variants to nb_dominant.csv in current working directory\"\n",
      "nb_dominant.to_csv('nb_dominant.csv', header=True, encoding='utf-8', index=False)\n",
      "\n",
      "print \"Saving \" + str(len(nb_hom_recessive)) + \" homozygous recessive variants to nb_hom_recessive.csv in current working directory\"\n",
      "nb_hom_recessive.to_csv('nb_hom_recessive.csv', header=True, encoding='utf-8', index=False)"
     ],
     "language": "python",
     "prompt_number": 33
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0
}