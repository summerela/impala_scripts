{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 1,
     "source": [
      "NBS Gene Annotation"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Purpose"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the following newborns:   \n",
      "\n",
      "102-07005-03  \n",
      "102-00997-03  \n",
      "102-00996-03  \n",
      "102-02001-03  \n",
      "102-00961-03  \n",
      "102-07009-03  \n",
      "102-00932-03  \n",
      "102-00979-03  \n",
      "102-01532-03  \n",
      "102-00974-03  \n",
      "\n",
      "Variants were annotated with the NBS gene table provided by Ben Solomon at ITMI. Variants located in NBS gene regions were filtered, keeping only variants with a Kaviar frequency less than 1%. Candidate variants were then annotated with ClinVar, DANN scores for SNV's and coding consequence predictions. Results were reported for Dominant, homozygous recessive and compound heterozygotes. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Transform of NBS Gene Table"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The NBS Gene Table provided by ITMI was transformed as follows and uploaded to impala:   \n",
      "\n",
      "- A 'level' column was added to represent the color coding found in the file, with the following options: red, yellow, null  \n",
      "- All commas were replaced with colons to prevent errors while importing csv file  \n",
      "- All semicolons were replaced with colons for consistency of data  \n",
      "- Spaces in column names were replaced with underscores  \n",
      "- Special characters were removed from column names"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding rare variants with Kaviar"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To reduce the number of variants input into downstream queries and analysis, all trio variants were annotated with kaviar frequencies, Keep only variants with a kaviar frequency less than .01, or variants not listed in the kaviar table.  \n",
      "\n",
      "         WITH bv AS (\n",
      "             SELECT bv.sample_id, bv.chr, bv.pos, bv.id, bv.ref, bv.alt, bv.qual, bv.filter, bv.gt\n",
      "             FROM p7_platform.brady_variant bv\n",
      "             WHERE (bv.sample_id LIKE '%03' OR bv.sample_id LIKE '%02' OR bv.sample_id LIKE '%01')\n",
      "          )\n",
      "  \n",
      "          SELECT bv.*, k.alle_freq\n",
      "          FROM bv\n",
      "          LEFT JOIN /* +SHUFFLE */ public_hg19.kaviar k\n",
      "               ON bv.chr = k.chromosome\n",
      "               AND bv.pos = k.pos\n",
      "               AND bv.ref = k.ref\n",
      "               AND bv.alt = k.alt\n",
      "         WHERE (k.alle_freq < .01 OR k.alle_freq IS NULL)\n",
      "\n",
      "Query Statements:   \n",
      "- Queries were limited to trio members, excluding more distant relatives  \n",
      "- Keep only variants with a kaviar frequency less than .01, or variants not listed in the kaviar table. \n",
      "\n",
      "Results were saved to an hdfs table named bv_kaviar. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding positional information to the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Chromosome, start and stop positions were added to the NBS Gene list by joining it with the \n",
      "ensembl_genes table using gene name. This resulted in mulitple listings per gene for each exon, \n",
      "allowing for more precise matches. \n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_positional AS SELECT nbs.gene, \n",
      "        nbs.entrez_gene_id as entrez_id, ens.gene_id AS ensembl_id, ens.chromosome as chrom, \n",
      "        ens.start, ens.stop, nbs.condition, nbs.omim_phenotype, nbs.va_name, nbs.inheritance, \n",
      "        nbs.allelic_condition, nbs.in_pgb, nbs.level, ens.feature, ens.transcript_name, \n",
      "        ens.transcript_id, ens.exon_number, ens.exon_id, ens.gene_biotype, nbs.comments\n",
      "        FROM users_selasady.nbs_genes nbs\n",
      "        LEFT JOIN\n",
      "                 public_hg19.ensembl_genes ens\n",
      "                ON nbs.gene = ens.gene_name\n",
      "\n",
      "The results were saved as users _ selasady.nbs _ ensembl containing 20872 rows. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Locate rare variants in the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next the Kaviar-filtered variants were joined with nbs _ ensembl using chromosome, start and stop positions, returning rare variants in the nbs_gene list, and annotated those with ClinVar. \n",
      "\n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_annotated AS \n",
      "            WITH nbs AS (\n",
      "            SELECT bv.sample_id, bv.chr as chrom, bv.pos, bv.id as rs_id, bv.ref, bv.alt, bv.qual, bv.filter,bv.gt, \n",
      "            bv.alle_freq AS kav_freq,nbs.gene, nbs.entrez_id, nbs.ensembl_id, nbs.condition, nbs.omim_phenotype, \n",
      "            nbs.va_name, nbs.inheritance, nbs.allelic_condition,nbs.in_pgb, nbs.level, nbs.feature, \n",
      "            nbs.transcript_name, nbs.transcript_id, nbs.exon_number, nbs.exon_id, nbs.gene_biotype, nbs.comments\n",
      "            FROM public_hg19.bv_kaviar bv, users_selasady.nbs_ensembl nbs\n",
      "            WHERE bv.chr = nbs.chrom\n",
      "            AND bv.pos BETWEEN nbs.start and nbs.stop\n",
      "            )\n",
      "  \n",
      "           SELECT nbs.*, clin.clin_hgvs, clin.clin_sig, clin.clin_dbn, clin.clin_acc \n",
      "           FROM nbs\n",
      "           LEFT JOIN public_hg19.clinvar clin\n",
      "               ON nbs.rs_id = clin.id\n",
      "\n",
      "6927 rows were returned, the table was saved as users _ selasady.nbs_annotated. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding DANN scores  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "DANN scores whole-genome variants by training a deep neural network (DNN). DNNs can capture non-linear relationships among features, and are better suited than SVMs for problems with a large number of samples and features. DANN scores have been shown to outperform both CADD and FATHMM (http://www.enlis.com/blog/2015/03/17/the-best-variant-prediction-method-that-no-one-is-using/).\n",
      "\n",
      "DANN scores are provided for SNV's and range between 0 and 1. The closer a score is to 1, the more pathogenic the variant. \n",
      "\n",
      "The following query was used to annotate the nbs variants with DANN scores by matching on chromosome and position, then outputting the score for the alt allele. \n",
      "\n",
      "\tSELECT n.*, CASE \n",
      "             WHEN n.alt = 'A' then d.score_a\n",
      "             WHEN n.alt = 'T' then d.score_t\n",
      "             WHEN n.alt = 'G' then d.score_g\n",
      "             WHEN n.alt = 'C' then d.score_c\n",
      "        END as dann_score \n",
      "        FROM users_selasady.nbs_annotated n\n",
      "        LEFT JOIN public_hg19.DANN d\n",
      "            ON n.chrom = d.chrom"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reading the impala results into python"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "#################\n",
      "# load modules  #\n",
      "#################\n",
      "import pandas as pd\n",
      "from impala.dbapi import connect\n",
      "from impala.util import as_pandas\n",
      "\n",
      "#create database connection\n",
      "conn = connect(host='glados19', port=21050)\n",
      "cur = conn.cursor()\n",
      "\n",
      "# query to left join nbs_annotated variants with DANN scores\n",
      "query = \"\"\"\n",
      "    SELECT * FROM users_selasady.nbs_dann\n",
      "    \"\"\"\n",
      "# run query on impala\n",
      "cur.execute(query)\n",
      "\n",
      "#store results as pandas data frame\n",
      "nbs_df = as_pandas(cur)"
     ],
     "language": "python",
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding Functional Annotation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn set was output to a modified version of Plink's tab2vcf script to create a VCF file for use with SnpEff. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn variants in the VCF file were annotated with coding consequences using SnpEff version 4.1h (build 2015-08-03) with GRCh37.75. \n",
      "\n",
      "The functional annotations were read back into Python, parsed and matched with the each respective variant data frame."
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import numpy as np\n",
      "# read in vcf as tsv file, skipping header\n",
      "annot_vcf = pd.read_csv('newborns_annot.vcf', sep='\\t', skiprows=8)\n",
      "\n",
      "# split info columns by \"|\" and keep most detrimental consequence (first)\n",
      "info_df = pd.DataFrame(list(annot_vcf['INFO'].str.split('|')))\n",
      "# keep only first consequence listed\n",
      "info_df = info_df[list(info_df.columns[1:11])]\n",
      "\n",
      "# merge annotations with annot_vcf\n",
      "annot_vcf = annot_vcf[np.r_[0:2,3, 4]]\n",
      "annot_df = pd.concat([annot_vcf, info_df], axis=1)\n",
      "# remove duplicated rows\n",
      "annot_df.drop_duplicates(inplace=True)\n",
      "# rename columns\n",
      "annot_df.columns = ['chrom', 'pos', 'ref', 'alt', 'effect', 'impact','gene_name', 'gene_id', 'feature_type', \n",
      "                    'feature_id', 'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']\n",
      "\n",
      "# merge annotations with newborn variant table\n",
      "newborn_annot = pd.merge(newborns, annot_df, on=['chrom', 'pos', 'ref', 'alt'], how='left')\n",
      "\n",
      "# drop columns with duplicated info after merge\n",
      "newborn_annot.drop(['gene_name', 'gene_id', 'feature_type', 'feature_id', 'tx_biotype'], axis=1, inplace=True)"
     ],
     "language": "python",
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import os\n",
      "import numpy as np\n",
      "\n",
      "# function to add functional annotation\n",
      "def df_to_snpeff(input_df, out_name):\n",
      "    # subset columns to output to vcf file\n",
      "    df = input_df[['chrom', 'pos', 'ref', 'alt']]\n",
      "    # write to file for conversion to vcf\n",
      "    df.to_csv('{}/{}.tsv'.format(os.getcwd(), out_name), header=True, encoding='utf-8', sep=\"\\t\", index=False)\n",
      "    # run tab2vcf.py script\n",
      "    os.system(\"./tab2vcf.py '{}/{}.tsv'.format(os.getcwd(), out_name)\")\n",
      "    #os.system(\"java -Xmx4g -jar /Users/summerrae/tools/snpEff/snpEff.jar -v GRCh37.75 '{}/{}.tsv'.format(os.getcwd(), out_name) > '{}_annot'.format(out_name)\")\n",
      "\n",
      "df_to_snpeff(nbs_df, 'nbs_genes')\n",
      "    \n",
      "# def vcf_to_snpeff(vcf, annot_outfile_name):\n",
      "#     # run SnpEff on vcf file\n",
      "#     #!java -Xmx4g -jar `cygpath -m /cygdrive/D/Documents/tools/snpEff/snpEff.jar` \\\n",
      "#          #-v GRCh37.75 {vcf} > {'{}/{}.vcf'.format(os.getcwd(), out_name)}\n",
      "#     os.system('java -Xmx4g -jar /Users/summerrae/tools/snpEff/snpEff.jar -v GRCh37.75 {vcf} > {annot_outfile_name)}'\n",
      "#     # # read in vcf as tsv file, skipping header\n",
      "#     # annot_vcf = pd.read_csv('{}/{}.vcf'.format(os.getcwd(), out_name), sep='\\t', skiprows=8)\n",
      "#     # # split info columns by \"|\" and keep most detrimental consequence (first)\n",
      "#     # info_df = pd.DataFrame(list(annot_vcf['INFO'].str.split('|')))\n",
      "#     # # keep only first consequence listed\n",
      "#     # info_df = info_df[list(info_df.columns[1:11])]\n",
      "#     # # merge annotations with annot_vcf\n",
      "#     # annot_vcf = annot_vcf[np.r_[0:2, 3, 4]]\n",
      "#     # annot_df = pd.concat([annot_vcf, info_df], axis=1)\n",
      "#     # # remove duplicated rows\n",
      "#     # annot_df.drop_duplicates(inplace=True)\n",
      "#     # # rename columns\n",
      "#     # annot_df.columns =['chrom', 'pos', 'ref', 'alt', 'effect', 'impact', 'gene_name', 'gene_id', 'feature_type', \\\n",
      "#     #     'feature_id', 'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']\n",
      "#     # # merge annotations with variant table\n",
      "#     # df_func_annot = pd.merge(input_df, annot_df, on=['chrom', 'pos', 'ref', 'alt'], how='left')\n",
      "#     # # drop columns with duplicated info after merge\n",
      "#     # df_func_annot.drop(['gene_name', 'gene_id', 'feature_id', 'feature_type', 'tx_biotype'], axis=1, inplace=True) \\\n",
      "# \n",
      "# test = vcf_to_snpeff('test.tsv.vcf')"
     ],
     "language": "python",
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "ename": "SystemExit",
       "evalue": "2",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/IPython/utils/py3compat.pyc\u001b[0m in \u001b[0;36mexecfile\u001b[0;34m(fname, glob, loc, compiler)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mwhere\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mns\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mns\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcompiler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mbuiltin_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mscripttext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltin_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/summerrae/impala_scripts/tab2vcf.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetavar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Enter the full file path to the tsv file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_tsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/argparse.pyc\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized arguments: %s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/argparse.pyc\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2372\u001b[0m         \"\"\"\n\u001b[1;32m   2373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s: error: %s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/argparse.pyc\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mSystemExit\u001b[0m: 2"
       ]
      }
     ],
     "input": [
      "%tb"
     ],
     "language": "python",
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataframe was separated into mother, father and newborn for downstream analysis. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "newborns = nbs_df[nbs_df['sample_id'].str.endswith('03')]\n",
      "mothers = nbs_df[nbs_df['sample_id'].str.endswith('01')]\n",
      "fathers = nbs_df[nbs_df['sample_id'].str.endswith('02')]"
     ],
     "language": "python"
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reporting dominant and homozygous recessive variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn subset was split into dominant, homozygous recessive and heterozygous variants for downstream analysis. \n",
      "\n",
      "A family id column was added for downstream matching. A variant id composed of chrom:pos:ref:alt was added for matching nb comp_het variants with parent variants.  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "118 dominant variants found.\n248 homozygous recessive variants found.\n"
       ]
      }
     ],
     "input": [
      "# disable erroneous pandas warning\n",
      "pd.options.mode.chained_assignment = None\n",
      "\n",
      "# subset newborns by variant zygosity\n",
      "nb_dominant = newborn_annot[(newborn_annot['inheritance'] == 'AD')]\n",
      "nb_hom_recessive = newborn_annot[((newborn_annot['inheritance'] == 'AR') & (newborn_annot['gt'] == '1/1'))]\n",
      "nb_het = newborn_annot[((newborn_annot['inheritance'] == 'AR') & (newborn_annot['gt'] == '0/1'))]\n",
      "\n",
      "# add family id to simplify variant matching\n",
      "nb_het['family_id'] = nb_het['sample_id'].apply(lambda x: x[:-3])\n",
      "mothers['family_id'] = mothers['sample_id'].apply(lambda x: x[:-3])\n",
      "fathers['family_id'] = fathers['sample_id'].apply(lambda x: x[:-3])\n",
      "\n",
      "# add variant id's to simplify variant matching\n",
      "nb_het['var_id'] = nb_het.apply(lambda x:'{}:{}:{}:{}:{}'.format(x['chrom'],x['pos'], x['ref'], x['alt'],\n",
      "                                                                 x['family_id']),axis=1)\n",
      "mothers['var_id'] = mothers.apply(lambda x:'{}:{}:{}:{}:{}'.format(x['chrom'],x['pos'], x['ref'], x['alt'], \n",
      "                                                                   x['family_id']),axis=1)\n",
      "fathers['var_id'] = fathers.apply(lambda x:'{}:{}:{}:{}:{}'.format(x['chrom'],x['pos'], x['ref'], x['alt'], \n",
      "                                                                   x['family_id']),axis=1)\n",
      "\n",
      "print str(len(nb_dominant)) + \" dominant variants found.\"\n",
      "print str(len(nb_hom_recessive)) + \" homozygous recessive variants found.\""
     ],
     "language": "python",
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reporting compound heterozygous recessive variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Heterozygous recessive newborn variants were examined for compound heterozygosity, keeping only variants that the parents were heterozygous for, and that matched with a het newborn variant. \n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# function to drop extra columns ending in _y from df merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "\n",
      "########################################\n",
      "## Find matching variants from father ## \n",
      "########################################\n",
      "# merge het newborns with matching variants from father \n",
      "nb_and_dad = pd.merge(nb_het, fathers, on=['var_id'], how='inner')\n",
      "# rename father's sample_id column\n",
      "nb_and_dad.rename(columns = {'sample_id_y':'sample_id_dad'}, inplace=True)\n",
      "# drop extra y columns from merge with fathers\n",
      "drop_y(nb_and_dad)\n",
      "#remove _x from colnames\n",
      "nb_and_dad.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "# subset to keep only heterozygous, pathogenic variants\n",
      "nb_and_dad = nb_and_dad[(nb_and_dad['gt'] == '0/1')]\n",
      "\n",
      "########################################\n",
      "## Find matching variants from mother ## \n",
      "########################################\n",
      "# merge het newborns with matching variants from mother \n",
      "nb_and_mom = pd.merge(nb_het, mothers, on=['var_id'], how='inner')\n",
      "# rename mother's sample_id column\n",
      "nb_and_mom.rename(columns = {'sample_id_y':'sample_id_mom'}, inplace=True)\n",
      "# drop extra y columns from merge with fathers\n",
      "drop_y(nb_and_mom)\n",
      "#remove _x from colnames\n",
      "nb_and_mom.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "# subset to keep only heterozygous, pathogenic variants\n",
      "nb_and_mom = nb_and_mom[(nb_and_mom['gt'] == '0/1')]"
     ],
     "language": "python",
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After creating data frames for variants that have a match from either the mother or father, the newborn het dataframe is subset for only recessive variants that have a match to either the father or the mother (dominant have already been identified), the remaining variants are grouped by gene name to search for genes with variants in more than on position. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# subset nb_hets for only variants found in either mother or father\n",
      "het_cands = (nb_het[(nb_het['var_id'].isin(nb_and_dad['var_id']) | nb_het['var_id'].isin(nb_and_mom['var_id']))])\n",
      "\n",
      "#subset het variants to include only recessive \n",
      "het_cands = het_cands[(het_cands['inheritance'] == 'AR')]\n",
      "\n",
      "# group variants by gene name\n",
      "by_gene = het_cands.groupby(['gene', 'family_id'])"
     ],
     "language": "python",
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After grouping the filtered nb het variants by gene, the variants will be filtered to keep only variants with pathogenic mutations at more than one position. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "192 comp_het variants found.\n"
       ]
      }
     ],
     "input": [
      "# create empty list to hold comp_hets\n",
      "comp_hets = []\n",
      "\n",
      "for name, group in by_gene:\n",
      "    #if there is a variant in more than one position\n",
      "    if group.pos.nunique() > 1:\n",
      "        # and there are more than one variants from both parents\n",
      "        if (len(group[(group['var_id'].isin(nb_and_dad['var_id']))] > 1) and \\\n",
      "                len(group[(group['var_id'].isin(nb_and_mom['var_id']))] > 1)):\n",
      "            comp_hets.append(group)\n",
      "        # or if there is a variant from both parents\n",
      "        elif (len(group[(group['var_id'].isin(nb_and_dad['var_id']))] > 0) and \\\n",
      "                len(group[(group['var_id'].isin(nb_and_mom['var_id']))] > 0)):\n",
      "            # and those variants are different\n",
      "            if len(group[(group['var_id'].isin(fathers['var_id']))].pos - group[(group['var_id'].isin(mothers['var_id']))].pos) > 0:\n",
      "                    comp_hets.append(group)\n",
      "\n",
      "# combine results into dataframe                    \n",
      "comphet_df = pd.concat(comp_hets)\n",
      "\n",
      "print str(len(comphet_df)) + \" comp_het variants found.\""
     ],
     "language": "python",
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding newborns predicted to have NBS conditions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dominant, homozgous recessive and compound heterozygous recessive candidate variants were filtered to locate \n",
      "newborns predicted to have NBS conditions:    \n",
      "\n",
      "- Presence of mutation(s) with appropriate inheritance using filtering procedures outlined above  \n",
      "- Mutations defined strictly as either:   \n",
      "    - Clearly annotated in ClinVar, HGMD or both, as pathogenic or disease-causing for the NBS condition   \n",
      "     OR  \n",
      "    - Novel but predicted to be disease-causing (ie, a stop-gain, stop-loss, splice-site, whole-exon or larger deletion, or frameshift).  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3_prime_UTR_variant                               52\nsynonymous_variant                                35\nmissense_variant                                  26\ndownstream_gene_variant                            2\n5_prime_UTR_variant                                2\n5_prime_UTR_premature_start_codon_gain_variant     1\ndtype: int64\n"
       ]
      }
     ],
     "input": [
      "print nb_dominant['effect'].value_counts()"
     ],
     "language": "python",
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-19-3484c7e441b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mnb_dominant\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_dominant\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clin_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mnb_dominant\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\WinPython-64bit-2.7.9.3\\python-2.7.9.amd64\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    696\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[0;32m    697\u001b[0m                          \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
       ]
      }
     ],
     "input": [
      "disease_causing = ['']\n",
      "\n",
      "# subset for variants where clinvar is not null \n",
      "# or the variant is in the disease causing list\n",
      "nb_dominant[(nb_dominant['clin_acc'].notnull())]:"
     ],
     "language": "python",
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "6,927 variants were located in the NBS gene list. Of those variants: \n",
      "\n",
      "- 118 dominant variants found.  \n",
      "- 248 homozygous recessive variants found.  \n",
      "- 192 comp_het variants found."
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dominant \n\nImpact: \nMODIFIER    56\nLOW         36\nMODERATE    26\ndtype: int64\n\n\nEffect: \n3_prime_UTR_variant                               52\nsynonymous_variant                                35\nmissense_variant                                  26\ndownstream_gene_variant                            2\n5_prime_UTR_variant                                2\n5_prime_UTR_premature_start_codon_gain_variant     1\ndtype: int64\n\n\nCondiction: \nChoreoathetosis: hypothyroidism: and neonatal respiratory distress    45\nPallister-Hall syndrome 2                                       33\nHypothyroidism: congenital: nongoitrous 2                       32\nHypothyroidism: congenital nongoitrous: 5                        8\ndtype: int64\n\n\nHomozygous Recessive \n\nImpact: \nMODERATE    111\nMODIFIER     71\nLOW          66\ndtype: int64\n\n\nEffect: \ndisruptive_inframe_deletion    60\nmissense_variant               51\n3_prime_UTR_variant            43\nTF_binding_site_variant        38\nsynonymous_variant             17\ndownstream_gene_variant        13\nsequence_feature                9\nintron_variant                  9\nupstream_gene_variant           4\nnon_coding_exon_variant         2\nsplice_region_variant           2\ndtype: int64\n\n\nCondiction: \nNiemann-Pick disease: type A: Niemann-Pick disease: type B      60\nAcyl-CoA dehydrogenase: very long chain: deficiency of          36\n  Mucopolysaccharidosis: type Ih (Hurler syndrome)              33\nAcyl-CoA dehydrogenase: medium chain: deficiency of             15\nSevere combined immunodeficiency                                14\nMethylmalonic acidemia: cblG type                               12\nHyperprolinemia: type I                                         10\nMitochondrial DNA depletion syndrome 9 (encephalomyopathic type with methylmalonic aciduria)     9\nMultiple acyl-CoA dehydrogenase deficiency: Glutaric aciduria IIC     8\nMaple syrup urine disease: type II                               7\nCombined malonic and methylmalonic aciduria                      6\nAlpha-methylacetoacetic aciduria                                 5\nMucopolysaccharidosis: type VII (Sly syndrome)                   4\nGalactosemia                                                     4\nDiabetes mellitus: neonatal: with congenital hypothyroidism      3\nHypothyroidism: congenital: nongoitrous: 1                       3\n3-beta-hydroxysteroid dehydrogenase: type II: deficiency         2\nBamforth-Lazarus syndrome                                        2\nHomocystinuria                                                   2\n3-methylglutaconic aciduria: type III                            2\nGalactose epimerase deficiency                                   2\nTrifunctional protein deficiency                                 2\nCystinosis (multiple types)                                      2\nMethylmalonic acidemia: cblB type                                1\nTranscobalamin II deficiency                                     1\nMethylmalonic acidemia due to methylmalonyl-CoA mutase deficiency     1\nMucopolysaccharidosis: type VI (Maroteaux-Lamy syndrome)         1\nT cell-negative: B cell-negative: natural killer cell-positive severe combined immunodeficiency: Omenn syndrome: Alpha/beta T-cell lymphopenia with gamma/delta T-cell expansion: severe cytomegalovirus infection: and autoimmunity: Combined cellular and humoral immune defects with granulomas     1\ndtype: int64\n\n\nCompound Heterozygous \n\nImpact: \nMODIFIER    79\nLOW         61\nMODERATE    52\ndtype: int64\n\n\nEffect: \nmissense_variant           52\n3_prime_UTR_variant        44\nsynonymous_variant         36\nsequence_feature           25\n5_prime_UTR_variant        15\ndownstream_gene_variant    12\nintron_variant              5\nnon_coding_exon_variant     2\nupstream_gene_variant       1\ndtype: int64\n\n\nCondiction: \n  Mucopolysaccharidosis: type Ih (Hurler syndrome)              23\nMultiple acyl-CoA dehydrogenase deficiency: Glutaric aciduria IIB    19\nMaple syrup urine disease: mild variant                         16\nTyrosinemia: type I                                             16\nCombined malonic and methylmalonic aciduria                     15\nCystic fibrosis                                                 10\nMaple syrup urine disease: type II                               9\nAcyl-CoA dehydrogenase family: member 9: deficiency of           9\nProlidase deficiency                                             9\nHolocarboxylase synthetase deficiency                            8\nMucopolysaccharidosis: type VII (Sly syndrome)                   7\nDiabetes mellitus: neonatal: with congenital hypothyroidism      6\nOmenn syndrome: Severe combined immunodeficiency with sensitivity to ionizing radiation     6\nGalactose epimerase deficiency                                   6\n3-methylglutaconic aciduria: type III                            5\nHyperprolinemia: type I                                          5\nTranscobalamin II deficiency                                     5\nThyroid dyshormonogenesis 4                                      4\nPhenylketonuria: Hyperphenylalaninemia: non-PKU mild             3\nBamforth-Lazarus syndrome                                        3\nAlpha-methylacetoacetic aciduria                                 2\nCarbamoylphosphate synthetase I deficiency                       2\nLipoid adrenal hyperplasi                                        2\nNiemann-Pick disease: type C1: Niemann-Pick disease: type D      2\ndtype: int64\n\n\n"
       ]
      }
     ],
     "input": [
      "def summarize(df):\n",
      "    impact = df['impact'].value_counts()\n",
      "    print \"Impact: \\n\", impact\n",
      "    print \"\\n\"\n",
      "    effect = df['effect'].value_counts()\n",
      "    print \"Effect: \\n\", effect\n",
      "    print \"\\n\"\n",
      "    condition = df['condition'].value_counts()\n",
      "    print \"Condiction: \\n\", condition\n",
      "    print \"\\n\"\n",
      "    \n",
      "print \"Dominant \\n\"    \n",
      "summarize(nb_dominant)\n",
      "\n",
      "print \"Homozygous Recessive \\n\"    \n",
      "summarize(nb_hom_recessive)\n",
      "    \n",
      "print \"Compound Heterozygous \\n\"    \n",
      "summarize(comphet_df)"
     ],
     "language": "python",
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Saving Output"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving 192 het variants to nb_het.csv in current working directory\nSaving 118 dominant variants to nb_dominant.csv in current working directory\nSaving 248 homozygous recessive variants to nb_hom_recessive.csv in current working directory\n"
       ]
      }
     ],
     "input": [
      "# save output to current working directory\n",
      "\n",
      "print \"Saving \" + str(len(comphet_df)) + \" het variants to nb_het.csv in current working directory\"\n",
      "comphet_df.to_csv('nb_het.csv', header=True, encoding='utf-8', index=False)\n",
      "\n",
      "print \"Saving \" + str(len(nb_dominant)) + \" dominant variants to nb_dominant.csv in current working directory\"\n",
      "nb_dominant.to_csv('nb_dominant.csv', header=True, encoding='utf-8', index=False)\n",
      "\n",
      "print \"Saving \" + str(len(nb_hom_recessive)) + \" homozygous recessive variants to nb_hom_recessive.csv in current working directory\"\n",
      "nb_hom_recessive.to_csv('nb_hom_recessive.csv', header=True, encoding='utf-8', index=False)"
     ],
     "language": "python",
     "prompt_number": 33
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0
}