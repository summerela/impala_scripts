{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 1,
     "source": [
      "NBS Gene Annotation"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Purpose"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the following newborns:   \n",
      "\n",
      "102-07005-03  \n",
      "102-00997-03  \n",
      "102-00996-03  \n",
      "102-02001-03  \n",
      "102-00961-03  \n",
      "102-07009-03  \n",
      "102-00932-03  \n",
      "102-00979-03  \n",
      "102-01532-03  \n",
      "102-00974-03  \n",
      "\n",
      "Variants were annotated with the NBS gene table provided by Ben Solomon at ITMI. Variants located in NBS gene regions were filtered, keeping only variants with a Kaviar frequency less than 1%. Candidate variants were then annotated with ClinVar and coding consequence predictions. Results were reported for Dominant, homozygous recessive and compound heterozygotes. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Transform of NBS Gene Table"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The NBS Gene Table provided by ITMI was transformed as follows and uploaded to impala:   \n",
      "\n",
      "- A 'level' column was added to represent the color coding found in the file, with the following options: red, yellow, null  \n",
      "- All commas were replaced with colons to prevent errors while importing csv file  \n",
      "- All semicolons were replaced with colons for consistency of data  \n",
      "- Spaces in column names were replaced with underscores  \n",
      "- Special characters were removed from column names"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding rare variants with Kaviar"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To reduce the number of variants input into downstream queries and analysis, all trio variants were annotated with kaviar frequencies, Keep only variants with a kaviar frequency less than .01, or variants not listed in the kaviar table.  \n",
      "\n",
      "         WITH bv AS (\n",
      "             SELECT bv.sample_id, bv.chr, bv.pos, bv.id, bv.ref, bv.alt, bv.qual, bv.filter, bv.gt\n",
      "             FROM p7_platform.brady_variant bv\n",
      "             WHERE (bv.sample_id LIKE '%03' OR bv.sample_id LIKE '%02' OR bv.sample_id LIKE '%01')\n",
      "          )\n",
      "  \n",
      "          SELECT bv.*, k.alle_freq\n",
      "          FROM bv\n",
      "          LEFT JOIN /* +SHUFFLE */ public_hg19.kaviar k\n",
      "               ON bv.chr = k.chromosome\n",
      "               AND bv.pos = k.pos\n",
      "               AND bv.ref = k.ref\n",
      "               AND bv.alt = k.alt\n",
      "         WHERE (k.alle_freq < .01 OR k.alle_freq IS NULL)\n",
      "\n",
      "Query Statements:   \n",
      "- Queries were limited to trio members, excluding more distant relatives  \n",
      "- Keep only variants with a kaviar frequency less than .01, or variants not listed in the kaviar table. \n",
      "\n",
      "Results were saved to an hdfs table named bv_kaviar. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding positional information to the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Chromosome, start and stop positions were added to the NBS Gene list by joining it with the \n",
      "ensembl_genes table using gene name. This resulted in mulitple listings per gene for each exon, \n",
      "allowing for more precise matches. \n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_positional AS SELECT nbs.gene, \n",
      "        nbs.entrez_gene_id as entrez_id, ens.gene_id AS ensembl_id, ens.chromosome as chrom, \n",
      "        ens.start, ens.stop, nbs.condition, nbs.omim_phenotype, nbs.va_name, nbs.inheritance, \n",
      "        nbs.allelic_condition, nbs.in_pgb, nbs.level, ens.feature, ens.transcript_name, \n",
      "        ens.transcript_id, ens.exon_number, ens.exon_id, ens.gene_biotype, nbs.comments\n",
      "        FROM users_selasady.nbs_genes nbs\n",
      "        LEFT JOIN\n",
      "                 public_hg19.ensembl_genes ens\n",
      "                ON nbs.gene = ens.gene_name\n",
      "\n",
      "The results were saved as users _ selasady.nbs _ ensembl containing 20872 rows. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Locate rare variants in the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next the Kaviar-filtered variants were joined with nbs _ ensembl using chromosome, start and stop positions, returning rare variants in the nbs_gene list, and annotated those with ClinVar. \n",
      "\n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_annotated AS \n",
      "            WITH nbs AS (\n",
      "            SELECT bv.sample_id, bv.chr as chrom, bv.pos, bv.id as rs_id, bv.ref, bv.alt, bv.qual, bv.filter,bv.gt, \n",
      "            bv.alle_freq AS kav_freq,nbs.gene, nbs.entrez_id, nbs.ensembl_id, nbs.condition, nbs.omim_phenotype, \n",
      "            nbs.va_name, nbs.inheritance, nbs.allelic_condition,nbs.in_pgb, nbs.level, nbs.feature, \n",
      "            nbs.transcript_name, nbs.transcript_id, nbs.exon_number, nbs.exon_id, nbs.gene_biotype, nbs.comments\n",
      "            FROM public_hg19.bv_kaviar bv, users_selasady.nbs_ensembl nbs\n",
      "            WHERE bv.chr = nbs.chrom\n",
      "            AND bv.pos BETWEEN nbs.start and nbs.stop\n",
      "            )\n",
      "  \n",
      "           SELECT nbs.*, clin.clin_hgvs, clin.clin_sig, clin.clin_dbn, clin.clin_acc \n",
      "           FROM nbs\n",
      "           LEFT JOIN public_hg19.clinvar clin\n",
      "               ON nbs.rs_id = clin.id\n",
      "\n",
      "6927 rows were returned, the table was saved as users _ selasady.nbs_annotated. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Add functional annotation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Coding consequences for each variant were predictedusing ensembl VEP. \n",
      "\n",
      "VEP requires input in either VCF format or a tab-delimieted file of chromosomal location and ref and alt alleles. Results from the NBS gene list were read into python. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "#################\n",
      "# load modules  #\n",
      "#################\n",
      "import pandas as pd\n",
      "from impala.dbapi import connect\n",
      "from impala.util import as_pandas\n",
      "\n",
      "#create database connection\n",
      "conn = connect(host='glados19', port=21050)\n",
      "cur = conn.cursor()\n",
      "\n",
      "#########################\n",
      "# Run Query on Impala ##\n",
      "#########################\n",
      "query = \"SELECT * FROM users_selasady.nbs_annotated\"\n",
      "cur.execute(query)\n",
      "\n",
      "#store results as pandas data frame\n",
      "nbs_df = as_pandas(cur)"
     ],
     "language": "python",
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataframe was separated into mother, father and newborn for downstream analysis. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "newborns = nbs_df[nbs_df['sample_id'].str.endswith('03')]\n",
      "mothers = nbs_df[nbs_df['sample_id'].str.endswith('01')]\n",
      "fathers = nbs_df[nbs_df['sample_id'].str.endswith('02')]"
     ],
     "language": "python",
     "prompt_number": 209
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn set was output to a modified version of Plink's tab2vcf script to create a VCF file for use with SnpEff. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "newborns.tsv\n0 1 2 3\n"
       ]
      }
     ],
     "input": [
      "import os\n",
      "import sys\n",
      "\n",
      "# output columns to vcf file using a modified version of anntools tab2vcf.py\n",
      "nb_to_vcf = newborns[['chrom','pos', 'ref', 'alt']]\n",
      "\n",
      "\n",
      "# write to file for conversion to vcf\n",
      "nb_to_vcf.to_csv('{}/newborns.tsv'.format(os.getcwd()), header=True, encoding='utf-8', sep=\"\\t\", index=False)\n",
      "\n",
      "# run tab2vcf.py script\n",
      "try:\n",
      "    %run ./tab2vcf.py newborns.tsv\n",
      "except Exception,e: print str(e)"
     ],
     "language": "python",
     "prompt_number": 112
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The VCF file was annotated with coding consequences using SnpEff version 4.1h (build 2015-08-03) with _GRCh37.75. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# run SnpEff on newborns.vcf for windows\n",
      "#!java -Xmx4g -jar `cygpath -m /cygdrive/D/Documents/tools/snpEff/snpEff.jar` -v GRCh37.75 ./newborns.tsv.vcf > \n",
      "# newborns_annot.vcf"
     ],
     "language": "python",
     "prompt_number": 108
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The annotations were read back into Python, parsed and matched with the variant data frame."
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   chrom       pos ref alt                   effect    impact gene_name  \\\n0     15  76566668   A   C  downstream_gene_variant  MODIFIER      ETFA   \n2     15  80469886   A   G       synonymous_variant       LOW       FAH   \n13     4    993785   G   A         sequence_feature       LOW      IDUA   \n14    11  36532543   T   A    upstream_gene_variant  MODIFIER     TRAF6   \n15    11  36595107   C   G         missense_variant  MODERATE      RAG1   \n\n            gene_id feature_type       feature_id      tx_biotype   rank  \\\n0   ENSG00000140374   transcript  ENST00000560345  protein_coding          \n2   ENSG00000103876   transcript  ENST00000261755  protein_coding  12/15   \n13  ENSG00000127415  beta_strand  ENST00000247933  protein_coding          \n14  ENSG00000175104   transcript  ENST00000348124  protein_coding          \n15  ENSG00000166349   transcript  ENST00000299440  protein_coding    2/2   \n\n          hgvs_c       hgvs_p  \n0      c.*717T>G               \n2       c.921A>G  p.Gly307Gly  \n13  c.300-615G>A               \n14     c.-325A>T               \n15      c.253C>G   p.Pro85Ala  \n"
       ]
      }
     ],
     "input": [
      "import numpy as np\n",
      "# read in vcf as tsv file, skipping header\n",
      "annot_vcf = pd.read_csv('newborns_annot.vcf', sep='\\t', skiprows=8)\n",
      "\n",
      "#split info columns by \"|\" and keep most detrimental consequence (first)\n",
      "info_df = pd.DataFrame(list(annot_vcf['INFO'].str.split('|')))\n",
      "#keep only first consequence listed\n",
      "info_df = info_df[list(info_df.columns[1:11])]\n",
      "\n",
      "#merge annotations with annot_vcf\n",
      "annot_vcf = annot_vcf[np.r_[0:2,3, 4]]\n",
      "annot_df = pd.concat([annot_vcf, info_df], axis=1)\n",
      "#remove duplicated rows\n",
      "annot_df.drop_duplicates(inplace=True)\n",
      "#rename columns\n",
      "annot_df.columns = ['chrom', 'pos', 'ref', 'alt', 'effect', 'impact','gene_name', 'gene_id', 'feature_type', \n",
      "                    'feature_id', 'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']"
     ],
     "language": "python",
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "newborn_annot = pd.merge(newborns, annot_df, on=['chrom', 'pos', 'ref', 'alt'], how='left')"
     ],
     "language": "python",
     "prompt_number": 213
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reporting dominant and homozygous recessive variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn subset was split into dominant, homozygous recessive and heterozygous variants for downstream analysis. \n",
      "\n",
      "A variant id composed of chrom:pos:ref:alt was added for matching nb comp_het variants with parent variants.  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "nb_dominant = newborn_annot[(newborn_annot['inheritance'] == 'AD')]\n",
      "nb_hom_recessive = newborn_annot[((newborn_annot['inheritance'] == 'AR') & (newborn_annot['gt'] == '1/1'))]\n",
      "nb_het = newborn_annot[((newborn_annot['inheritance'] == 'AR') & (newborn_annot['gt'] == '0/1'))]\n",
      "\n",
      "# add family id to simplify variant matching\n",
      "nb_het['family_id'] = nb_het['sample_id'].apply(lambda x: x[:-3])\n",
      "mothers['family_id'] = mothers['sample_id'].apply(lambda x: x[:-3])\n",
      "fathers['family_id'] = fathers['sample_id'].apply(lambda x: x[:-3])\n",
      "\n",
      "# add variant id's to simplify variant matching\n",
      "nb_het['var_id'] = nb_het.apply(lambda x:'{}:{}:{}:{}:{}'.format(x['chrom'],x['pos'], x['ref'], x['alt'], \n",
      "                                                                 x['family_id']),axis=1)\n",
      "mothers['var_id'] = mothers.apply(lambda x:'{}:{}:{}:{}:{}'.format(x['chrom'],x['pos'], x['ref'], x['alt'], \n",
      "                                                                   x['family_id']),axis=1)\n",
      "fathers['var_id'] = fathers.apply(lambda x:'{}:{}:{}:{}:{}'.format(x['chrom'],x['pos'], x['ref'], x['alt'], \n",
      "                                                                   x['family_id']),axis=1)"
     ],
     "language": "python",
     "prompt_number": 214
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reporting heterozygous recessive variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Heterozygous recessive variants were examined for compound heterozygosity and output as a tsv file. \n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# merge het newborns with matching variants from father \n",
      "nb_and_dad = pd.merge(nb_het, fathers, on=['var_id'], how='inner')\n",
      "# rename father's sample_id column\n",
      "nb_and_dad.rename(columns = {'sample_id_y':'sample_id_f'}, inplace=True)\n",
      "\n",
      "# drop extra columns ending in _y from merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "\n",
      "# drop extra y columns from merge with fathers\n",
      "drop_y(nb_and_dad)\n",
      "#remove _x from colnames\n",
      "nb_and_dad.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "\n",
      "# merge het newborns with matching variants from mother \n",
      "nb_and_mom = pd.merge(nb_het, mothers, on=['var_id'], how='inner')\n",
      "# rename mother's sample_id column\n",
      "nb_and_mom.rename(columns = {'sample_id_y':'sample_id_m'}, inplace=True)\n",
      "\n",
      "# drop extra columns ending in _y from merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "\n",
      "# drop extra y columns from merge with fathers\n",
      "drop_y(nb_and_mom)\n",
      "#remove _x from colnames\n",
      "nb_and_mom.rename(columns=lambda x: x.replace('_x', ''), inplace=True)"
     ],
     "language": "python",
     "prompt_number": 215
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After creating data frames for variants that have a match from either the mother or father, the newborn het dataframe is subset for only variants in either set, and then grouped by gene name to search within genes for compound heterozygosity. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1324 candidate variants found\n"
       ]
      }
     ],
     "input": [
      "# subset nb_hets for only variants found in either mother or father\n",
      "het_cands = (nb_het[(nb_het['var_id'].isin(nb_and_dad['var_id']) | nb_het['var_id'].isin(nb_and_mom['var_id']))])\n",
      "print str(len(het_cands)) + \" candidate variants found\"\n",
      "\n",
      "# group variants by gene name\n",
      "by_gene = het_cands.groupby(['gene', 'family_id'])"
     ],
     "language": "python",
     "prompt_number": 216
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Search for genes that contain newborn variants at more than one position; if those genes have variants from both parents at different positions, mark as compound het. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# create empty list to hold comp_hets\n",
      "comp_hets = []\n",
      "\n",
      "for name, group in by_gene:\n",
      "    #if there is a variant in more than one position\n",
      "    if group.pos.nunique() > 1:\n",
      "        # and there are more than one variants from both parents\n",
      "        if (len(group[(group['var_id'].isin(nb_and_dad['var_id']))] > 1) and \\\n",
      "                len(group[(group['var_id'].isin(nb_and_mom['var_id']))] > 1)):\n",
      "            comp_hets.append(group)\n",
      "        # or if there is a variant from both parents\n",
      "        elif (len(group[(group['var_id'].isin(nb_and_dad['var_id']))] > 0) and \\\n",
      "                len(group[(group['var_id'].isin(nb_and_mom['var_id']))] > 0)):\n",
      "            # and those variants are different\n",
      "            if len(group[(group['var_id'].isin(fathers['var_id']))].pos - group[(group['var_id'].isin(mothers['var_id']))].pos) > 0:\n",
      "                    comp_hets.append(group)"
     ],
     "language": "python",
     "prompt_number": 233
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TO Do: \n",
      "\n",
      "- Save to file\n",
      "= Add DANN annotation"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "         sample_id chrom        pos        rs_id ref alt    qual filter   gt  \\\n397   102-07005-03     3  128634878  rs187378980   C   T  166.00   PASS  0/1   \n1533  102-07005-03     3  128628253  rs150283105   C   T  187.00   PASS  0/1   \n1534  102-07005-03     3  128628253  rs150283105   C   T  187.00   PASS  0/1   \n1535  102-07005-03     3  128628253  rs150283105   C   T  187.00   PASS  0/1   \n1536  102-07005-03     3  128628253  rs150283105   C   T  187.00   PASS  0/1   \n\n      kav_freq            ...             gene_name          gene_id  \\\n397   0.001250            ...                 ACAD9  ENSG00000177646   \n1533  0.000104            ...                 ACAD9  ENSG00000177646   \n1534  0.000104            ...                 ACAD9  ENSG00000177646   \n1535  0.000104            ...                 ACAD9  ENSG00000177646   \n1536  0.000104            ...                 ACAD9  ENSG00000177646   \n\n     feature_type       feature_id               tx_biotype   rank     hgvs_c  \\\n397    transcript  ENST00000508971  nonsense_mediated_decay  16/16  n.*685C>T   \n1533   transcript  ENST00000308982           protein_coding  15/18  c.1552C>T   \n1534   transcript  ENST00000308982           protein_coding  15/18  c.1552C>T   \n1535   transcript  ENST00000308982           protein_coding  15/18  c.1552C>T   \n1536   transcript  ENST00000308982           protein_coding  15/18  c.1552C>T   \n\n           hgvs_p  family_id                     var_id  \n397                102-07005  3:128634878:C:T:102-07005  \n1533  p.Arg518Cys  102-07005  3:128628253:C:T:102-07005  \n1534  p.Arg518Cys  102-07005  3:128628253:C:T:102-07005  \n1535  p.Arg518Cys  102-07005  3:128628253:C:T:102-07005  \n1536  p.Arg518Cys  102-07005  3:128628253:C:T:102-07005  \n\n[5 rows x 43 columns]\n"
       ]
      }
     ],
     "input": [
      "comphet_df = pd.concat(comp_hets)\n"
     ],
     "language": "python",
     "prompt_number": 235
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0
}