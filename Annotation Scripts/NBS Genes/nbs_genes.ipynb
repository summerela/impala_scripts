{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 1,
     "source": [
      "NBS Gene Annotation"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Purpose"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the following newborns:   \n",
      "\n",
      "102-07005-03  \n",
      "102-00997-03  \n",
      "102-00996-03  \n",
      "102-02001-03  \n",
      "102-00961-03  \n",
      "102-07009-03  \n",
      "102-00932-03  \n",
      "102-00979-03  \n",
      "102-01532-03  \n",
      "102-00974-03  \n",
      "\n",
      "Variants were annotated with the NBS gene table provided by Ben Solomon at ITMI. Variants located in NBS gene regions were filtered, keeping only variants with a Kaviar frequency less than 1%. Candidate variants were then annotated with ClinVar, DANN scores for SNV's and coding consequence predictions. Results were reported for Dominant, homozygous recessive and compound heterozygotes. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Transform of NBS Gene Table"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The NBS Gene Table provided by ITMI was transformed as follows and uploaded to impala:   \n",
      "\n",
      "- A 'level' column was added to represent the color coding found in the file, with the following options: red, yellow, null  \n",
      "- All commas were replaced with colons to prevent errors while importing csv file  \n",
      "- All semicolons were replaced with colons for consistency of data  \n",
      "- Spaces in column names were replaced with underscores  \n",
      "- Special characters were removed from column names"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding rare variants with Kaviar"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To reduce the number of variants input into downstream queries and analysis, all trio variants were annotated with kaviar frequencies, Keep only variants with a kaviar frequency less than .01, or variants not listed in the kaviar table.  \n",
      "\n",
      "         WITH bv AS (\n",
      "             SELECT bv.sample_id, bv.chr, bv.pos, bv.id, bv.ref, bv.alt, bv.qual, bv.filter, bv.gt\n",
      "             FROM p7_platform.brady_variant bv\n",
      "             WHERE (bv.sample_id LIKE '%03' OR bv.sample_id LIKE '%02' OR bv.sample_id LIKE '%01')\n",
      "          )\n",
      "  \n",
      "          SELECT bv.*, k.alle_freq\n",
      "          FROM bv\n",
      "          LEFT JOIN /* +SHUFFLE */ public_hg19.kaviar k\n",
      "               ON bv.chr = k.chromosome\n",
      "               AND bv.pos = k.pos\n",
      "               AND bv.ref = k.ref\n",
      "               AND bv.alt = k.alt\n",
      "         WHERE (k.alle_freq < .01 OR k.alle_freq IS NULL)\n",
      "\n",
      "Query Statements:   \n",
      "- Queries were limited to trio members, excluding more distant relatives  \n",
      "- Keep only variants with a kaviar frequency less than .01, or variants not listed in the kaviar table. \n",
      "\n",
      "Results were saved to an hdfs table named bv_kaviar. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding positional information to the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Chromosome, start and stop positions were added to the NBS Gene list by joining it with the \n",
      "ensembl_genes table using gene name. This resulted in mulitple listings per gene for each exon, \n",
      "allowing for more precise matches. \n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_positional AS SELECT nbs.gene, \n",
      "        nbs.entrez_gene_id as entrez_id, ens.gene_id AS ensembl_id, ens.chromosome as chrom, \n",
      "        ens.start, ens.stop, nbs.condition, nbs.omim_phenotype, nbs.va_name, nbs.inheritance, \n",
      "        nbs.allelic_condition, nbs.in_pgb, nbs.level, ens.feature, ens.transcript_name, \n",
      "        ens.transcript_id, ens.exon_number, ens.exon_id, ens.gene_biotype, nbs.comments\n",
      "        FROM users_selasady.nbs_genes nbs\n",
      "        LEFT JOIN\n",
      "                 public_hg19.ensembl_genes ens\n",
      "                ON nbs.gene = ens.gene_name\n",
      "\n",
      "The results were saved as users _ selasady.nbs _ ensembl containing 20872 rows. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Locate rare variants in the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next the Kaviar-filtered variants were joined with nbs _ ensembl using chromosome, start and stop positions, returning rare variants in the nbs_gene list, and annotated those with ClinVar. \n",
      "\n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_annot AS \n",
      "            WITH nbs AS (\n",
      "            SELECT bv.sample_id, bv.chr as chrom, bv.pos, bv.id as rs_id, bv.ref, bv.alt, bv.qual, bv.filter,bv.gt, \n",
      "            bv.alle_freq AS kav_freq,nbs.gene, nbs.entrez_id, nbs.ensembl_id, nbs.condition, nbs.omim_phenotype, \n",
      "            nbs.va_name, nbs.inheritance, nbs.allelic_condition,nbs.in_pgb, nbs.level, nbs.feature, \n",
      "            nbs.transcript_name, nbs.transcript_id, nbs.exon_number, nbs.exon_id, nbs.gene_biotype, nbs.comments\n",
      "            FROM public_hg19.bv_kaviar bv, users_selasady.nbs_ensembl nbs\n",
      "            WHERE bv.chr = nbs.chrom\n",
      "            AND bv.pos BETWEEN nbs.start and nbs.stop\n",
      "            )\n",
      "  \n",
      "           SELECT nbs.*, clin.clin_hgvs, clin.clin_sig, clin.clin_dbn, clin.clin_acc,\n",
      "           CASE WHEN (clin.clin_sig NOT REGEXP '3|2[^5]|2$'  \n",
      "                    AND  clin.clin_sig REGEXP '4|[^25]5|^5') THEN 'Y'\n",
      "           ELSE 'N'\n",
      "           END AS clin_patho\n",
      "           FROM nbs\n",
      "           LEFT JOIN public_hg19.clinvar clin\n",
      "               ON nbs.rs_id = clin.id\n",
      "\n",
      "6927 rows were returned, the table was saved as users _ selasady.nbs_annot. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding DANN scores "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "DANN scores whole-genome variants by training a deep neural network (DNN). DNNs can capture non-linear relationships among features, and are better suited than SVMs for problems with a large number of samples and features. DANN scores have been shown to outperform both CADD and FATHMM (http://www.enlis.com/blog/2015/03/17/the-best-variant-prediction-method-that-no-one-is-using/).\n",
      "\n",
      "DANN scores are provided for SNV's and range between 0 and 1. The closer a score is to 1, the more pathogenic the variant. \n",
      "\n",
      "The following query was used to annotate the nbs variants with DANN scores by matching on chromosome and position, then outputting the score for the alt allele. \n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_dann AS (\n",
      "            SELECT n.*, CASE \n",
      "                        WHEN n.alt = 'A' THEN d.score_a\n",
      "                        WHEN n.alt = 'T' THEN d.score_t\n",
      "                        WHEN n.alt = 'G' THEN d.score_g\n",
      "                        WHEN n.alt = 'C' THEN d.score_c\n",
      "                    END as dann_score, \n",
      "                    CASE\n",
      "                        WHEN SUBSTRING(n.sample_id, -2) = '01'THEN 'M'\n",
      "                        WHEN SUBSTRING(n.sample_id, -2) = '02' THEN 'F'\n",
      "                        WHEN SUBSTRING(n.sample_id, -2) = '03'THEN 'NB'\n",
      "                    END as member,\n",
      "                    SUBSTRING(n.sample_id, 1, (length(n.sample_id)-3)) as family_id,\n",
      "                   CONCAT(n.chrom, ':', CAST(n.pos AS STRING), ':', n.ref, ':', n.alt, ':', SUBSTRING(n.sample_id, 1, (length(n.sample_id)-3))) as var_id\n",
      "                   FROM users_selasady.nbs_annot n\n",
      "                   LEFT JOIN public_hg19.DANN d\n",
      "                       ON n.chrom = d.chrom\n",
      "                       AND n.pos = d.pos\n",
      "              )"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reading the impala results into python"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "#################\n",
      "# load modules  #\n",
      "#################\n",
      "import pandas as pd\n",
      "from impala.dbapi import connect\n",
      "from impala.util import as_pandas\n",
      "\n",
      "#create database connection\n",
      "conn = connect(host='glados19', port=21050)\n",
      "cur = conn.cursor()\n",
      "\n",
      "# query to left join nbs_annotated variants with DANN scores\n",
      "query = \"\"\"\n",
      "    SELECT * FROM users_selasady.nbs_dann\n",
      "    \"\"\"\n",
      "# run query on impala\n",
      "cur.execute(query)\n",
      "\n",
      "#store results as pandas data frame\n",
      "nbs_df = as_pandas(cur)"
     ],
     "language": "python",
     "prompt_number": 167
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding Functional Annotation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn set was output to a modified version of Plink's tab2vcf script to create a VCF file for use with SnpEff. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn variants in the VCF file were annotated with coding consequences using SnpEff version 4.1h (build 2015-08-03) with GRCh37.75. \n",
      "\n",
      "The functional annotations were read back into Python, parsed and matched with the each respective variant data frame. \n",
      "\n",
      "Annotated variants were then labled as pathogenic if they predicted a newborn to have an NBS conddition based on the following parameters:   \n",
      "- Presence of mutation(s) with appropriate inheritance (eg, 2 bi-allelic pathogenic mutations for a recessive disorder).  \n",
      "- Mutations are defined strictly as either:   \n",
      "    - Annotated in ClinVar with a clinical significance of 4 or 5, but never 2 or 3 or labeled pathogenic in HGMD (to be added later) OR\n",
      "    - Novel but predicted to be disease-causing (ie, a stop-gain, stop-loss, splice-site, whole-exon or larger deletion, or frameshift) \n",
      "\n",
      "This output will be used downstream to output a list of high priority variants for examination. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import subprocess as subp\n",
      "import numpy as np\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "# enter path to your snpeff jar\n",
      "snpeff_path = '/Users/selasady/tools/snpEff/snpEff.jar'\n",
      "\n",
      "# enter basename for output files\n",
      "out_name = 'nbs_genes'\n",
      "\n",
      "# setup file names\n",
      "tsv_outname = '{}/{}.tsv'.format(os.getcwd(), out_name)\n",
      "vcf_outname = '{}/{}.vcf'.format(os.getcwd(), out_name)\n",
      "snpeff_outname = '{}/{}_snpeff'.format(os.getcwd(), out_name)\n",
      "\n",
      "# function to add functional annotation\n",
      "# def df_to_snpeff(input_df):\n",
      "#     # subset columns to output to vcf file\n",
      "#     df = input_df[['chrom', 'pos', 'ref', 'alt']]\n",
      "#     # write to file for conversion to vcf\n",
      "#     df.to_csv(tsv_outname, header=True, encoding='utf-8', sep=\"\\t\", index=False)\n",
      "#     # command to run tab2vcf and then snpeff\n",
      "#     run_cmd = './tab2vcf.py ' + tsv_outname + ' && java -Xmx4g -jar {} -v GRCh37.75 {} > {}'.format(snpeff_path, vcf_outname, snpeff_outname)\n",
      "#     # run tab2vcf and upon success, run snpeff\n",
      "#     snpeff_process = subp.Popen(run_cmd, shell=True)\n",
      "#     snpeff_output = snpeff_process.communicate()[0]\n",
      "#     if snpeff_output != 0:\n",
      "#         print ('SnpEff failed {} {}'.format(snpeff_output.returncode, snpeff_output))\n",
      "#     else: \n",
      "#         print \"SnpEff finished. Output saved to {}\".format(snpeff_outname)\n",
      "# \n",
      "# # run function on dataframe\n",
      "# df_to_snpeff(nbs_df)\n",
      " \n",
      "# add snpeff annotations back to dataframe\n",
      "def parse_snpeff(input_df):\n",
      "    # merge snpeff annotated vcf file with dataframe , skipping header\n",
      "    annot_vcf = pd.read_csv(snpeff_outname, sep='\\t', skiprows=8)\n",
      "    # split info columns by \"|\" and keep only most detrimental consequence (first)\n",
      "    info_df = pd.DataFrame(list(annot_vcf['INFO'].str.split('|')))\n",
      "    # keep only first consequence listed\n",
      "    info_df = info_df[list(info_df.columns[1:11])]\n",
      "    # merge truncated info field with annot_vcf\n",
      "    annot_vcf = annot_vcf[np.r_[0:2, 3, 4]]\n",
      "    annot_df = pd.concat([annot_vcf, info_df], axis=1)\n",
      "    # remove duplicated rows\n",
      "    annot_df.drop_duplicates(inplace=True)\n",
      "    # rename columns\n",
      "    annot_df.columns =['chrom', 'pos', 'ref', 'alt', 'effect', 'impact', 'gene_name', 'gene_id', 'feature_type', \\\n",
      "        'feature_id', 'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']\n",
      "    # merge annotations with variant table\n",
      "    df_functional = pd.merge(input_df, annot_df, on=['chrom', 'pos', 'ref', 'alt'], how='left')\n",
      "    # drop columns with duplicated info after merge\n",
      "    df_functional.drop(['gene_name', 'gene_id', 'feature_id', 'feature_type', 'rank'], axis=1, inplace=True)\n",
      "    return df_functional\n",
      "    \n",
      "# merge nbs_genes with functional annotations\n",
      "nbs_annot = parse_snpeff(nbs_df)\n",
      "\n",
      "# label variants considered pathogenic \n",
      "nbs_annot['pathogenic'] = (nbs_annot['impact'] == 'HIGH') |  (nbs_annot['clin_patho'] == 'Y')"
     ],
     "language": "python",
     "prompt_number": 170
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataframe was separated into mother, father and newborn for downstream analysis. \n",
      "\n",
      "These dataframes were further subset to include only pathogenic variants for downstream analysis. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of newborn variants: 2369, Number of pathogenic: 120\nNumber of mother variants: 2358, Number of pathogenic: 108\nNumber of father variants: 2200, Number of pathogenic: 156\n"
       ]
      }
     ],
     "input": [
      "# subset data frame by trio member\n",
      "newborns = nbs_annot[nbs_annot['member'] == 'NB']\n",
      "mothers = nbs_annot[nbs_annot['member'] == 'M']\n",
      "fathers = nbs_annot[nbs_annot['member'] == 'F']\n",
      "\n",
      "# subset trio dataframes for only pathogenic variants\n",
      "mom_patho = mothers.loc[mothers['pathogenic'] == True]\n",
      "dad_patho = fathers.loc[fathers['pathogenic'] == True]\n",
      "nb_patho = newborns.loc[newborns['pathogenic'] == True]\n",
      "\n",
      "print \"Number of newborn variants: \" + str(len(newborns)) + \", Number of pathogenic: \" + str(len(nb_patho))\n",
      "print \"Number of mother variants: \" + str(len(mothers)) + \", Number of pathogenic: \" + str(len(mom_patho))\n",
      "print \"Number of father variants: \" + str(len(fathers)) + \", Number of pathogenic: \" + str(len(dad_patho))"
     ],
     "language": "python",
     "prompt_number": 183
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn subset was split to report:   \n",
      "- All variants in regions of dominant disorders  \n",
      "- All homozygous recessive variants in regions of autosomal recessive disorders  \n",
      "- All heterozygous variants in autosomal recessive regions for downstream analysis of compound heterozygosity  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "118 dominant variants found.\n248 homozygous recessive variants found.\n"
       ]
      }
     ],
     "input": [
      "# disable erroneous pandas warning\n",
      "pd.options.mode.chained_assignment = None\n",
      "\n",
      "# subset newborns by variant MOI and/or zygosity\n",
      "nb_dominant = newborns[(newborns['inheritance'] == 'AD')]\n",
      "nb_hom_recessive = newborns[((newborns['inheritance'] == 'AR') & (newborns['gt'] == '1/1'))]\n",
      "nb_het = newborns[((newborns['inheritance'] == 'AR') & (newborns['gt'] == '0/1'))]\n",
      "\n",
      "# report initial results \n",
      "print str(len(nb_dominant)) + \" dominant variants found.\"\n",
      "print str(len(nb_hom_recessive)) + \" homozygous recessive variants found.\""
     ],
     "language": "python",
     "prompt_number": 175
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      ""
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reporting compound heterozygous recessive variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Heterozygous variants in autosomal recessive regions were examined for compound heterozygosity, as follows: \n",
      "- Newborns must inherit at least one variant from each parent, at different positions on the same gene  \n",
      "- Parents must be heterozygous for the matching variant  \n",
      "- Matching parent variants must both be pathogenic\n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# keep only heterozygous pathogenic variants, as homozygous parents are not of interest\n",
      "mom_comphet = mom_patho.loc[mom_patho['gt'] == '0/1']\n",
      "dad_comphet = dad_patho.loc[dad_patho['gt'] == '0/1']\n",
      "\n",
      "# keep only newborn het, pathogenic variants with AR disorders\n",
      "nb_comphet = nb_patho.loc[((nb_patho['gt'] == '0/1') & (nb_patho['inheritance'] == 'AR'))]\n",
      "\n",
      "# function to drop extra columns ending in _y from df merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "            \n",
      "\n",
      "# function to find matching parent variants\n",
      "def find_parent_vars(nb_df, parent_df):\n",
      "    # merge dataframes on variant id\n",
      "    merged_df = pd.merge(nb_df, parent_df, on=['var_id'], how='inner')\n",
      "    # rename parent sample_id column to avoid dropping when removing '_y' cols\n",
      "    merged_df.rename(columns = {'sample_id_y':'parent_id'}, inplace=True)\n",
      "    # drop extra y columns from merge with fathers\n",
      "    drop_y(merged_df)\n",
      "    #remove _x from colnames\n",
      "    merged_df.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "    return merged_df\n",
      "    \n",
      "# run function for each parent set\n",
      "nb_and_mom = find_parent_vars(nb_comphet, mom_comphet)\n",
      "nb_and_dad = find_parent_vars(nb_comphet, dad_comphet)"
     ],
     "language": "python",
     "prompt_number": 197
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After creating data frames for variants that have a match from either the mother or father, a merged data frame is created from eligable variants that are then grouped by gene for further to search for genes that contain variants at more than one position. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# subset nb_hets for only variants found in either mother or father\n",
      "het_cands = pd.concat([nb_and_mom,nb_and_dad]).drop_duplicates().reset_index(drop=True)\n",
      "\n",
      "# group variants by gene name\n",
      "by_gene = het_cands.groupby(['gene', 'family_id'])"
     ],
     "language": "python",
     "prompt_number": 200
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After grouping the filtered nb het variants by gene, the variants will be filtered to keep only variants with pathogenic mutations at more than one position. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "ename": "Exception",
       "evalue": "All objects passed were None",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-201-7421e6e89437>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# combine results into dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcomphet_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp_hets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomphet_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" comp_het variants found.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/selasady/anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity)\u001b[0m\n\u001b[1;32m    715\u001b[0m                        \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                        verify_integrity=verify_integrity)\n\u001b[0m\u001b[1;32m    718\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/selasady/anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All objects passed were None'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;31m# consolidate data & figure out what our result ndim is going to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mException\u001b[0m: All objects passed were None"
       ]
      }
     ],
     "input": [
      "# create empty list to hold comp_hets\n",
      "comp_hets = []\n",
      "\n",
      "for name, group in by_gene:\n",
      "    #if there is a variant in more than one position\n",
      "    if group.pos.nunique() > 1:\n",
      "        # and there are more than one variants from both parents\n",
      "        if (len(group[(group['var_id'].isin(nb_and_dad['var_id']))] > 1) and \\\n",
      "                len(group[(group['var_id'].isin(nb_and_mom['var_id']))] > 1)):\n",
      "            comp_hets.append(group)\n",
      "        # or if there is a variant from both parents\n",
      "        elif (len(group[(group['var_id'].isin(nb_and_dad['var_id']))] > 0) and \\\n",
      "                len(group[(group['var_id'].isin(nb_and_mom['var_id']))] > 0)):\n",
      "            # and those variants are different\n",
      "            if len(group[(group['var_id'].isin(fathers['var_id']))].pos - group[(group['var_id'].isin(mothers['var_id']))].pos) > 0:\n",
      "                    comp_hets.append(group)\n",
      "\n",
      "# combine results into dataframe                    \n",
      "comphet_df = pd.concat(comp_hets)\n",
      "\n",
      "print str(len(comphet_df)) + \" comp_het variants found.\""
     ],
     "language": "python",
     "prompt_number": 201
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding newborns predicted to have NBS conditions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dominant, homozgous recessive and compound heterozygous recessive candidate variants were filtered to locate \n",
      "newborns predicted to have NBS conditions:    \n",
      "\n",
      "- Presence of mutation(s) with appropriate inheritance using filtering procedures outlined above  \n",
      "- Mutations defined strictly as either:   \n",
      "    - Clearly annotated in ClinVar, HGMD or both, as pathogenic or disease-causing for the NBS condition   \n",
      "     OR  \n",
      "    - Novel but predicted to be disease-causing (ie, a stop-gain, stop-loss, splice-site, whole-exon or larger deletion, or frameshift).  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3_prime_UTR_variant                               52\nsynonymous_variant                                35\nmissense_variant                                  26\ndownstream_gene_variant                            2\n5_prime_UTR_variant                                2\n5_prime_UTR_premature_start_codon_gain_variant     1\ndtype: int64\n"
       ]
      }
     ],
     "input": [
      "print nb_dominant['effect'].value_counts()"
     ],
     "language": "python",
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-19-3484c7e441b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mnb_dominant\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_dominant\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clin_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mnb_dominant\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\WinPython-64bit-2.7.9.3\\python-2.7.9.amd64\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    696\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[0;32m    697\u001b[0m                          \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
       ]
      }
     ],
     "input": [
      "disease_causing = ['']\n",
      "\n",
      "# subset for variants where clinvar is not null \n",
      "# or the variant is in the disease causing list\n",
      "nb_dominant[(nb_dominant['clin_acc'].notnull())]:"
     ],
     "language": "python",
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "6,927 variants were located in the NBS gene list. Of those variants: \n",
      "\n",
      "- 118 dominant variants found.  \n",
      "- 248 homozygous recessive variants found.  \n",
      "- 192 comp_het variants found."
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dominant \n\nImpact: \nMODIFIER    56\nLOW         36\nMODERATE    26\ndtype: int64\n\n\nEffect: \n3_prime_UTR_variant                               52\nsynonymous_variant                                35\nmissense_variant                                  26\ndownstream_gene_variant                            2\n5_prime_UTR_variant                                2\n5_prime_UTR_premature_start_codon_gain_variant     1\ndtype: int64\n\n\nCondiction: \nChoreoathetosis: hypothyroidism: and neonatal respiratory distress    45\nPallister-Hall syndrome 2                                       33\nHypothyroidism: congenital: nongoitrous 2                       32\nHypothyroidism: congenital nongoitrous: 5                        8\ndtype: int64\n\n\nHomozygous Recessive \n\nImpact: \nMODERATE    111\nMODIFIER     71\nLOW          66\ndtype: int64\n\n\nEffect: \ndisruptive_inframe_deletion    60\nmissense_variant               51\n3_prime_UTR_variant            43\nTF_binding_site_variant        38\nsynonymous_variant             17\ndownstream_gene_variant        13\nsequence_feature                9\nintron_variant                  9\nupstream_gene_variant           4\nnon_coding_exon_variant         2\nsplice_region_variant           2\ndtype: int64\n\n\nCondiction: \nNiemann-Pick disease: type A: Niemann-Pick disease: type B      60\nAcyl-CoA dehydrogenase: very long chain: deficiency of          36\n  Mucopolysaccharidosis: type Ih (Hurler syndrome)              33\nAcyl-CoA dehydrogenase: medium chain: deficiency of             15\nSevere combined immunodeficiency                                14\nMethylmalonic acidemia: cblG type                               12\nHyperprolinemia: type I                                         10\nMitochondrial DNA depletion syndrome 9 (encephalomyopathic type with methylmalonic aciduria)     9\nMultiple acyl-CoA dehydrogenase deficiency: Glutaric aciduria IIC     8\nMaple syrup urine disease: type II                               7\nCombined malonic and methylmalonic aciduria                      6\nAlpha-methylacetoacetic aciduria                                 5\nMucopolysaccharidosis: type VII (Sly syndrome)                   4\nGalactosemia                                                     4\nDiabetes mellitus: neonatal: with congenital hypothyroidism      3\nHypothyroidism: congenital: nongoitrous: 1                       3\n3-beta-hydroxysteroid dehydrogenase: type II: deficiency         2\nBamforth-Lazarus syndrome                                        2\nHomocystinuria                                                   2\n3-methylglutaconic aciduria: type III                            2\nGalactose epimerase deficiency                                   2\nTrifunctional protein deficiency                                 2\nCystinosis (multiple types)                                      2\nMethylmalonic acidemia: cblB type                                1\nTranscobalamin II deficiency                                     1\nMethylmalonic acidemia due to methylmalonyl-CoA mutase deficiency     1\nMucopolysaccharidosis: type VI (Maroteaux-Lamy syndrome)         1\nT cell-negative: B cell-negative: natural killer cell-positive severe combined immunodeficiency: Omenn syndrome: Alpha/beta T-cell lymphopenia with gamma/delta T-cell expansion: severe cytomegalovirus infection: and autoimmunity: Combined cellular and humoral immune defects with granulomas     1\ndtype: int64\n\n\nCompound Heterozygous \n\nImpact: \nMODIFIER    79\nLOW         61\nMODERATE    52\ndtype: int64\n\n\nEffect: \nmissense_variant           52\n3_prime_UTR_variant        44\nsynonymous_variant         36\nsequence_feature           25\n5_prime_UTR_variant        15\ndownstream_gene_variant    12\nintron_variant              5\nnon_coding_exon_variant     2\nupstream_gene_variant       1\ndtype: int64\n\n\nCondiction: \n  Mucopolysaccharidosis: type Ih (Hurler syndrome)              23\nMultiple acyl-CoA dehydrogenase deficiency: Glutaric aciduria IIB    19\nMaple syrup urine disease: mild variant                         16\nTyrosinemia: type I                                             16\nCombined malonic and methylmalonic aciduria                     15\nCystic fibrosis                                                 10\nMaple syrup urine disease: type II                               9\nAcyl-CoA dehydrogenase family: member 9: deficiency of           9\nProlidase deficiency                                             9\nHolocarboxylase synthetase deficiency                            8\nMucopolysaccharidosis: type VII (Sly syndrome)                   7\nDiabetes mellitus: neonatal: with congenital hypothyroidism      6\nOmenn syndrome: Severe combined immunodeficiency with sensitivity to ionizing radiation     6\nGalactose epimerase deficiency                                   6\n3-methylglutaconic aciduria: type III                            5\nHyperprolinemia: type I                                          5\nTranscobalamin II deficiency                                     5\nThyroid dyshormonogenesis 4                                      4\nPhenylketonuria: Hyperphenylalaninemia: non-PKU mild             3\nBamforth-Lazarus syndrome                                        3\nAlpha-methylacetoacetic aciduria                                 2\nCarbamoylphosphate synthetase I deficiency                       2\nLipoid adrenal hyperplasi                                        2\nNiemann-Pick disease: type C1: Niemann-Pick disease: type D      2\ndtype: int64\n\n\n"
       ]
      }
     ],
     "input": [
      "def summarize(df):\n",
      "    impact = df['impact'].value_counts()\n",
      "    print \"Impact: \\n\", impact\n",
      "    print \"\\n\"\n",
      "    effect = df['effect'].value_counts()\n",
      "    print \"Effect: \\n\", effect\n",
      "    print \"\\n\"\n",
      "    condition = df['condition'].value_counts()\n",
      "    print \"Condiction: \\n\", condition\n",
      "    print \"\\n\"\n",
      "    \n",
      "print \"Dominant \\n\"    \n",
      "summarize(nb_dominant)\n",
      "\n",
      "print \"Homozygous Recessive \\n\"    \n",
      "summarize(nb_hom_recessive)\n",
      "    \n",
      "print \"Compound Heterozygous \\n\"    \n",
      "summarize(comphet_df)"
     ],
     "language": "python",
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Saving Output"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving 192 het variants to nb_het.csv in current working directory\nSaving 118 dominant variants to nb_dominant.csv in current working directory\nSaving 248 homozygous recessive variants to nb_hom_recessive.csv in current working directory\n"
       ]
      }
     ],
     "input": [
      "# save output to current working directory\n",
      "\n",
      "print \"Saving \" + str(len(comphet_df)) + \" het variants to nb_het.csv in current working directory\"\n",
      "comphet_df.to_csv('nb_het.csv', header=True, encoding='utf-8', index=False)\n",
      "\n",
      "print \"Saving \" + str(len(nb_dominant)) + \" dominant variants to nb_dominant.csv in current working directory\"\n",
      "nb_dominant.to_csv('nb_dominant.csv', header=True, encoding='utf-8', index=False)\n",
      "\n",
      "print \"Saving \" + str(len(nb_hom_recessive)) + \" homozygous recessive variants to nb_hom_recessive.csv in current working directory\"\n",
      "nb_hom_recessive.to_csv('nb_hom_recessive.csv', header=True, encoding='utf-8', index=False)"
     ],
     "language": "python",
     "prompt_number": 33
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0
}