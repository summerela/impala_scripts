{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 1,
     "source": [
      "NBS Gene Annotation"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Purpose"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the following newborns:   \n",
      "\n",
      "102-07005-03  \n",
      "102-00997-03  \n",
      "102-00996-03  \n",
      "102-02001-03  \n",
      "102-00961-03  \n",
      "102-07009-03  \n",
      "102-00932-03  \n",
      "102-00979-03  \n",
      "102-01532-03  \n",
      "102-00974-03  \n",
      "\n",
      "Variants were annotated with the NBS gene table provided by Ben Solomon at ITMI. Variants located in NBS gene regions were filtered, keeping only variants with a Kaviar frequency less than 1%. Candidate variants were then annotated with ClinVar, DANN scores for SNV's and coding consequence predictions. Results were reported for Dominant, homozygous recessive and compound heterozygotes. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Transform of NBS Gene Table"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The NBS Gene Table provided by ITMI was transformed as follows and uploaded to impala:   \n",
      "\n",
      "- A 'level' column was added to represent the color coding found in the file, with the following options: red, yellow, null  \n",
      "- All commas were replaced with colons to prevent errors while importing csv file  \n",
      "- All semicolons were replaced with colons for consistency of data  \n",
      "- Spaces in column names were replaced with underscores  \n",
      "- Special characters were removed from column names"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding positional information to the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Chromosome, start and stop positions were added to the NBS Gene list by joining it with the \n",
      "ensembl_genes table using gene name. This resulted in mulitple listings per gene for each exon, \n",
      "allowing for more precise matches. \n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_ensembl AS \n",
      "            SELECT DISTINCT nbs.gene, nbs.entrez_gene_id as entrez_id, ens.gene_id AS ensembl_id, \n",
      "                ens.chromosome as chrom, ens.start, ens.stop, nbs.condition, nbs.omim_phenotype, \n",
      "                nbs.va_name, nbs.inheritance, nbs.allelic_condition, nbs.in_pgb, nbs.level, ens.feature, \n",
      "                ens.transcript_name, ens.transcript_id, ens.exon_number, ens.exon_id, ens.gene_biotype, nbs.comments\n",
      "            FROM users_selasady.nbs_genes nbs\n",
      "            LEFT JOIN\n",
      "                public_hg19.ensembl_genes ens\n",
      "                ON nbs.gene = ens.gene_name\n",
      "\n",
      "The results were saved as users _ selasady.nbs _ ensembl containing 20872 rows. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding rare variants with Kaviar"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For all trio members in the family's listed above, variants were filtered using Kaviar to retain only variants with a Kaviar frequency of less than .01, or variants not listed in Kaviar at all. The rare variants were then joined with the nbs_ensembl table to locate rare variants falling in NBS gene regions.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "     CREATE TABLE nbs_kaviar AS          \n",
      "          WITH bv as (\n",
      "              SELECT bv.sample_id, bv.chr as chrom, bv.pos, bv.id, bv.ref, \n",
      "                  bv.alt, bv.qual, bv.filter, bv.gt, k.alle_freq\n",
      "             FROM p7_platform.brady_variant bv\n",
      "             LEFT JOIN /* +SHUFFLE */ public_hg19.kaviar k\n",
      "                  ON bv.chr = k.chromosome\n",
      "                  AND bv.pos = k.pos\n",
      "                  AND bv.ref = k.ref\n",
      "                  AND bv.alt = k.alt\n",
      "             WHERE (k.alle_freq < .01 OR k.alle_freq IS NULL)\n",
      "            AND (bv.sample_id LIKE '%03' OR bv.sample_id LIKE '%02' OR bv.sample_id LIKE '%01')\n",
      "         )\n",
      "        SELECT bv.*, nbs.gene, nbs.entrez_id, nbs.ensembl_id, nbs.condition, \n",
      "            nbs.omim_phenotype, nbs.va_name, nbs.inheritance, nbs.allelic_condition,nbs.in_pgb, \n",
      "            nbs.level, nbs.feature, nbs.transcript_name, nbs.transcript_id, nbs.exon_number, \n",
      "            nbs.exon_id, nbs.gene_biotype, nbs.comments          \n",
      "        FROM bv, users_selasady.nbs_ensembl nbs\n",
      "       WHERE bv.chrom = nbs.chrom\n",
      "       AND bv.pos BETWEEN nbs.start and nbs.stop\n",
      "\n",
      "This table was saved as users _ selasady.nbs _ kaviar with 6760 rows. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Annotating with ClinVar and DANN scores "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Rare variants were annotated with the ClinVar table using genomic position. Variants with a ClinVar significance rating of 4 or 5, but never 2 or 3, were marked with a 'Y' in the clin_patho column to denote non-conflicted pathogenically significant ratings.\n",
      "\n",
      "DANN scores whole-genome variants by training a deep neural network (DNN). DNNs can capture non-linear relationships among features, and are better suited than SVMs for problems with a large number of samples and features. DANN scores have been shown to outperform both CADD and FATHMM (http://www.enlis.com/blog/2015/03/17/the-best-variant-prediction-method-that-no-one-is-using/).\n",
      "\n",
      "DANN scores are provided for SNV's and range between 0 and 1. The closer a score is to 1, the more pathogenic the variant. \n",
      "\n",
      "The following query was used to annotate the nbs variants with DANN scores by matching on chromosome and position, then outputting the score for the alt allele. \n",
      "\n",
      "        CREATE TABLE nbs_annotated AS \n",
      "        WITH n as (\n",
      "            SELECT nbs.*, clin.clin_hgvs, clin.clin_sig, clin.clin_dbn, clin.clin_acc,\n",
      "                CASE WHEN (clin.clin_sig NOT REGEXP '3|2[^5]|2 (replace this text with a dollar sign)'  \n",
      "                    AND  clin.clin_sig REGEXP '4|[^25]5|^5') THEN 'Y'\n",
      "                    ELSE 'N'\n",
      "                END AS clin_patho\n",
      "            FROM users_selasady.nbs_kav_genes nbs\n",
      "            LEFT JOIN public_hg19.clinvar clin\n",
      "                ON nbs.chrom = clin.chrom\n",
      "                AND nbs.pos = clin.pos\n",
      "                AND nbs.ref = clin.ref\n",
      "                AND nbs.alt = clin.alt\n",
      "         )\n",
      "        SELECT n.*, \n",
      "            CASE WHEN n.alt = 'A' THEN d.score_a\n",
      "                WHEN n.alt = 'T' THEN d.score_t\n",
      "                WHEN n.alt = 'G' THEN d.score_g\n",
      "                WHEN n.alt = 'C' THEN d.score_c\n",
      "                ELSE 'indel'\n",
      "             END as dann_score, \n",
      "             CASE\n",
      "                 WHEN SUBSTRING(n.sample_id, -2) = '01'THEN 'M'\n",
      "                 WHEN SUBSTRING(n.sample_id, -2) = '02' THEN 'F'\n",
      "                 WHEN SUBSTRING(n.sample_id, -2) = '03'THEN 'NB'\n",
      "             END as member,\n",
      "             SUBSTRING(n.sample_id, 1, (length(n.sample_id)-3)) as family_id,\n",
      "             CONCAT(n.chrom, ':', CAST(n.pos AS STRING), ':', n.ref, ':', n.alt, ':', SUBSTRING(n.sample_id, 1, (length(n.sample_id)-3))) as var_id\n",
      "        FROM n\n",
      "        LEFT JOIN public_hg19.DANN d\n",
      "            ON n.chrom = d.chrom\n",
      "            AND n.pos = d.pos\n",
      "\n",
      "This table was saves as users _ selasady.nbs _ annotated with 6,760 rows. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reading the impala results into python"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "#################\n",
      "# load modules  #\n",
      "#################\n",
      "import pandas as pd\n",
      "from impala.dbapi import connect\n",
      "from impala.util import as_pandas\n",
      "\n",
      "#create database connection\n",
      "conn = connect(host='glados19', port=21050)\n",
      "cur = conn.cursor()\n",
      "\n",
      "# query to left join nbs_annotated variants with DANN scores\n",
      "query = \"\"\"\n",
      "    SELECT * FROM users_selasady.nbs_annotated\n",
      "    \"\"\"\n",
      "# run query on impala\n",
      "cur.execute(query)\n",
      "\n",
      "#store results as pandas data frame\n",
      "nbs_df = as_pandas(cur)"
     ],
     "language": "python",
     "prompt_number": 119
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding Functional Annotation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn set was output to a modified version of Plink's tab2vcf script to create a VCF file for use with SnpEff. The newborn variants in the VCF file were annotated with coding consequences using SnpEff version 4.1h (build 2015-08-03) with GRCh37.75. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import subprocess as subp\n",
      "import numpy as np\n",
      "import os\n",
      "import pandas as pd\n",
      "import sys\n",
      "\n",
      "# enter path to your snpeff jar\n",
      "snpeff_path = '/Users/selasady/tools/snpEff/snpEff.jar'\n",
      "\n",
      "# enter basename for output files\n",
      "out_name = 'nbs_genes'\n",
      "\n",
      "# setup file names\n",
      "tsv_outname = '{}/{}.tsv'.format(os.getcwd(), out_name)\n",
      "vcf_outname = '{}/{}.vcf'.format(os.getcwd(), out_name)\n",
      "snpeff_outname = '{}/{}_snpeff'.format(os.getcwd(), out_name)\n",
      "\n",
      "# function to add functional annotation\n",
      "def df_to_snpeff(input_df):\n",
      "    if os.path.exists(snpeff_path):\n",
      "        # subset columns to output to vcf file\n",
      "        df = input_df[['chrom', 'pos', 'ref', 'alt']]\n",
      "        # write to file for conversion to vcf\n",
      "        df.to_csv(tsv_outname, header=True, encoding='utf-8', sep=\"\\t\", index=False)\n",
      "        # command to run tab2vcf and then snpeff\n",
      "        run_cmd = './tab2vcf.py ' + tsv_outname + ' && java -Xmx4g -jar {} -v GRCh37.75 {} > {}'.format(snpeff_path, vcf_outname, snpeff_outname)\n",
      "        # run tab2vcf and upon success, run snpeff\n",
      "        snpeff_process = subp.Popen(run_cmd, shell=True)\n",
      "        snpeff_process.communicate()[0]\n",
      "    else:\n",
      "        print \"Make sure you entered the correct path to snpeff.jar.\"\n",
      "        sys.exit(1)\n",
      "\n",
      "# run function on dataframe\n",
      "try :\n",
      "    df_to_snpeff(nbs_df)\n",
      "except Exception,e: print str(e)"
     ],
     "language": "python",
     "prompt_number": 120
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The functional annotations were read back into Python, parsed and matched with the each respective variant data frame. \n",
      "\n",
      "Annotated variants were then labled as pathogenic if they predicted a newborn to have an NBS conddition based on the following parameters:   \n",
      "- Presence of mutation(s) with appropriate inheritance (eg, 2 bi-allelic pathogenic mutations for a recessive disorder).  \n",
      "- Mutations are defined strictly as either:   \n",
      "    - Annotated in ClinVar with a clinical significance of 4 or 5, but never 2 or 3 or labeled pathogenic in HGMD (to be added later) OR\n",
      "    - Novel but predicted to be disease-causing (ie, a stop-gain, stop-loss, splice-site, whole-exon or larger deletion, or frameshift) \n",
      "\n",
      "This output will be used downstream to output a list of high priority variants for examination. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# add snpeff annotations back to dataframe\n",
      "def parse_snpeff(input_df):\n",
      "    # merge snpeff annotated vcf file with dataframe , skipping header\n",
      "    annot_vcf = pd.read_csv(snpeff_outname, sep='\\t', skiprows=8)\n",
      "    # split info columns by \"|\" and keep only most detrimental consequence (first)\n",
      "    info_df = pd.DataFrame(list(annot_vcf['INFO'].str.split('|')))\n",
      "    # keep only first consequence listed\n",
      "    info_df = info_df[list(info_df.columns[1:11])]\n",
      "    # merge truncated info field with annot_vcf\n",
      "    annot_vcf = annot_vcf[np.r_[0:2, 3, 4]]\n",
      "    annot_df = pd.concat([annot_vcf, info_df], axis=1)\n",
      "    # remove duplicated rows\n",
      "    annot_df.drop_duplicates(inplace=True)\n",
      "    # rename columns\n",
      "    annot_df.columns =['chrom', 'pos', 'ref', 'alt', 'effect', 'impact', 'gene_name', 'gene_id', 'feature_type', \\\n",
      "        'feature_id', 'tx_biotype', 'rank', 'hgvs_c', 'hgvs_p']\n",
      "    # merge annotations with variant table\n",
      "    df_functional = pd.merge(input_df, annot_df, on=['chrom', 'pos', 'ref', 'alt'], how='left')\n",
      "    # drop columns with duplicated info after merge\n",
      "    df_functional.drop(['gene_name', 'gene_id', 'feature_id', 'feature_type', 'rank'], axis=1, inplace=True)\n",
      "    return df_functional\n",
      "    \n",
      "# merge nbs_genes with functional annotations\n",
      "nbs_annot = parse_snpeff(nbs_df)\n",
      "\n",
      "# label variants considered pathogenic \n",
      "nbs_annot['pathogenic'] = (nbs_annot['impact'] == 'HIGH') |  (nbs_annot['clin_patho'] == 'Y')"
     ],
     "language": "python",
     "prompt_number": 121
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataframe was separated into mother, father and newborn for downstream analysis. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of newborn variants: 2331\nNumber of mother variants: 2294\nNumber of father variants: 2135\n"
       ]
      }
     ],
     "input": [
      "# subset data frame by trio member\n",
      "newborns = nbs_annot[nbs_annot['member'] == 'NB']\n",
      "mothers = nbs_annot[nbs_annot['member'] == 'M']\n",
      "fathers = nbs_annot[nbs_annot['member'] == 'F']\n",
      "\n",
      "print \"Number of newborn variants: \" + str(len(newborns)) \n",
      "print \"Number of mother variants: \" + str(len(mothers)) \n",
      "print \"Number of father variants: \" + str(len(fathers))"
     ],
     "language": "python",
     "prompt_number": 122
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn subset was split to report:   \n",
      "- All variants in regions of dominant disorders  \n",
      "- All homozygous recessive variants in regions of autosomal recessive disorders  \n",
      "- All heterozygous variants in autosomal recessive regions for downstream analysis of compound heterozygosity  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# disable erroneous pandas warning\n",
      "pd.options.mode.chained_assignment = None\n",
      "\n",
      "# subset newborns by variant MOI and/or zygosity\n",
      "nb_dominant = newborns[(newborns['inheritance'] == 'AD')]\n",
      "nb_hom_recessive = newborns[((newborns['inheritance'] == 'AR') & (newborns['gt'] == '1/1'))]\n",
      "nb_het = newborns[((newborns['inheritance'] == 'AR') & (newborns['gt'] == '0/1'))]"
     ],
     "language": "python",
     "prompt_number": 123
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reporting compound heterozygous recessive variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Heterozygous variants in autosomal recessive regions were examined for compound heterozygosity, as follows:   \n",
      "- Newborns must inherit at least one variant from each parent, at different positions on the same gene  \n",
      "- Parents must be heterozygous for the matching variant  \n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# keep only heterozygous variants, as homozygous parents are not of interest\n",
      "mom_het = mothers.loc[mothers['gt'] == '0/1']\n",
      "dad_het = fathers.loc[fathers['gt'] == '0/1']\n",
      "\n",
      "# function to drop extra columns ending in _y from df merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "            \n",
      "# function to find matching parent variants\n",
      "def find_parent_vars(nb_df, parent_df):\n",
      "    # merge dataframes on variant id\n",
      "    merged_df = pd.merge(nb_df, parent_df, on=['var_id'], how='inner')\n",
      "    # rename parent sample_id column to avoid dropping when removing '_y' cols\n",
      "    merged_df.rename(columns = {'sample_id_y':'parent_id'}, inplace=True)\n",
      "    # drop extra y columns from merge with fathers\n",
      "    drop_y(merged_df)\n",
      "    #remove _x from colnames\n",
      "    merged_df.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "    return merged_df\n",
      "    \n",
      "# run function for each parent set\n",
      "nb_and_mom = find_parent_vars(nb_het, mom_het)\n",
      "nb_and_dad = find_parent_vars(nb_het, dad_het)"
     ],
     "language": "python",
     "prompt_number": 124
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After creating data frames for variants that have a pathogenic variant from either the mother or father, these variants are grouped by gene to search for regions with variants at more than one position. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# merge variants found in either mother or father\n",
      "het_cands = pd.concat([nb_and_mom,nb_and_dad]).drop_duplicates().reset_index(drop=True)\n",
      "\n",
      "# group variants by gene name\n",
      "by_gene = het_cands.groupby(['gene', 'family_id'])"
     ],
     "language": "python",
     "prompt_number": 125
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After grouping the variants by gene, the variants will be filtered to keep only variants with at least one different variant coming from the mother and one from the father.  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "what?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\nwhat?\n"
       ]
      }
     ],
     "input": [
      "# function to find compound hets\n",
      "def find_comphets(gene_group, comphet_list_name):\n",
      "    for name, group in gene_group:\n",
      "        #if there is a variant in more than one position\n",
      "        if group.pos.nunique() > 1:\n",
      "            if len(group[group['member'] == 'M'] > 1):\n",
      "                print group\n",
      "            else: \n",
      "                print 'what?'\n",
      "            # and there are more than one variants from both parents\n",
      "            # if ((len(group[(group['member'] == 'M')] > 1) and (len(group[(group['member'] == 'F')] > 1))):\n",
      "            #     comphet_list_name.append(group)\n",
      "            # # or if there is a variant from both parents\n",
      "            # elif (len(group[(group['member'] == 'M')] = 1) and (len(group[(group['member'] == 'F')] = 1)):\n",
      "            #     # and those variants are different\n",
      "            #     if len(group[(group['member'] == 'M'].pos - group[(group['member'] == 'F'].pos) > 0:\n",
      "            #             comphet_list_name.append(group)\n",
      "\n",
      "# create empty list to store comp_hets\n",
      "comp_hets = []\n",
      "# run function on by_gene\n",
      "find_comphets(by_gene, comp_hets)\n",
      "# combine results into datafrae \n",
      "#comphet_df = pd.concat(comp_hets)"
     ],
     "language": "python",
     "prompt_number": 136
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding newborns predicted to have NBS conditions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dominant, homozgous recessive and compound heterozygous recessive candidate variants were filtered to locate \n",
      "newborns predicted to have NBS conditions:     \n",
      "\n",
      "- Presence of mutation(s) with appropriate inheritance using filtering procedures outlined above   \n",
      "- Mutations defined strictly as either:   \n",
      "    - Clearly annotated in ClinVar, HGMD or both, as pathogenic or disease-causing for the NBS condition   \n",
      "     OR  \n",
      "    - Novel but predicted to be disease-causing (ie, a rating of 'HIGH' from SnpEff impact score)  \n",
      "- Additionally, compound heterozygous variants will be filtered to include only mutations where both variants inherited from the parent are pathogenic  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# return only variants that are pathogenic\n",
      "nb_dom_patho= nb_dominant.loc[nb_dominant['pathogenic'] == True]\n",
      "nb_hom_rec_patho = nb_hom_recessive.loc[nb_hom_recessive['pathogenic'] == True]\n",
      "\n",
      "###############################################################\n",
      "## find comp_het variants where both variants are pathogenic ##\n",
      "###############################################################\n",
      "\n",
      "# subset nb het variants to include only pathogenic variants\n",
      "nb_het_pathos = nb_het.loc[nb_het['pathogenic'] == True]\n",
      "\n",
      "# merge nb_het_pathos with matching parent variants\n",
      "nbpatho_and_mom = find_parent_vars(nb_het_pathos, mom_het)\n",
      "nbpatho_and_dad = find_parent_vars(nb_het_pathos, dad_het) \n",
      "\n",
      "# merge variants found in either mother or father\n",
      "het_patho_cands = pd.concat([nbpatho_and_mom,nbpatho_and_dad]).drop_duplicates().reset_index(drop=True)\n",
      "\n",
      "# group nb_het_patho by gene and family id\n",
      "patho_by_gene = het_patho_cands.groupby(['gene', 'family_id'])\n",
      "\n",
      "# create empty list to store comp_hets\n",
      "comphet_patho = []\n",
      "# run function on by_gene\n",
      "find_comphets(patho_by_gene, comphet_patho)\n",
      "\n",
      "if len(comphet_patho) > 0:\n",
      "    # combine results into dataframe\n",
      "    comphet_patho_df = pd.concat(comphet_patho)\n",
      "else:\n",
      "    comphet_patho_df = ''"
     ],
     "language": "python",
     "prompt_number": 127
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Results"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variants found:\n114 dominant variants found.\n247 homozygous recessive variants found.\n229 compound het variants found.\n\n\nOf those variants, the following were predicted to cause NBS disorders:\nNo pathogenic dominant variants found.\nNo pathogenic homozygous recessive variants found.\nNo pathogenic comp het variants found.\n"
       ]
      }
     ],
     "input": [
      "# report variant counts\n",
      "def report_result_counts(results_df, result_type_name):\n",
      "    if len(results_df) > 0:\n",
      "        print str(len(results_df)) + ' {} variants found.'.format(result_type_name)\n",
      "    else:\n",
      "         print \"No {} variants found.\".format(result_type_name)\n",
      "        \n",
      "print \"Variants found:\"\n",
      "report_result_counts(nb_dominant, 'dominant')\n",
      "report_result_counts(nb_hom_recessive, 'homozygous recessive')\n",
      "report_result_counts(comphet_df, 'compound het')\n",
      "print \"\\n\"\n",
      "\n",
      "print \"Of those variants, the following were predicted to cause NBS disorders:\"        \n",
      "report_result_counts(nb_dom_patho, 'pathogenic dominant')\n",
      "report_result_counts(nb_hom_rec_patho, 'pathogenic homozygous recessive')\n",
      "report_result_counts(comphet_patho_df, 'pathogenic comp het')\n",
      "\n",
      "def summarize(df, df_name):\n",
      "    if len(df) > 0:\n",
      "        print '\\n' + df_name + ': ', '\\n'\n",
      "        impact = df['impact'].value_counts()\n",
      "        effect = df['effect'].value_counts()\n",
      "        condition = df['condition'].value_counts()\n",
      "        genes = df['gene'].unique()\n",
      "        print 'Impact: \\n', impact, '\\n'\n",
      "        print 'Effect: \\n', effect, '\\n'\n",
      "        print 'Condition: \\n', condition, '\\n'\n",
      "        print 'Affected gene(s): \\n', genes, '\\n'\n",
      "\n",
      "summarize(nb_dom_patho, 'Pathogenic dominant')\n",
      "summarize(nb_hom_rec_patho, 'Pathogenic homozygous recessive')\n",
      "summarize(comphet_patho_df, 'Pathogenic comp het')"
     ],
     "language": "python",
     "prompt_number": 128
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Saving Output"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving 192 het variants to nb_het.csv in current working directory\nSaving 118 dominant variants to nb_dominant.csv in current working directory\nSaving 248 homozygous recessive variants to nb_hom_recessive.csv in current working directory\n"
       ]
      }
     ],
     "input": [
      "# save output to current working directory\n",
      "\n",
      "print \"Saving \" + str(len(comphet_df)) + \" het variants to nb_het.csv in current working directory\"\n",
      "comphet_df.to_csv('nb_het.csv', header=True, encoding='utf-8', index=False)\n",
      "\n",
      "print \"Saving \" + str(len(nb_dominant)) + \" dominant variants to nb_dominant.csv in current working directory\"\n",
      "nb_dominant.to_csv('nb_dominant.csv', header=True, encoding='utf-8', index=False)\n",
      "\n",
      "print \"Saving \" + str(len(nb_hom_recessive)) + \" homozygous recessive variants to nb_hom_recessive.csv in current working directory\"\n",
      "nb_hom_recessive.to_csv('nb_hom_recessive.csv', header=True, encoding='utf-8', index=False)"
     ],
     "language": "python",
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0
}