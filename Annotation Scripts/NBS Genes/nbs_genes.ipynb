{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 1,
     "source": [
      "NBS Gene Annotation"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Purpose"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the following newborns:   \n",
      "\n",
      "102-07005-03  \n",
      "102-00997-03  \n",
      "102-00996-03  \n",
      "102-02001-03  \n",
      "102-00961-03  \n",
      "102-07009-03  \n",
      "102-00932-03  \n",
      "102-00979-03  \n",
      "102-01532-03  \n",
      "102-00974-03  \n",
      "\n",
      "Variants were annotated with the NBS gene table provided by Ben Solomon at ITMI. Variants located in NBS gene regions were filtered, keeping only variants with a Kaviar frequency less than 1%. Candidate variants were then annotated with ClinVar and coding consequence predictions. Results were reported for Dominant, homozygous recessive and compound heterozygotes. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Transform of NBS Gene Table"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The NBS Gene Table provided by ITMI was transformed as follows and uploaded to impala:   \n",
      "\n",
      "- A 'level' column was added to represent the color coding found in the file, with the following options: red, yellow, null  \n",
      "- All commas were replaced with colons to prevent errors while importing csv file  \n",
      "- All semicolons were replaced with colons for consistency of data  \n",
      "- Spaces in column names were replaced with underscores  \n",
      "- Special characters were removed from column names"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Finding rare variants with Kaviar"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To reduce the number of variants input into downstream queries and analysis, all trio variants were annotated with kaviar frequencies, Keep only variants with a kaviar frequency less than .01, or variants not listed in the kaviar table.  \n",
      "\n",
      "         WITH bv AS (\n",
      "             SELECT bv.sample_id, bv.chr, bv.pos, bv.id, bv.ref, bv.alt, bv.qual, bv.filter, bv.gt\n",
      "             FROM p7_platform.brady_variant bv\n",
      "             WHERE (bv.sample_id LIKE '%03' OR bv.sample_id LIKE '%02' OR bv.sample_id LIKE '%01')\n",
      "          )\n",
      "  \n",
      "          SELECT bv.*, k.alle_freq\n",
      "          FROM bv\n",
      "          LEFT JOIN /* +SHUFFLE */ public_hg19.kaviar k\n",
      "               ON bv.chr = k.chromosome\n",
      "               AND bv.pos = k.pos\n",
      "               AND bv.ref = k.ref\n",
      "               AND bv.alt = k.alt\n",
      "         WHERE (k.alle_freq < .01 OR k.alle_freq IS NULL)\n",
      "\n",
      "Query Statements:   \n",
      "- Queries were limited to trio members, excluding more distant relatives  \n",
      "- Keep only variants with a kaviar frequency less than .01, or variants not listed in the kaviar table. \n",
      "\n",
      "Results were saved to an hdfs table named bv_kaviar. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Adding positional information to the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Chromosome, start and stop positions were added to the NBS Gene list by joining it with the \n",
      "ensembl_genes table using gene name. This resulted in mulitple listings per gene for each exon, \n",
      "allowing for more precise matches. \n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_positional AS SELECT nbs.gene, \n",
      "        nbs.entrez_gene_id as entrez_id, ens.gene_id AS ensembl_id, ens.chromosome as chrom, \n",
      "        ens.start, ens.stop, nbs.condition, nbs.omim_phenotype, nbs.va_name, nbs.inheritance, \n",
      "        nbs.allelic_condition, nbs.in_pgb, nbs.level, ens.feature, ens.transcript_name, \n",
      "        ens.transcript_id, ens.exon_number, ens.exon_id, ens.gene_biotype, nbs.comments\n",
      "        FROM users_selasady.nbs_genes nbs\n",
      "        LEFT JOIN\n",
      "                 public_hg19.ensembl_genes ens\n",
      "                ON nbs.gene = ens.gene_name\n",
      "\n",
      "The results were saved as users _ selasady.nbs _ ensembl containing 20872 rows. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Locate rare variants in the NBS gene list"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next the Kaviar-filtered variants were joined with nbs _ ensembl using chromosome, start and stop positions, returning rare variants in the nbs_gene list, and annotated those with ClinVar. \n",
      "\n",
      "\n",
      "        CREATE TABLE users_selasady.nbs_annotated AS \n",
      "            WITH nbs AS (\n",
      "            SELECT bv.sample_id, bv.chr as chrom, bv.pos, bv.id as rs_id, bv.ref, bv.alt, bv.qual, bv.filter,bv.gt, \n",
      "            bv.alle_freq AS kav_freq,nbs.gene, nbs.entrez_id, nbs.ensembl_id, nbs.condition, nbs.omim_phenotype, \n",
      "            nbs.va_name, nbs.inheritance, nbs.allelic_condition,nbs.in_pgb, nbs.level, nbs.feature, \n",
      "            nbs.transcript_name, nbs.transcript_id, nbs.exon_number, nbs.exon_id, nbs.gene_biotype, nbs.comments\n",
      "            FROM public_hg19.bv_kaviar bv, users_selasady.nbs_ensembl nbs\n",
      "            WHERE bv.chr = nbs.chrom\n",
      "            AND bv.pos BETWEEN nbs.start and nbs.stop\n",
      "            )\n",
      "  \n",
      "           SELECT nbs.*, clin.clin_hgvs, clin.clin_sig, clin.clin_dbn, clin.clin_acc \n",
      "           FROM nbs\n",
      "           LEFT JOIN public_hg19.clinvar clin\n",
      "               ON nbs.rs_id = clin.id\n",
      "\n",
      "6927 rows were returned, the table was saved as users _ selasady.nbs_annotated. "
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Add functional annotation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Coding consequences for each variant were predictedusing ensembl VEP. \n",
      "\n",
      "VEP requires input in either VCF format or a tab-delimieted file of chromosomal location and ref and alt alleles. Results from the NBS gene list were read into python. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "#################\n",
      "# load modules  #\n",
      "#################\n",
      "import pandas as pd\n",
      "from impala.dbapi import connect\n",
      "from impala.util import as_pandas\n",
      "\n",
      "#create database connection\n",
      "conn = connect(host='glados19', port=21050)\n",
      "cur = conn.cursor()\n",
      "\n",
      "#########################\n",
      "# Run Query on Impala ##\n",
      "#########################\n",
      "query = \"SELECT * FROM users_selasady.nbs_annotated\"\n",
      "cur.execute(query)\n",
      "\n",
      "#store results as pandas data frame\n",
      "nbs_df = as_pandas(cur)"
     ],
     "language": "python",
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataframe was separated into mother, father and newborn for downstream analysis. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "newborns = nbs_df[nbs_df['sample_id'].str.endswith('03')]\n",
      "mothers = nbs_df[nbs_df['sample_id'].str.endswith('01')]\n",
      "fathers = nbs_df[nbs_df['sample_id'].str.endswith('02')]"
     ],
     "language": "python",
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn set was output to a modified version of Plink's tab2vcf script and annotated with coding consequences using ensembl's VEP version 81 for grch37 (ftp://ftp.ensembl.org/pub/release-81/variation/VEP/homo_sapiens_vep_81_GRCh37.tar.gz). "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "newborns.tsv\n0 1 2 3 6 7 9 4 5 8\n"
       ]
      }
     ],
     "input": [
      "import os\n",
      "import sys\n",
      "\n",
      "# output columns to vcf file using a modified version of anntools tab2vcf.py\n",
      "nb_to_vcf = newborns[['chrom','pos', 'ref', 'alt', 'qual', 'filter','rs_id', 'sample_id', 'gt','gene']]\n",
      "# rename rsid column\n",
      "nb_to_vcf = nb_to_vcf.rename(columns = {'rs_id':'id'})\n",
      "# add unique variant id to rows that have no rsid\n",
      "nb_to_vcf['id'].fillna(nb_to_vcf.apply(lambda x:'{}:{}:{}:{}'.format(x['chrom'],x['pos'], x['ref'], x['alt']),axis=1), inplace=True)\n",
      "\n",
      "# write to file for conversion to vcf\n",
      "nb_to_vcf.to_csv('{}/newborns.tsv'.format(os.getcwd()), header=True, encoding='utf-8', sep=\"\\t\", index=False)\n",
      "\n",
      "# run tab2vcf.py script\n",
      "try:\n",
      "    %run ./tab2vcf.py newborns.tsv\n",
      "except Exception,e: print str(e)"
     ],
     "language": "python",
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Cache directory /.vep/homo_sapiens not found\n"
       ]
      }
     ],
     "input": [
      "# run VEP on newborn vcf file \n",
      "\n",
      "# for windows (update location of vep perl script)\n",
      "!perl D:\\Documents\\tools\\ensembl-tools-release-81\\ensembl-tools-release-81\\scripts\\variant_effect_predictor\\variant_effect_predictor.pl -i newborns.vcf --cache \\home\\summer\\.vep/ --port 3337 --everything --compress \"gzip -dc\""
     ],
     "language": "python",
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reporting dominant and homozygous recessive variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The newborn subset was split into dominant, homozygous recessive and heterozygous variants for downstream analysis. \n",
      "\n",
      "A variant id composed of chrom:pos:ref:alt was added for matching nb comp_het variants with parent variants.  "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "nb_dominant = newborns[(newborns['inheritance'] == 'AD')]\n",
      "nb_hom_recessive = newborns[((newborns['inheritance'] == 'AR') & (newborns['gt'] == '1/1'))]\n",
      "nb_het = newborns[((newborns['inheritance'] == 'AR') & (newborns['gt'] == '0/1'))]\n",
      "\n",
      "# add family id to simplify variant matching\n",
      "nb_het['family_id'] = nb_het['sample_id'].apply(lambda x: x[:-3])\n",
      "mothers['family_id'] = mothers['sample_id'].apply(lambda x: x[:-3])\n",
      "fathers['family_id'] = fathers['sample_id'].apply(lambda x: x[:-3])\n",
      "\n",
      "# add variant id's to simplify variant matching\n",
      "nb_het['var_id'] = nb_het.apply(lambda x:'{}:{}:{}:{}:{}'.format(x['chrom'],x['pos'], x['ref'], x['alt'], \n",
      "                                                                 x['family_id']),axis=1)\n",
      "mothers['var_id'] = mothers.apply(lambda x:'{}:{}:{}:{}:{}'.format(x['chrom'],x['pos'], x['ref'], x['alt'], \n",
      "                                                                   x['family_id']),axis=1)\n",
      "fathers['var_id'] = fathers.apply(lambda x:'{}:{}:{}:{}:{}'.format(x['chrom'],x['pos'], x['ref'], x['alt'], \n",
      "                                                                   x['family_id']),axis=1)"
     ],
     "language": "python",
     "prompt_number": 83
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Reporting heterozygous recessive variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Heterozygous recessive variants were examined for compound heterozygosity and output as a tsv file. \n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# merge het newborns with matching variants from father \n",
      "nb_and_dad = pd.merge(nb_het, fathers, on=['var_id'], how='inner')\n",
      "# rename father's sample_id column\n",
      "nb_and_dad.rename(columns = {'sample_id_y':'sample_id_f'}, inplace=True)\n",
      "\n",
      "# drop extra columns ending in _y from merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "\n",
      "# drop extra y columns from merge with fathers\n",
      "drop_y(nb_and_dad)\n",
      "#remove _x from colnames\n",
      "nb_and_dad.rename(columns=lambda x: x.replace('_x', ''), inplace=True)\n",
      "\n",
      "# merge het newborns with matching variants from mother \n",
      "nb_and_mom = pd.merge(nb_het, mothers, on=['var_id'], how='inner')\n",
      "# rename mother's sample_id column\n",
      "nb_and_mom.rename(columns = {'sample_id_y':'sample_id_m'}, inplace=True)\n",
      "\n",
      "# drop extra columns ending in _y from merge\n",
      "def drop_y(df):\n",
      "    for col in df:\n",
      "        if col.endswith('_y'):\n",
      "            df.drop(col, axis=1, inplace=True)\n",
      "\n",
      "# drop extra y columns from merge with fathers\n",
      "drop_y(nb_and_mom)\n",
      "#remove _x from colnames\n",
      "nb_and_mom.rename(columns=lambda x: x.replace('_x', ''), inplace=True)"
     ],
     "language": "python",
     "prompt_number": 84
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After creating data frames for variants that have a match from either the mother or father, the newborn het dataframe is subset for only variants in either set, and then grouped by gene name to search within genes for compound heterozygosity. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1324 candidate variants found\n"
       ]
      }
     ],
     "input": [
      "# subset nb_hets for only variants found in either mother or father\n",
      "het_cands = (nb_het[(nb_het['var_id'].isin(nb_and_dad['var_id']) | nb_het['var_id'].isin(nb_and_mom['var_id']))])\n",
      "print str(len(het_cands)) + \" candidate variants found\"\n",
      "\n",
      "# group variants by gene name\n",
      "by_gene = het_cands.groupby(['gene', 'family_id'])"
     ],
     "language": "python",
     "prompt_number": 96
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Search for genes that contain newborn variants at more than one position; if those genes have variants from both parents at different positions, mark as compound het. "
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('ACAD9', '102-07005') 1119    102-07005\n4595    102-07005\n4596    102-07005\n4597    102-07005\n4598    102-07005\n4599    102-07005\n4600    102-07005\n4601    102-07005\n4602    102-07005\nName: family_id, dtype: object\n('ACAT1', '102-07005') 1933    102-07005\n5276    102-07005\nName: family_id, dtype: object\n('ACSF3', '102-00996') 1826    102-00996\n1827    102-00996\n1828    102-00996\n1829    102-00996\n1830    102-00996\n1831    102-00996\n1832    102-00996\n6910    102-00996\n6911    102-00996\n6912    102-00996\n6913    102-00996\n6914    102-00996\n6915    102-00996\n6916    102-00996\n6917    102-00996\nName: family_id, dtype: object\n('CFTR', '102-00961')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3515    102-00961\n3516    102-00961\n3517    102-00961\n3518    102-00961\n3559    102-00961\n3560    102-00961\n3561    102-00961\n3562    102-00961\n3563    102-00961\n3564    102-00961\nName: family_id, dtype: object\n('CPS1', '102-02001') 2404    102-02001\n5615    102-02001\nName: family_id, dtype: object\n('DBT', '102-00932') 1703    102-00932\n3995    102-00932\nName: family_id, dtype: object"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n('DBT', '102-00961') 1693    102-00961\n2695    102-00961\nName: family_id, dtype: object\n('DBT', '102-00979') 1700    102-00979\n3994    102-00979\nName: family_id, dtype: object\n('DBT', '102-01532') 1419    102-01532\n1697    102-01532\n3992    102-01532\nName: family_id, dtype: object\n('DCLRE1C', '102-00974') 1972    102-00974\n3854    102-00974\nName: family_id, dtype: object\n('DCLRE1C', '102-00979') 3070    102-00979\n5369    102-00979\n5370    102-00979\n5371    102-00979\nName: family_id, dtype: object\n('ETFB', '102-00974')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1930    102-00974\n2913    102-00974\n2996    102-00974\n5219    102-00974\nName: family_id, dtype: object\n('ETFB', '102-01532') 1916    102-01532\n2981    102-01532\nName: family_id, dtype: object\n('ETFB', '102-02001') 1926    102-02001\n1927    102-02001\n2991    102-02001\n5215    102-02001\n5231    102-02001\n5248    102-02001\nName: family_id, dtype: object\n('ETFB', '102-07005') 2995    102-07005\n5218    102-07005\n5251    102-07005\n6672    102-07005\nName: family_id, dtype: object\n('ETFB', '102-07009') 1920    102-07009\n5229    102-07009\n5245    102-07009\nName: family_id, dtype: object\n('FAH', '102-00979')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2       102-00979\n3       102-00979\n4       102-00979\n5       102-00979\n6       102-00979\n7       102-00979\n8       102-00979\n9       102-00979\n10      102-00979\n11      102-00979\n12      102-00979\n3367    102-00979\n3368    102-00979\n3369    102-00979\n3370    102-00979\n3371    102-00979\nName: family_id, dtype: object\n('FOXE1', '102-07009') 1681    102-07009\n1682    102-07009\n4479    102-07009\nName: family_id, dtype: object\n('GALE', '102-00996') 876     102-00996\n4063    102-00996\n4064    102-00996\nName: family_id, dtype: object\n('GALE', '102-02001') 2379    102-02001\n4079    102-02001\n4080    102-02001\nName: family_id, dtype: object\n('GLIS3', '102-00961') 524     102-00961\n2819    102-00961\n2820    102-00961\n5850    102-00961\nName: family_id, dtype: object"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n('GLIS3', '102-02001') 533     102-02001\n2268    102-02001\nName: family_id, dtype: object\n('GUSB', '102-00979') 1394    102-00979\n3104    102-00979\n3105    102-00979\n3106    102-00979\n3107    102-00979\n3108    102-00979\n3109    102-00979\nName: family_id, dtype: object\n('HLCS', '102-00979') 1585    102-00979\n1586    102-00979\n2457    102-00979\n2458    102-00979\n2459    102-00979\n2460    102-00979\nName: family_id, dtype: object\n('HLCS', '102-07009') 2473    102-07009\n4377    102-07009\nName: family_id, dtype: object\n('IDUA', '102-00961')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4318    102-00961\n4319    102-00961\n4320    102-00961\n4321    102-00961\n4322    102-00961\n4323    102-00961\n4324    102-00961\n6850    102-00961\n6851    102-00961\n6852    102-00961\n6853    102-00961\n6854    102-00961\n6855    102-00961\n6856    102-00961\n6857    102-00961\n6858    102-00961\n6859    102-00961\n6860    102-00961\n6861    102-00961\n6862    102-00961\n6863    102-00961\n6864    102-00961\n6865    102-00961\nName: family_id, dtype: object\n('IYD', '102-00974') 63      102-00974\n64      102-00974\n2447    102-00974\n2448    102-00974\nName: family_id, dtype: object\n('NPC1', '102-00979')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 675     102-00979\n3037    102-00979\nName: family_id, dtype: object\n('OPA3', '102-00996') 4690    102-00996\n5532    102-00996\n5533    102-00996\nName: family_id, dtype: object\n('OPA3', '102-02001') 3803    102-02001\n4698    102-02001\nName: family_id, dtype: object\n('PAH', '102-07009') 2717    102-07009\n3126    102-07009\n5105    102-07009\nName: family_id, dtype: object\n('PEPD', '102-00979') 1736    102-00979\n1737    102-00979\n1738    102-00979\n1739    102-00979\n1740    102-00979\n1741    102-00979\n1742    102-00979\n1743    102-00979\n6803    102-00979\nName: family_id, dtype: object\n('PPM1K', '102-00932')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2735    102-00932\n2738    102-00932\n2739    102-00932\n2740    102-00932\n2741    102-00932\n2742    102-00932\n2743    102-00932\n2744    102-00932\n2745    102-00932\n2746    102-00932\n2747    102-00932\n2748    102-00932\n2749    102-00932\nName: family_id, dtype: object\n('PPM1K', '102-00979') 3620    102-00979\n3622    102-00979\n5114    102-00979\nName: family_id, dtype: object\n('PRODH', '102-02001') 2608    102-02001\n2609    102-02001\n2610    102-02001\n3497    102-02001\n3498    102-02001\nName: family_id, dtype: object\n('STAR', '102-00979') 4866    102-00979\n6701    102-00979\nName: family_id, dtype: object\n('TCN2', '102-07005')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2676    102-07005\n2677    102-07005\n2678    102-07005\n2679    102-07005\n4464    102-07005\nName: family_id, dtype: object\n"
       ]
      }
     ],
     "input": [
      "# create empty list to hold comp_hets\n",
      "comp_hets = []\n",
      "\n",
      "for name, group in by_gene:\n",
      "    #if there is a variant in more than one position\n",
      "    if group.pos.nunique() > 1:\n",
      "        # and there are more than one variants from both parents\n",
      "        if (len(group[(group['var_id'].isin(nb_and_dad['var_id']))] > 1) and \\\n",
      "                len(group[(group['var_id'].isin(nb_and_mom['var_id']))] > 1)):\n",
      "            comp_hets.append(group)\n",
      "            print name, group['family_id']\n",
      "        # or if there is a variant from both parents\n",
      "        elif (len(group[(group['var_id'].isin(nb_and_dad['var_id']))] > 0) and \\\n",
      "                len(group[(group['var_id'].isin(nb_and_mom['var_id']))] > 0)):\n",
      "            # and those variants are different\n",
      "            if len(group[(group['var_id'].isin(fathers['var_id']))].pos - group[(group['var_id'].isin(mothers['var_id']))].pos) > 0:\n",
      "                    comp_hets.append(group)"
     ],
     "language": "python",
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0
}