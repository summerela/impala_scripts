{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Annotated Table of Global Distinct Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tables containing variants in impala will be used to create a global table of disctinct variants. There variants will be given the following annotations: \n",
    "\n",
    "    - SnpEff coding consequence preditions  \n",
    "    - DANN scores  \n",
    "    - Ensembl gene annotations  \n",
    "    - dbSNP rsid  \n",
    "    - Clinvar clinical significance rating  \n",
    "    - Kaviar allele frequency  \n",
    "    \n",
    "To be added when available:   \n",
    "    - PFAM  \n",
    "    - CADD  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ibis: install Ibis from git master https://github.com/cloudera/ibis\n",
    "- Impyla: install impyla from git master https://github.com/cloudera/impyla\n",
    "- SnpEff: http://snpeff.sourceforge.net/\n",
    "- Reference (downloaded automoatically) GRCh37.74 to match vcf files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Impala with Ibis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hdfs: update 'user' argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ibis\n",
    "import os\n",
    "\n",
    "# connect to impala with ibis\n",
    "hdfs_port = os.environ.get('glados20', 50070)\n",
    "hdfs = ibis.hdfs_connect(host='glados20', port=hdfs_port, user='selasady')\n",
    "con = ibis.impala.connect(host='glados19', port=21050, timeout=120)\n",
    "\n",
    "# enable interactive mode\n",
    "ibis.options.interactive = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add All Variants and Annotations from Reference Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All reference sources containing variants were outer joined to compile a list of all variants found on impala. \n",
    "\n",
    "TODO: Variants from CGI and Illumina will be added after normalized files are available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create connections to each needed table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = 'p7_ref_grch37'\n",
    "\n",
    "# connect to variant tables\n",
    "kaviar = con.table('kaviar_isb', database=db)\n",
    "clinvar = con.table('clinvar', database=db) \n",
    "dbsnp = con.table('dbsnp', database=db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Views with Distinct Subsets of each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subset the data for distinct elements from the needed columns\n",
    "kav_sub = kaviar['chrom', 'pos', 'stop', 'ref', 'alt', 'allele_freq', 'sources'].distinct()\n",
    "clin_sub = clinvar['chrom', 'pos', 'ref', 'alt', 'clin_sig', 'clin_dbn'].distinct()\n",
    "dbsnp_sub = dbsnp['chrom', 'pos', 'ref', 'alt', 'rs_id', 'dbsnpbuildid', 'vc'].distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create views on impala\n",
    "con.create_view('kav_distinct', kav_sub, database='training')\n",
    "con.create_view('clin_distinct', clin_sub, database='training')\n",
    "con.create_view('dbsnp_distinct', dbsnp_sub, database='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a connect to each view\n",
    "kav = con.table('kav_distinct', database='training')\n",
    "clin = con.table('clin_distinct', database='training')\n",
    "dbsnp = con.table('dbsnp_distinct', database='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer Join between Kaviar_ISB and ClinVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The Kaviar_ISB file and ClinVar files were joined, keeping all variants found in both tables as well as the Clinvar significance rating and phenotype name. \n",
    " \n",
    "For SNV's, Kaviar and ClinVar were matched by chromosome and exact position, as well as reference and alt allele. For indels, the tables were matched where ClinVar variant position was between the Kaviar reported start and stop position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join clinvar and kaviar for SNP's\n",
    "kav_snp = kav[kav.alt.length() == 1]\n",
    "\n",
    "# create statements to join clinvar and kaviar\n",
    "clin_expr = [kav_snp.chrom == clin.chrom, kav_snp.pos == clin.pos, kav_snp.ref == clin.ref,\\\n",
    "               kav_snp.alt == clin.alt]\n",
    "\n",
    "# create expression for coalescing common columns\n",
    "kav_chrom_col = ibis.coalesce(kav_snp.chrom, clin.chrom).name('chrom')\n",
    "kav_pos_col = ibis.coalesce(kav_snp.pos, clin.pos).cast('int32').name('pos')\n",
    "kav_ref_col = ibis.coalesce(kav_snp.ref, clin.ref).name('ref')\n",
    "kav_alt_col = ibis.coalesce(kav_snp.alt, clin.ref).name('alt')\n",
    "\n",
    "#outer join clinvar with kaviar_isb\n",
    "clin_kav_snp = kav_snp.outer_join(clin, clin_expr)[kav_chrom_col, \\\n",
    "           kav_pos_col, kav_ref_col, kav_alt_col, clin.clin_sig, clin.clin_dbn, \\\n",
    "           kav_snp.allele_freq.name('kav_freq'), kav_snp.sources.name('kav_source')].distinct()\n",
    "\n",
    "# create table with snps\n",
    "con.create_table('clin_kav_distinct', clin_kav_snp, database='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join clinvar and kaviar for indels\n",
    "kav_indel = kav[kav.alt.length() != 1]\n",
    "\n",
    "# create statements to join clinvar and kaviar\n",
    "clin_expr = [kav_indel.chrom == clin.chrom, kav_indel.pos == clin.pos, kav_indel.ref == clin.ref,\\\n",
    "               kav_indel.alt == clin.alt]\n",
    "\n",
    "# create expression for coalescing common columns\n",
    "indel_chrom_col = ibis.coalesce(kav_indel.chrom, clin.chrom).name('chrom')\n",
    "indel_pos_col = ibis.coalesce(kav_indel.pos, clin.pos).cast('int32').name('pos')\n",
    "indel_pos_ref = ibis.coalesce(kav_indel.ref, clin.ref).name('ref')\n",
    "indel_pos_alt = ibis.coalesce(kav_indel.alt, clin.ref).name('alt')\n",
    "\n",
    "#outer join clinvar with kaviar_isb\n",
    "clin_kav_indel = kav_indel.outer_join(clin, clin_expr)[indel_chrom_col, \\\n",
    "           indel_pos_col, indel_pos_ref, indel_pos_alt, clin.clin_sig, clin.clin_dbn,\\\n",
    "           kav_indel.allele_freq.name('kav_freq'), kav_indel.sources.name('kav_source')].distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert indels into clin_kav_distinct table\n",
    "con.insert('clin_kav_distinct', clin_kav_indel, database='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join ClinVar and Kaviar with dbSNP to gain rsID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clin_kav_distinct = con.table('clin_kav_distinct', database='training')\n",
    "\n",
    "# create statements to join the clin_kav table with dbsnp\n",
    "dbsnp_exprs = [clin_kav_distinct.chrom == dbsnp.chrom, clin_kav_distinct.pos == dbsnp.pos, \\\n",
    "               clin_kav_distinct.ref == dbsnp.ref, clin_kav_distinct.alt == dbsnp.alt]\n",
    "\n",
    "# create expression for coalescing common columns\n",
    "clin_kav_chrom = ibis.coalesce(clin_kav_distinct.chrom, dbsnp.chrom).name('chrom')\n",
    "clin_kav_pos = ibis.coalesce(clin_kav_distinct.pos, dbsnp.pos).cast('int32').name('pos')\n",
    "clin_kav_ref = ibis.coalesce(clin_kav_distinct.ref, dbsnp.ref).name('ref')\n",
    "clin_kav_alt = ibis.coalesce(clin_kav_distinct.alt, dbsnp.ref).name('alt')\n",
    "\n",
    "# outer join clin_kav with dbsnp\n",
    "clinkav_dbsnp = clin_kav_distinct.outer_join(dbsnp, dbsnp_exprs)[clin_kav_chrom, clin_kav_pos, clin_kav_ref, clin_kav_alt,\\\n",
    "                        dbsnp.rs_id, clin_kav_distinct.clin_sig, clin_kav_distinct.clin_dbn, clin_kav_distinct.kav_freq, \\\n",
    "                        clin_kav_distinct.kav_source, dbsnp.dbsnpbuildid.name('dbsnp_build'), dbsnp.vc.name('var_type')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reduce all_vars to distinct entries and save as a view on impala to join with indels\n",
    "con.create_table('all_vars', clinkav_dbsnp.distinct(), database='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Regional Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Region-based annotations will be added to speed up downstream analysis and lookups. \n",
    "\n",
    "TODO: Add CADD and PFAM annotations when available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# connect to regional annotation tables\n",
    "dann = con.table('dann', database='p7_ref_grch37')\n",
    "ensembl = con.table('ensembl_genes', database='p7_ref_grch37')\n",
    "dbnsfp = con.table('dbnsfp_variant', database='p7_ref_grch37')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subset tables for only required columns and distinct rows\n",
    "ensembl_sub = ensembl['chrom', 'start', 'stop', 'strand', 'gene_name', 'gene_id'].distinct()\n",
    "dbnsfp_sub = dbnsfp['chrom', 'pos', 'ref', 'alt', 'cadd_raw', 'interpro_domain'].distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create temp tables on impala\n",
    "con.create_table('ens_distinct', ensembl_sub, database='training')\n",
    "con.create_table('dbnsfp_distinct', dbnsfp_sub, database='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a connection to each view or table\n",
    "ens = con.table('ens_distinct', database='training')\n",
    "dbnsfp_dist = con.table('dbnsfp_distinct', database='training')\n",
    "all_vars = con.table('all_vars', database='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Regional Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following annotations will be broken out into chromosome as these tables are getting very large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create case statement to add DANN score depending on reference\n",
    "dann_case = (ibis.case()\n",
    "            .when(all_vars.alt == 'A', dann.score_a)\n",
    "            .when(all_vars.alt == 'T', dann.score_t)\n",
    "            .when(all_vars.alt == 'C', dann.score_c)\n",
    "            .when(all_vars.alt == 'G', dann.score_g)\n",
    "            .else_(ibis.NA)\n",
    "            .end())    \n",
    "\n",
    "# create expression for coalescing common columns\n",
    "dann_chrom = ibis.coalesce(all_vars.chrom, dann.chrom).name('chrom')\n",
    "dann_pos = ibis.coalesce(all_vars.pos, dann.pos).cast('int32').name('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create empty table\n",
    "# create table with variants and dann score annnoations for chromosome 1\n",
    "\n",
    "vars_dann_schema = ibis.schema([('chrom', 'string'), \n",
    "                                ('pos', 'int32'), \n",
    "                                ('ref', 'string'),\n",
    "                                ('alt', 'string'), \n",
    "                                ('rs_id', 'string'), \n",
    "                                ('clin_sig', 'string'),\n",
    "                                ('clin_dbn', 'string'), \n",
    "                                ('kav_freq', 'float'), \n",
    "                                ('kav_source', 'string'),\n",
    "                                ('dbsnp_build', 'string'), \n",
    "                                ('var_type', 'string'), \n",
    "                                ('dann_score', 'float')])\n",
    "\n",
    "con.create_table('vars_dann', schema=vars_dann_schema, database='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create string of chromosomes in the data set\n",
    "chroms = all_vars.chrom.distinct().execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# append each chromosome to vars_dann table\n",
    "for x in chroms:\n",
    "    # create table with variants and dann score annnoations\n",
    "    dann_exp = [all_vars.chrom == x, dann.chrom == all_vars.chrom, all_vars.pos == dann.pos]\n",
    "    con.insert('vars_dann', all_vars.join(dann, dann_exp)\n",
    "               [dann_chrom, \n",
    "                dann_pos, \n",
    "                all_vars.ref, \n",
    "                all_vars.alt, \n",
    "                all_vars.rs_id, \n",
    "                all_vars.clin_sig, \n",
    "                all_vars.clin_dbn, \n",
    "                all_vars.kav_freq, \n",
    "                all_vars.kav_source, \n",
    "                all_vars.dbsnp_build, \n",
    "                all_vars.var_type,                          \n",
    "                dann_case.cast('float').name('dann_score')].distinct(), database='training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# connect to vars_dann table and run compute stats\n",
    "vars_dann = con.table('vars_dann', database='training')\n",
    "vars_dann.compute_stats()\n",
    "\n",
    "# create table with ensembl gene annotations\n",
    "ensembl_exp = [vars_dann.chrom == ens.chrom, vars_dann.pos >= ens.start, \\\n",
    "               vars_dann.pos <= ens.stop]\n",
    "vars_dann_ens = vars_dann.join(ens, ensembl_exp)[vars_dann, ens.gene_name.name('ens_gene')].distinct()\n",
    "\n",
    "# create a table with variants, dann and ensembl annotations\n",
    "con.create_table('vars_dann_ens', vars_dann_ens, database= 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  create a connection to variants with dann and ensembl annotations view \n",
    "add_dbnsfp = con.table('vars_dann_ens', database = 'training')\n",
    "add_dbnsfp.compute_stats()\n",
    "\n",
    "# add CADD and PFAM scores from dbNSFP table\n",
    "dbnsfp_exp = [add_dbnsfp.chrom == dbnsfp_dist.chrom, add_dbnsfp.pos == dbnsfp_dist.pos, \\\n",
    "              add_dbnsfp.ref == dbnsfp_dist.ref, add_dbnsfp.alt == dbnsfp_dist.alt]\n",
    "\n",
    "global_vars = add_dbnsfp.join(dbnsfp_dist, dbnsfp_exp)[add_dbnsfp, dbnsfp_dist.sift_score,  \\\n",
    "                         dbnsfp_dist.polyphen2_hdiv_score, dbnsfp_dist.polyphen2_hvar_score, \\\n",
    "                         dbnsfp_dist.cadd_raw, dbnsfp_dist.interpro_domain].distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save global variants as impala table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table is too large to add snpeff annotations without first saving the table to impala. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "Operation is in ERROR_STATE",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e3030f6ef2e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'global_vars'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\ibis\\impala\\client.pyc\u001b[0m in \u001b[0;36mcreate_table\u001b[1;34m(self, table_name, obj, schema, database, format, force, external, path, partition, like_parquet)\u001b[0m\n\u001b[0;32m    798\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIbisError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Must pass expr or schema'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_write_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\ibis\\client.pyc\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, query, results)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\ibis\\impala\\client.pyc\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, query, async)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\ibis\\impala\\client.pyc\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, stmt, async)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_synchronous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_wait_synchronous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\ibis\\impala\\client.pyc\u001b[0m in \u001b[0;36m_wait_synchronous\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhs2_cursor_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_op_state_is_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mOperationalError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Operation is in ERROR_STATE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_op_state_is_executing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: Operation is in ERROR_STATE"
     ]
    }
   ],
   "source": [
    "con.create_table('global_vars', global_vars.distinct(), database='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up temp tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "    - Add normalized variants from illumina and cgi\n",
    "    - Add PFAM domains\n",
    "    - Add snpeff annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
