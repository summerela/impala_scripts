{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Annotated Table of Global Distinct Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tables containing variants in impala will be used to create a global table of disctinct variants. There variants will be given the following annotations: \n",
    "\n",
    "    - SnpEff coding consequence preditions  \n",
    "    - DANN scores  \n",
    "    - Ensembl gene annotations  \n",
    "    - dbSNP rsid  \n",
    "    - Clinvar clinical significance rating  \n",
    "    - Kaviar allele frequency  \n",
    "    \n",
    "To be added when available:   \n",
    "    - PFAM  \n",
    "    - CADD  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ibis: install Ibis from git master https://github.com/cloudera/ibis\n",
    "- Impyla: install impyla from git master https://github.com/cloudera/impyla\n",
    "- SnpEff: http://snpeff.sourceforge.net/\n",
    "- Reference (downloaded automoatically) GRCh37.74 to match vcf files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Impala with Ibis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hdfs: update 'user' argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ibis\n",
    "import os\n",
    "\n",
    "# connect to impala with ibis\n",
    "hdfs_port = os.environ.get('glados20', 50070)\n",
    "hdfs = ibis.hdfs_connect(host='glados20', port=hdfs_port, user='selasady')\n",
    "con = ibis.impala.connect(host='glados19', port=21050, timeout=120)\n",
    "\n",
    "# enable interactive mode\n",
    "ibis.options.interactive = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add All Variants and Annotations from Reference Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All reference sources containing variants were outer joined to compile a list of all variants found on impala. \n",
    "\n",
    "TODO: Variants from CGI and Illumina will be added after normalized files are available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create connections to each needed table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = 'p7_ref_grch37'\n",
    "\n",
    "# connect to variant tables\n",
    "kaviar = con.table('kaviar_isb', database=db)\n",
    "clinvar = con.table('clinvar', database=db) \n",
    "dbsnp = con.table('dbsnp', database=db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Views with Distinct Subsets of each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# limit dbsnp to build 142\n",
    "dbsnp = dbsnp[dbsnp.dbsnpbuildid == '142']\n",
    "\n",
    "# subset the data for distinct elements from the needed columns\n",
    "kav_sub = kaviar['chrom', 'pos', 'stop', 'ref', 'alt', 'allele_freq', 'sources'].distinct()\n",
    "clin_sub = clinvar['chrom', 'pos', 'ref', 'alt', 'clin_sig', 'clin_dbn'].distinct()\n",
    "dbsnp_sub = dbsnp['chrom', 'pos', 'ref', 'alt', 'rs_id'].distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create views on impala\n",
    "con.create_view('kav_distinct', kav_sub, database='training')\n",
    "con.create_view('clin_distinct', clin_sub, database='training')\n",
    "con.create_view('dbsnp_distinct', dbsnp_sub, database='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an object for each view\n",
    "kav = con.table('kav_distinct', database='training')\n",
    "clin = con.table('clin_distinct', database='training')\n",
    "dbsnp = con.table('dbsnp_distinct', database='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer Join between Kaviar_ISB, ClinVar and dbSNP for SNV's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The Kaviar_ISB file and ClinVar files were joined, keeping all variants found in both tables, and Clinvar significance rating and phenotype name. \n",
    " \n",
    "For SNV's, Kaviar and ClinVar were matched by chromosome and exact position, as well as reference and alt allele. For indels, the tables were matched where ClinVar variant position was between the Kaviar reported start and stop position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join clinvar and kaviar for SNP's\n",
    "kav_snp = kav[kav.alt.length() == 1]\n",
    "\n",
    "# create statements to join clinvar and kaviar\n",
    "clin_expr = [kav_snp.chrom == clin.chrom, kav_snp.pos == clin.pos, kav_snp.ref == clin.ref,\\\n",
    "               kav_snp.alt == clin.alt]\n",
    "\n",
    "# create expression for coalescing common columns\n",
    "kav_chrom_col = ibis.coalesce(kav_snp.chrom, clin.chrom).name('chrom')\n",
    "kav_pos_col = ibis.coalesce(kav_snp.pos, clin.pos).cast('int32').name('pos')\n",
    "kav_ref_col = ibis.coalesce(kav_snp.ref, clin.ref).name('ref')\n",
    "kav_alt_col = ibis.coalesce(kav_snp.alt, clin.ref).name('alt')\n",
    "\n",
    "#outer join clinvar with kaviar_isb\n",
    "clin_kav_snp = kav_snp.outer_join(clin, clin_expr)[kav_chrom_col, \\\n",
    "           kav_pos_col, kav_ref_col, kav_alt_col, kav_snp.allele_freq.name('kav_freq'), \\\n",
    "           kav_snp.sources.name('kav_source'), clin.clin_sig, clin.clin_dbn].distinct()\n",
    "\n",
    "# create table with snps\n",
    "con.create_table('clin_kav_distinct', clin_kav_snp, database='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join clinvar and kaviar for indels\n",
    "kav_indel = kav[kav.alt.length() != 1]\n",
    "\n",
    "# create statements to join clinvar and kaviar\n",
    "clin_expr = [kav_indel.chrom == clin.chrom, kav_indel.pos == clin.pos, kav_indel.ref == clin.ref,\\\n",
    "               kav_indel.alt == clin.alt]\n",
    "\n",
    "# create expression for coalescing common columns\n",
    "indel_chrom_col = ibis.coalesce(kav_indel.chrom, clin.chrom).name('chrom')\n",
    "indel_pos_col = ibis.coalesce(kav_indel.pos, clin.pos).cast('int32').name('pos')\n",
    "indel_pos_ref = ibis.coalesce(kav_indel.ref, clin.ref).name('ref')\n",
    "indel_pos_alt = ibis.coalesce(kav_indel.alt, clin.ref).name('alt')\n",
    "\n",
    "#outer join clinvar with kaviar_isb\n",
    "clin_kav_indel = kav_indel.outer_join(clin, clin_expr)[indel_chrom_col, \\\n",
    "           indel_pos_col, indel_pos_ref, indel_pos_alt, kav_indel.allele_freq.name('kav_freq'), \\\n",
    "           kav_indel.sources.name('kav_source'), clin.clin_sig, clin.clin_dbn].distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert indels into clin_kav_distinct table\n",
    "con.insert('clin_kav_distinct', clin_kav_indel, database='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clin_kav_distinct = con.table('clin_kav_distinct', database='training')\n",
    "\n",
    "# create statements to join the clin_kav table with dbsnp\n",
    "dbsnp_exprs = [clin_kav_distinct.chrom == dbsnp.chrom, clin_kav_distinct.pos == dbsnp.pos, \\\n",
    "               clin_kav_distinct.ref == dbsnp.ref, clin_kav_distinct.alt == dbsnp.alt]\n",
    "\n",
    "# create expression for coalescing common columns\n",
    "clin_kav_chrom = ibis.coalesce(clin_kav_distinct.chrom, dbsnp.chrom).name('chrom')\n",
    "clin_kav_pos = ibis.coalesce(clin_kav_distinct.pos, dbsnp.pos).cast('int32').name('pos')\n",
    "clin_kav_ref = ibis.coalesce(clin_kav_distinct.ref, dbsnp.ref).name('ref')\n",
    "clin_kav_alt = ibis.coalesce(clin_kav_distinct.alt, dbsnp.ref).name('alt')\n",
    "\n",
    "# outer join clin_kav with dbsnp\n",
    "clinkav_dbsnp = clin_kav_distinct.outer_join(dbsnp, dbsnp_exprs)[clin_kav_chrom, clin_kav_pos, clin_kav_ref, clin_kav_alt,\\\n",
    "                        clin_kav_distinct.kav_freq, clin_kav_distinct.kav_source,clin_kav_distinct.clin_sig, \\\n",
    "                        clin_kav_distinct.clin_dbn, dbsnp.rs_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reduce all_vars to distinct entries and save as a view on impala to join with indels\n",
    "con.create_table('all_vars', clinkav_dbsnp.distinct(), database='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer Join between Kaviar_ISB, ClinVar and dbSNP for indels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join clinvar and kaviar for SNP's\n",
    "kav_indel = kav[kav.alt.length() > 1]\n",
    "\n",
    "# create statements to join clinvar and kaviar\n",
    "clin_indel_expr = [kav_indel.chrom == clin.chrom, \\\n",
    "                   clin.pos >= kav_indel.pos, clin.pos <= kav_indel.stop, \\\n",
    "                   kav_indel.ref == clin.ref,\\\n",
    "                   kav_indel.alt == clin.alt]\n",
    "\n",
    "#outer join clinvar with kaviar_isb\n",
    "clin_kav_indel = kav_indel.outer_join(clin, clin_indel_expr)[kav_indel.chrom, kav_indel.pos, \\\n",
    "           kav_indel.ref, kav_indel.alt, kav_indel.allele_freq.name('kav_freq'), \\\n",
    "           kav_indel.sources.name('kav_source'), clin.clin_sig, clin.clin_dbn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create statements to join the clin_kav table with dbsnp\n",
    "dbsnp_indel_exprs = [clin_kav_indel.chrom == dbsnp.chrom, clin_kav_indel.pos == dbsnp.pos, \\\n",
    "               clin_kav_indel.ref == dbsnp.ref, clin_kav_indel.alt == dbsnp.alt]\n",
    "\n",
    "# outer join clin_kav with dbsnp\n",
    "indels = clin_kav_indel.outer_join(dbsnp, dbsnp_indel_exprs)[clin_kav_indel, dbsnp.rs_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge SNP's and indels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con.insert('all_vars', indels, database='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Regional Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Region-based annotations will be added to speed up downstream analysis and lookups. \n",
    "\n",
    "TODO: Add CADD and PFAM annotations when available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# connect to regional annotation tables\n",
    "dann = con.table('dann', database='p7_ref_grch37')\n",
    "ensembl = con.table('ensembl_genes', database='p7_ref_grch37')\n",
    "dbnsfp = con.table('dbnsfp_variant', database='p7_ref_grch37')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a subset from each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subset tables for only required columns and distinct rows\n",
    "ensembl_sub = ensembl['chrom', 'start', 'stop', 'strand', 'gene_name', 'gene_id'].distinct()\n",
    "dbnsfp_sub = dbnsfp['chrom', 'pos', 'ref', 'alt', 'sift_score', 'sift_pred', 'polyphen2_hdiv_score', \\\n",
    "             'polyphen2_hvar_score', 'cadd_raw', 'interpro_domain'].distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create views on impala\n",
    "con.create_view('ens_distinct', ensembl_sub, database='training')\n",
    "con.create_view('dbnsfp_distinct', dbnsfp_sub, database='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a connection to each view or table\n",
    "ens = con.table('ens_distinct', database='training')\n",
    "dbnsfp_dist = con.table('dbnsfp_distinct', database='training')\n",
    "all_vars = con.table('all_vars', database='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Regional Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following annotations will be broken out into chromosome as these tables are getting very large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create case statement to add DANN score depending on reference\n",
    "dann_case = (ibis.case()\n",
    "            .when(all_vars.alt == 'A', dann.score_a)\n",
    "            .when(all_vars.alt == 'T', dann.score_t)\n",
    "            .when(all_vars.alt == 'C', dann.score_c)\n",
    "            .when(all_vars.alt == 'G', dann.score_g)\n",
    "            .else_(ibis.NA)\n",
    "            .end())    \n",
    "\n",
    "# create table with variants and dann score annnoations\n",
    "dann_exp = [all_vars.chrom == '1', dann.chrom == all_vars.chrom, all_vars.pos == dann.pos]\n",
    "con.create_table('vars_dann', all_vars.join(dann, dann_exp)[all_vars, dann_case.name('dann_score')].distinct(), \\\n",
    "                 database='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      14\n",
      "1       6\n",
      "2       X\n",
      "3      21\n",
      "4       1\n",
      "5       2\n",
      "6     NaN\n",
      "7       7\n",
      "8      11\n",
      "9      16\n",
      "10     13\n",
      "11     12\n",
      "12      5\n",
      "13      9\n",
      "14      Y\n",
      "15      4\n",
      "16     17\n",
      "17     20\n",
      "18     18\n",
      "19     22\n",
      "20      8\n",
      "21      3\n",
      "22     19\n",
      "23     10\n",
      "24     15\n",
      "Name: chrom, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# create string of chromosomes in the data set\n",
    "chroms = str(all_vars.chrom.distinct())\n",
    "# remove chromosome 1\n",
    "chroms = chroms.translate(None, '1')\n",
    "\n",
    "print all_vars.chrom.distinct()\n",
    "\n",
    "# append each chromosome to vars_dann table\n",
    "#for this_chrom in chroms:\n",
    "#     # create table with variants and dann score annnoations\n",
    "#     dann_exp = [all_vars.chrom == this_chrom, dann.chrom == all_vars.chrom, all_vars.pos == dann.pos]\n",
    "#     con.insert('vars_dann', all_vars.join(dann, dann_exp)[all_vars, dann_case.name('dann_score')].distinct(), \\\n",
    "#                  database='training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# connect to vars_dann table and run compute stats\n",
    "vars_dann = con.table('vars_dann', database='training')\n",
    "vars_dann.compute_stats()\n",
    "\n",
    "# create table with ensembl gene annotations\n",
    "ensembl_exp = [vars_dann.chrom == ens.chrom, vars_dann.pos >= ens.start, \\\n",
    "               vars_dann.pos <= ens.stop]\n",
    "vars_dann_ens = vars_dann.join(ens, ensembl_exp)[vars_dann, ens.gene_name.name('ens_gene')].distinct()\n",
    "\n",
    "# create a table with variants, dann and ensembl annotations\n",
    "con.create_table('vars_dann_ens', vars_dann_ens, database= 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  create a connection to variants with dann and ensembl annotations view \n",
    "add_dbnsfp = con.table('vars_dann_ens', database = 'training')\n",
    "add_dbnsfp.compute_stats()\n",
    "\n",
    "# add CADD and PFAM scores from dbNSFP table\n",
    "dbnsfp_exp = [add_dbnsfp.chrom == dbnsfp_dist.chrom, add_dbnsfp.pos == dbnsfp_dist.pos, \\\n",
    "              add_dbnsfp.ref == dbnsfp_dist.ref, add_dbnsfp.alt == dbnsfp_dist.alt]\n",
    "\n",
    "global_vars = add_dbnsfp.join(dbnsfp_dist, dbnsfp_exp)[add_dbnsfp, dbnsfp_dist.sift_score,  \\\n",
    "                         dbnsfp_dist.polyphen2_hdiv_score, dbnsfp_dist.polyphen2_hvar_score, \\\n",
    "                         dbnsfp_dist.cadd_raw, dbnsfp_dist.interpro_domain].distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save global variants as impala table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table is too large to add snpeff annotations without first saving the table to impala. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "Operation is in ERROR_STATE",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e3030f6ef2e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'global_vars'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\ibis\\impala\\client.pyc\u001b[0m in \u001b[0;36mcreate_table\u001b[1;34m(self, table_name, obj, schema, database, format, force, external, path, partition, like_parquet)\u001b[0m\n\u001b[0;32m    798\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIbisError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Must pass expr or schema'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_write_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\ibis\\client.pyc\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, query, results)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\ibis\\impala\\client.pyc\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, query, async)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\ibis\\impala\\client.pyc\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, stmt, async)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_synchronous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_wait_synchronous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\ibis\\impala\\client.pyc\u001b[0m in \u001b[0;36m_wait_synchronous\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhs2_cursor_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_op_state_is_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mOperationalError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Operation is in ERROR_STATE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_op_state_is_executing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: Operation is in ERROR_STATE"
     ]
    }
   ],
   "source": [
    "con.create_table('global_vars', global_vars.distinct(), database='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up temp tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "    - Add normalized variants from illumina and cgi\n",
    "    - Add PFAM domains\n",
    "    - Add snpeff annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
